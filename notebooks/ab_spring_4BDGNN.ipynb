{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## IMPORT ######################\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from functools import partial, wraps\n",
    "\n",
    "# import fire\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "# import numpy as np\n",
    "from jax import jit, random, value_and_grad, vmap\n",
    "# from jax.experimental import optimizers\n",
    "from jax.example_libraries import optimizers\n",
    "from jax_md import space\n",
    "from shadow.plot import *\n",
    "from sklearn.metrics import r2_score\n",
    "# from sympy import LM\n",
    "# from torch import batch_norm_gather_stats_with_counts\n",
    "\n",
    "from psystems.nsprings import (chain, edge_order, get_connections,\n",
    "                               get_fully_connected_senders_and_receivers,\n",
    "                               get_fully_edge_order)\n",
    "\n",
    "MAINPATH = \"..\"  # nopep8\n",
    "sys.path.append(MAINPATH)  # nopep8\n",
    "\n",
    "import jraph\n",
    "import src\n",
    "from jax.config import config\n",
    "from src import lnn\n",
    "# from src.graph import *\n",
    "# from src.lnn import acceleration, accelerationFull, accelerationTV, acceleration_GNODE\n",
    "from src.md import *\n",
    "from src.models import MSE, initialize_mlp, GaussianNLL, initialize_mlp_gamma\n",
    "from src.nve import NVEStates, nve, BrownianStates\n",
    "from src.utils import *\n",
    "\n",
    "# config.update(\"jax_enable_x64\", True)\n",
    "# config.update(\"jax_debug_nans\", True)\n",
    "# jax.config.update('jax_platform_name', 'gpu')\n",
    "\n",
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "def pprint(*args, namespace=globals()):\n",
    "    for arg in args:\n",
    "        print(f\"{namestr(arg, namespace)[0]}: {arg}\")\n",
    "\n",
    "f32 = jnp.float32\n",
    "f64 = jnp.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs: \n",
      "N: 10\n",
      "epochs: 10000\n",
      "seed: 42\n",
      "rname: True\n",
      "dt: 0.001\n",
      "lr: 0.0001\n",
      "batch_size: 20\n"
     ]
    }
   ],
   "source": [
    "N = 10  # number of particles\n",
    "dim = 2  # dimensions\n",
    "runs = 1\n",
    "kT = 1 #1.380649e-23*T  # boltzmann constant*temperature\n",
    "# spring_constant = 1.0\n",
    "# length_constant = 1.0\n",
    "# nconfig=100\n",
    "seed=42\n",
    "dt = 1.0e-3 # time step*stride \n",
    "lr=1e-4\n",
    "batch_size=20\n",
    "epochs = 10000\n",
    "# node_type = jnp.array([0,0,0,0,0])\n",
    "masses = jnp.ones(N)\n",
    "# masses = 1.0#jnp.where(jnp.arange(N) <3, 1.0, 1.0)\n",
    "species = np.where(np.arange(N) < 3, 0, 1) #jnp.zeros(N, dtype=int)\n",
    "gamma = jnp.where(jnp.arange(N) <3, 1.0, 2.0).reshape(-1,1)\n",
    "\n",
    "rname=True\n",
    "withdata = None\n",
    "\n",
    "print(\"Configs: \")\n",
    "pprint(N, epochs, seed, rname, dt, lr, batch_size, namespace=locals())\n",
    "\n",
    "randfilename = datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "\n",
    "PSYS = f\"a-{N}-AB-Spring-data-brownian_EM\"\n",
    "TAG = f\"4BDGNN\"\n",
    "out_dir = f\"../results\"\n",
    "\n",
    "def _filename(name, tag=TAG):\n",
    "    rstring = randfilename if (rname and (tag != \"data\")) else (\n",
    "        \"0\" if (tag == \"data\") or (withdata == None) else f\"0_{withdata}\")\n",
    "    filename_prefix = f\"{out_dir}/{PSYS}-{tag}/{rstring}/\"\n",
    "    file = f\"{filename_prefix}/{name}\"\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    filename = f\"{filename_prefix}/{name}\".replace(\"//\", \"/\")\n",
    "    print(\"===\", filename, \"===\")\n",
    "    return filename\n",
    "\n",
    "def displacement(a, b):\n",
    "    return a - b\n",
    "\n",
    "def shift(R, dR):\n",
    "    return R+dR\n",
    "\n",
    "def OUT(f):\n",
    "    @wraps(f)\n",
    "    def func(file, *args, tag=TAG, **kwargs):\n",
    "        return f(_filename(file, tag=tag), *args, **kwargs)\n",
    "    return func\n",
    "\n",
    "loadmodel = OUT(src.models.loadmodel)\n",
    "savemodel = OUT(src.models.savemodel)\n",
    "\n",
    "loadfile = OUT(src.io.loadfile)\n",
    "savefile = OUT(src.io.savefile)\n",
    "save_ovito = OUT(src.io.save_ovito)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../results/a-10-AB-Spring-data-brownian_EM-data/0/model_states_brownian.pkl ===\n",
      "Total number of data points: 100x100\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "################## CONFIG ######################\n",
    "################################################\n",
    "np.random.seed(seed)\n",
    "key = random.PRNGKey(seed)\n",
    "\n",
    "try:\n",
    "    dataset_states = loadfile(f\"model_states_brownian.pkl\", tag=\"data\")[0]\n",
    "except:\n",
    "    raise Exception(\"Generate dataset first.\")\n",
    "\n",
    "model_states = dataset_states[0]\n",
    "\n",
    "print(f\"Total number of data points: {len(dataset_states)}x{model_states.position.shape[0]}\")\n",
    "\n",
    "Rs = States_Brow().fromlist(dataset_states).get_array()\n",
    "\n",
    "Rs_in = Rs[:,:99,:,:]\n",
    "Rs_out = Rs[:,1:100,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 DeepMind Technologies Limited.\n",
    "\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"A library of Graph Neural Network models.\"\"\"\n",
    "\n",
    "import functools\n",
    "import sunau\n",
    "from typing import Any, Callable, Iterable, Mapping, Optional, Union\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax_md import space\n",
    "import jax.tree_util as tree\n",
    "from frozendict import frozendict\n",
    "from jax import vmap\n",
    "from jraph._src import graph as gn_graph\n",
    "from jraph._src import utils\n",
    "\n",
    "from src.models import SquarePlus, forward_pass, forward_pass_gamma, ReLU #, SoftPlus\n",
    "\n",
    "jax.tree_util.register_pytree_node(\n",
    "    frozendict,\n",
    "    flatten_func=lambda s: (tuple(s.values()), tuple(s.keys())),\n",
    "    unflatten_func=lambda k, xs: frozendict(zip(k, xs)))\n",
    "\n",
    "# As of 04/2020 pytype doesn't support recursive types.\n",
    "# pytype: disable=not-supported-yet\n",
    "ArrayTree = Union[jnp.ndarray,\n",
    "                  Iterable['ArrayTree'], Mapping[Any, 'ArrayTree']]\n",
    "\n",
    "# All features will be an ArrayTree.\n",
    "NodeFeatures = EdgeFeatures = SenderFeatures = ReceiverFeatures = Globals = ArrayTree\n",
    "\n",
    "# Signature:\n",
    "# (edges of each node to be aggregated, segment ids, number of segments) ->\n",
    "# aggregated edges\n",
    "AggregateEdgesToNodesFn = Callable[\n",
    "    [EdgeFeatures, jnp.ndarray, int], NodeFeatures]\n",
    "\n",
    "# Signature:\n",
    "# (nodes of each graph to be aggregated, segment ids, number of segments) ->\n",
    "# aggregated nodes\n",
    "AggregateNodesToGlobalsFn = Callable[[NodeFeatures, jnp.ndarray, int],\n",
    "                                     Globals]\n",
    "\n",
    "# Signature:\n",
    "# (edges of each graph to be aggregated, segment ids, number of segments) ->\n",
    "# aggregated edges\n",
    "AggregateEdgesToGlobalsFn = Callable[[EdgeFeatures, jnp.ndarray, int],\n",
    "                                     Globals]\n",
    "\n",
    "# Signature:\n",
    "# (edge features, sender node features, receiver node features, globals) ->\n",
    "# attention weights\n",
    "AttentionLogitFn = Callable[\n",
    "    [EdgeFeatures, SenderFeatures, ReceiverFeatures, Globals], ArrayTree]\n",
    "\n",
    "# Signature:\n",
    "# (edge features, weights) -> edge features for node update\n",
    "AttentionReduceFn = Callable[[EdgeFeatures, ArrayTree], EdgeFeatures]\n",
    "\n",
    "# Signature:\n",
    "# (edges to be normalized, segment ids, number of segments) ->\n",
    "# normalized edges\n",
    "AttentionNormalizeFn = Callable[[EdgeFeatures, jnp.ndarray, int], EdgeFeatures]\n",
    "\n",
    "# Signature:\n",
    "# (edge features, sender node features, receiver node features, globals) ->\n",
    "# updated edge features\n",
    "GNUpdateEdgeFn = Callable[\n",
    "    [EdgeFeatures, SenderFeatures, ReceiverFeatures, Globals], EdgeFeatures]\n",
    "\n",
    "# Signature:\n",
    "# (node features, outgoing edge features, incoming edge features,\n",
    "#  globals) -> updated node features\n",
    "GNUpdateNodeFn = Callable[\n",
    "    [NodeFeatures, SenderFeatures, ReceiverFeatures, Globals], NodeFeatures]\n",
    "\n",
    "GNUpdateGlobalFn = Callable[[NodeFeatures, EdgeFeatures, Globals], Globals]\n",
    "\n",
    "# Signature:\n",
    "# (node features, outgoing edge features, incoming edge features,\n",
    "#  globals) -> updated node features\n",
    "# V: Potential energy of edge\n",
    "GN_to_V_Fn = Callable[[EdgeFeatures, NodeFeatures], float]\n",
    "GN_to_T_Fn = Callable[[NodeFeatures], float]\n",
    "\n",
    "\n",
    "def GNNet(\n",
    "    V_fn: GN_to_V_Fn,\n",
    "    initial_edge_embed_fn: Optional[GNUpdateEdgeFn],\n",
    "    initial_node_embed_fn: Optional[GNUpdateEdgeFn],\n",
    "    update_edge_fn: Optional[GNUpdateEdgeFn],\n",
    "    update_node_fn: Optional[GNUpdateNodeFn],\n",
    "    T_fn: GN_to_T_Fn = None,\n",
    "    update_global_fn: Optional[GNUpdateGlobalFn] = None,\n",
    "    aggregate_nodes_for_globals_fn: AggregateNodesToGlobalsFn = utils\n",
    "    .segment_sum,\n",
    "    aggregate_edges_for_globals_fn: AggregateEdgesToGlobalsFn = utils\n",
    "    .segment_sum,\n",
    "    attention_logit_fn: Optional[AttentionLogitFn] = None,\n",
    "    attention_normalize_fn: Optional[AttentionNormalizeFn] = utils\n",
    "    .segment_softmax,\n",
    "        attention_reduce_fn: Optional[AttentionReduceFn] = None,\n",
    "        N=1,):\n",
    "    \"\"\"Returns a method that applies a configured GraphNetwork.\n",
    "\n",
    "    This implementation follows Algorithm 1 in https://arxiv.org/abs/1806.01261\n",
    "\n",
    "    There is one difference. For the nodes update the class aggregates over the\n",
    "    sender edges and receiver edges separately. This is a bit more general\n",
    "    than the algorithm described in the paper. The original behaviour can be\n",
    "    recovered by using only the receiver edge aggregations for the update.\n",
    "\n",
    "    In addition this implementation supports softmax attention over incoming\n",
    "    edge features.\n",
    "\n",
    "    Example usage::\n",
    "\n",
    "      gn = GraphNetwork(update_edge_function,\n",
    "      update_node_function, **kwargs)\n",
    "      # Conduct multiple rounds of message passing with the same parameters:\n",
    "      for _ in range(num_message_passing_steps):\n",
    "        graph = gn(graph)\n",
    "\n",
    "    Args:\n",
    "      update_edge_fn: function used to update the edges or None to deactivate edge\n",
    "        updates.\n",
    "      update_node_fn: function used to update the nodes or None to deactivate node\n",
    "        updates.\n",
    "      update_global_fn: function used to update the globals or None to deactivate\n",
    "        globals updates.\n",
    "      aggregate_edges_for_nodes_fn: function used to aggregate messages to each\n",
    "        node.\n",
    "      aggregate_nodes_for_globals_fn: function used to aggregate the nodes for the\n",
    "        globals.\n",
    "      aggregate_edges_for_globals_fn: function used to aggregate the edges for the\n",
    "        globals.\n",
    "      attention_logit_fn: function used to calculate the attention weights or\n",
    "        None to deactivate attention mechanism.\n",
    "      attention_normalize_fn: function used to normalize raw attention logits or\n",
    "        None if attention mechanism is not active.\n",
    "      attention_reduce_fn: function used to apply weights to the edge features or\n",
    "        None if attention mechanism is not active.\n",
    "\n",
    "    Returns:\n",
    "      A method that applies the configured GraphNetwork.\n",
    "    \"\"\"\n",
    "    def not_both_supplied(x, y): return (\n",
    "        x != y) and ((x is None) or (y is None))\n",
    "    if not_both_supplied(attention_reduce_fn, attention_logit_fn):\n",
    "        raise ValueError(('attention_logit_fn and attention_reduce_fn must both be'\n",
    "                          ' supplied.'))\n",
    "\n",
    "    def _ApplyGraphNet(graph):\n",
    "        \"\"\"Applies a configured GraphNetwork to a graph.\n",
    "\n",
    "        This implementation follows Algorithm 1 in https://arxiv.org/abs/1806.01261\n",
    "\n",
    "        There is one difference. For the nodes update the class aggregates over the\n",
    "        sender edges and receiver edges separately. This is a bit more general\n",
    "        the algorithm described in the paper. The original behaviour can be\n",
    "        recovered by using only the receiver edge aggregations for the update.\n",
    "\n",
    "        In addition this implementation supports softmax attention over incoming\n",
    "        edge features.\n",
    "\n",
    "        Many popular Graph Neural Networks can be implemented as special cases of\n",
    "        GraphNets, for more information please see the paper.\n",
    "\n",
    "        Args:\n",
    "          graph: a `GraphsTuple` containing the graph.\n",
    "\n",
    "        Returns:\n",
    "          Updated `GraphsTuple`.\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        # pylint: disable=g-long-lambda\n",
    "        nodes, edges, receivers, senders, globals_, n_node, n_edge = graph\n",
    "        # nodes, edges, receivers, senders, globals_, n_node, n_edge, _, _, _  = graph\n",
    "        # nodes,edges,receivers,senders,globals_,n_node,n_edge,eorder,emask,nmask = graph\n",
    "        # Equivalent to jnp.sum(n_node), but jittable\n",
    "\n",
    "        # calculate number of nodes in graph\n",
    "        sum_n_node = tree.tree_leaves(nodes)[0].shape[0]\n",
    "\n",
    "        # calculate number of edges in graph\n",
    "        sum_n_edge = senders.shape[0]\n",
    "        \n",
    "        # check if all all node array are of same length = number of nodes\n",
    "        if not tree.tree_all(\n",
    "                tree.tree_map(lambda n: n.shape[0] == sum_n_node, nodes)):\n",
    "            raise ValueError(\n",
    "                'All node arrays in nest must contain the same number of nodes.')\n",
    "\n",
    "        # Initial sent info\n",
    "        sent_attributes = tree.tree_map(lambda n: n[senders], nodes)\n",
    "\n",
    "        # Initial received info\n",
    "        received_attributes = tree.tree_map(lambda n: n[receivers], nodes)\n",
    "\n",
    "        # Here we scatter the global features to the corresponding edges,\n",
    "        # giving us tensors of shape [num_edges, global_feat].\n",
    "        # i.e create an array per edge for global attributes\n",
    "        global_edge_attributes = tree.tree_map(lambda g: jnp.repeat(\n",
    "            g, n_edge, axis=0, total_repeat_length=sum_n_edge), globals_)\n",
    "\n",
    "        # Here we scatter the global features to the corresponding nodes,\n",
    "        # giving us tensors of shape [num_nodes, global_feat].\n",
    "        # i.e create an array per node for global attributes\n",
    "        global_attributes = tree.tree_map(lambda g: jnp.repeat(\n",
    "            g, n_node, axis=0, total_repeat_length=sum_n_node), globals_)\n",
    "\n",
    "        # apply initial edge embeddings\n",
    "        if initial_edge_embed_fn:\n",
    "            edges = initial_edge_embed_fn(edges, sent_attributes, received_attributes,\n",
    "                                          global_edge_attributes)\n",
    "        # apply initial node embeddings\n",
    "        if initial_node_embed_fn:\n",
    "            nodes = initial_node_embed_fn(nodes, sent_attributes,\n",
    "                                          received_attributes, global_attributes)\n",
    "\n",
    "        # Now perform message passing for N times\n",
    "        for pass_i in range(N):\n",
    "            if attention_logit_fn:\n",
    "                logits = attention_logit_fn(edges, sent_attributes, received_attributes,\n",
    "                                            global_edge_attributes)\n",
    "                tree_calculate_weights = functools.partial(\n",
    "                    attention_normalize_fn,\n",
    "                    segment_ids=receivers,\n",
    "                    num_segments=sum_n_node)\n",
    "                weights = tree.tree_map(tree_calculate_weights, logits)\n",
    "                edges = attention_reduce_fn(edges, weights)\n",
    "\n",
    "            if update_node_fn:\n",
    "                nodes = update_node_fn(\n",
    "                    nodes, edges, senders, receivers,\n",
    "                    global_attributes, sum_n_node)\n",
    "\n",
    "            if update_edge_fn:\n",
    "                senders_attributes = tree.tree_map(\n",
    "                    lambda n: n[senders], nodes)\n",
    "                receivers_attributes = tree.tree_map(\n",
    "                    lambda n: n[receivers], nodes)\n",
    "                edges = update_edge_fn(edges, senders_attributes, receivers_attributes,\n",
    "                                       global_edge_attributes, pass_i == N-1)\n",
    "\n",
    "        if update_global_fn:\n",
    "            n_graph = n_node.shape[0]\n",
    "            graph_idx = jnp.arange(n_graph)\n",
    "            # To aggregate nodes and edges from each graph to global features,\n",
    "            # we first construct tensors that map the node to the corresponding graph.\n",
    "            # For example, if you have `n_node=[1,2]`, we construct the tensor\n",
    "            # [0, 1, 1]. We then do the same for edges.\n",
    "            node_gr_idx = jnp.repeat(\n",
    "                graph_idx, n_node, axis=0, total_repeat_length=sum_n_node)\n",
    "            edge_gr_idx = jnp.repeat(\n",
    "                graph_idx, n_edge, axis=0, total_repeat_length=sum_n_edge)\n",
    "            # We use the aggregation function to pool the nodes/edges per graph.\n",
    "            node_attributes = tree.tree_map(\n",
    "                lambda n: aggregate_nodes_for_globals_fn(\n",
    "                    n, node_gr_idx, n_graph),\n",
    "                nodes)\n",
    "            edge_attribtutes = tree.tree_map(\n",
    "                lambda e: aggregate_edges_for_globals_fn(\n",
    "                    e, edge_gr_idx, n_graph),\n",
    "                edges)\n",
    "            # These pooled nodes are the inputs to the global update fn.\n",
    "            globals_ = update_global_fn(\n",
    "                node_attributes, edge_attribtutes, globals_)\n",
    "\n",
    "        V = 0.0\n",
    "        if V_fn is not None:\n",
    "            V += V_fn(edges, nodes)\n",
    "\n",
    "        T = 0.0\n",
    "        if T_fn is not None:\n",
    "            T += T_fn(nodes)\n",
    "\n",
    "        # pylint: enable=g-long-lambda\n",
    "        return gn_graph.GraphsTuple(\n",
    "            nodes=nodes,\n",
    "            edges=edges,\n",
    "            receivers=receivers,\n",
    "            senders=senders,\n",
    "            globals=globals_,\n",
    "            n_node=n_node,\n",
    "            n_edge=n_edge), V, T\n",
    "\n",
    "    return _ApplyGraphNet\n",
    "\n",
    "\n",
    "# Signature:\n",
    "# edge features -> embedded edge features\n",
    "EmbedEdgeFn = Callable[[EdgeFeatures], EdgeFeatures]\n",
    "\n",
    "# Signature:\n",
    "# node features -> embedded node features\n",
    "EmbedNodeFn = Callable[[NodeFeatures], NodeFeatures]\n",
    "\n",
    "# Signature:\n",
    "# globals features -> embedded globals features\n",
    "EmbedGlobalFn = Callable[[Globals], Globals]\n",
    "\n",
    "\n",
    "def get_fully_connected_senders_and_receivers(\n",
    "    num_particles: int, self_edges: bool = False,\n",
    "):\n",
    "    \"\"\"Returns senders and receivers for fully connected particles.\"\"\"\n",
    "    particle_indices = jnp.arange(num_particles)\n",
    "    senders, receivers = jnp.meshgrid(particle_indices, particle_indices)\n",
    "    senders, receivers = senders.flatten(), receivers.flatten()\n",
    "    if not self_edges:\n",
    "        mask = senders != receivers\n",
    "        senders, receivers = senders[mask], receivers[mask]\n",
    "    return senders, receivers\n",
    "\n",
    "\n",
    "def cal_graph(params, graph, eorder=None, mpass=1,\n",
    "              useT=True, useonlyedge=False, act_fn=SquarePlus):\n",
    "    fb_params = params[\"fb\"]\n",
    "    fne_params = params[\"fne\"]\n",
    "    fneke_params = params[\"fneke\"]\n",
    "    fv_params = params[\"fv\"]\n",
    "    fe_params = params[\"fe\"]\n",
    "    ff1_params = params[\"ff1\"]\n",
    "    ff2_params = params[\"ff2\"]\n",
    "    ff3_params = params[\"ff3\"]\n",
    "    ke_params = params[\"ke\"]\n",
    "\n",
    "    num_species = 1\n",
    "    \n",
    "    def onehot(n):\n",
    "        def fn(n):\n",
    "            out = jax.nn.one_hot(n, num_species)\n",
    "            return out\n",
    "        out = vmap(fn)(n.reshape(-1,))\n",
    "        return out\n",
    "\n",
    "    def fne(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(fne_params, ni, activation_fn=lambda x: x)\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0))(n)\n",
    "        return out\n",
    "\n",
    "    def fneke(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(fneke_params, ni, activation_fn=lambda x: x)\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0))(n)\n",
    "        return out\n",
    "\n",
    "    def fb(e):\n",
    "        def fn(eij):\n",
    "            out = forward_pass(fb_params, eij, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0))(e)\n",
    "        return out\n",
    "\n",
    "    def fv(n, e, s, r, sum_n_node):\n",
    "        c1ij = jnp.hstack([n[r], e])\n",
    "        out = vmap(lambda x: forward_pass(fv_params, x))(c1ij)\n",
    "        return n + jax.ops.segment_sum(out, r, sum_n_node)\n",
    "\n",
    "    def fe(e, s, r):\n",
    "        def fn(hi, hj):\n",
    "            c2ij = hi * hj\n",
    "            out = forward_pass(fe_params, c2ij, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = e + vmap(fn, in_axes=(0, 0))(s, r)\n",
    "        return out\n",
    "\n",
    "    def ff1(e):\n",
    "        def fn(eij):\n",
    "            out = forward_pass(ff1_params, eij, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn)(e)\n",
    "        return out\n",
    "\n",
    "    def ff2(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(ff2_params, ni, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn)(n)\n",
    "        return out\n",
    "\n",
    "    def ff3(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(ff3_params, ni, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn)(n)\n",
    "        return out\n",
    "\n",
    "    def ke(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(ke_params, ni, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn)(n)\n",
    "        return out\n",
    "    \n",
    "    # ================================================================================\n",
    "\n",
    "    def initial_edge_emb_fn(edges, senders, receivers, globals_):\n",
    "        del edges, globals_\n",
    "        dr = (senders[\"position\"] - receivers[\"position\"])\n",
    "        # eij = dr\n",
    "        eij = jnp.sqrt(jnp.square(dr).sum(axis=1, keepdims=True))\n",
    "        emb = fb(eij)\n",
    "        return frozendict({\"edge_embed\": emb, \"eij\": eij})\n",
    "\n",
    "    def initial_node_emb_fn(nodes, sent_edges, received_edges, globals_):\n",
    "        del sent_edges, received_edges, globals_\n",
    "        type_of_node = nodes[\"type\"]\n",
    "        ohe = onehot(type_of_node)\n",
    "        emb = fne(ohe)\n",
    "        emb_pos = jnp.hstack([emb, nodes[\"position\"]])\n",
    "        return frozendict({\"node_embed\": emb,\n",
    "                           \"node_pos_embed\": emb_pos,\n",
    "                           })\n",
    "\n",
    "    def update_node_fn(nodes, edges, senders, receivers, globals_, sum_n_node):\n",
    "        del globals_\n",
    "        emb = fv(nodes[\"node_embed\"], edges[\"edge_embed\"],\n",
    "                 senders, receivers, sum_n_node)\n",
    "        n = dict(nodes)\n",
    "        n.update({\"node_embed\": emb})\n",
    "        return frozendict(n)\n",
    "\n",
    "    def update_edge_fn(edges, senders, receivers, globals_, last_step):\n",
    "        del globals_\n",
    "        emb = fe(edges[\"edge_embed\"], senders[\"node_embed\"],\n",
    "                 receivers[\"node_embed\"])\n",
    "        if last_step:\n",
    "            if eorder is not None:\n",
    "                emb = (emb + fe(edges[\"edge_embed\"][eorder],\n",
    "                       receivers[\"node_embed\"], senders[\"node_embed\"])) / 2\n",
    "        return frozendict({\"edge_embed\": emb, \"eij\": edges[\"eij\"]})\n",
    "\n",
    "    if useonlyedge:\n",
    "        def edge_node_to_V_fn(edges, nodes):\n",
    "            vij = ff1(edges[\"edge_embed\"])\n",
    "            # print(vij, edges[\"eij\"])\n",
    "            return vij.sum()\n",
    "    else:\n",
    "        def edge_node_to_V_fn(edges, nodes):\n",
    "            vij = ff1(edges[\"edge_embed\"]).sum()\n",
    "            vi = 0\n",
    "            vi = vi + ff2(nodes[\"node_embed\"]).sum()\n",
    "            vi = vi + ff3(nodes[\"node_pos_embed\"]).sum()\n",
    "            return vij + vi\n",
    "    \n",
    "    if not(useT):\n",
    "        node_to_T_fn = None\n",
    "\n",
    "    Net = GNNet(N=mpass,\n",
    "                V_fn=edge_node_to_V_fn,\n",
    "                T_fn=node_to_T_fn,\n",
    "                initial_edge_embed_fn=initial_edge_emb_fn,\n",
    "                initial_node_embed_fn=initial_node_emb_fn,\n",
    "                update_edge_fn=update_edge_fn,\n",
    "                update_node_fn=update_node_fn)\n",
    "    \n",
    "    return Net(graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bdgnode_cal_force(params, graph, eorder=None, mpass=1, useT=True, useonlyedge=False, act_fn=SquarePlus):\n",
    "#     fb_params = params[\"fb\"]\n",
    "#     fne_params = params[\"fne\"]\n",
    "#     fneke_params = params[\"fneke\"]\n",
    "#     fv_params = params[\"fv\"]\n",
    "#     fe_params = params[\"fe\"]\n",
    "#     ff1_params = params[\"ff1\"]\n",
    "#     ff2_params = params[\"ff2\"]\n",
    "#     ff3_params = params[\"ff3\"]\n",
    "#     ke_params = params[\"ke\"]\n",
    "#     mass_params = params[\"mass\"]\n",
    "#     # gamma_params = params[\"gamma\"]\n",
    "    \n",
    "#     num_species = 1\n",
    "    \n",
    "#     def onehot(n):\n",
    "#         def fn(n):\n",
    "#             out = jax.nn.one_hot(n, num_species)\n",
    "#             return out\n",
    "#         out = vmap(fn)(n.reshape(-1,))\n",
    "#         return out\n",
    "    \n",
    "#     def fne(n):\n",
    "#         def fn(ni):\n",
    "#             out = forward_pass(fne_params, ni, activation_fn=lambda x: x)\n",
    "#             return out\n",
    "#         out = vmap(fn, in_axes=(0))(n)\n",
    "#         return out\n",
    "    \n",
    "#     def fneke(n):\n",
    "#         def fn(ni):\n",
    "#             out = forward_pass(fneke_params, ni, activation_fn=lambda x: x)\n",
    "#             return out\n",
    "#         out = vmap(fn, in_axes=(0))(n)\n",
    "#         return out\n",
    "    \n",
    "#     def fb(e):\n",
    "#         def fn(eij):\n",
    "#             out = forward_pass(fb_params, eij, activation_fn=act_fn)\n",
    "#             return out\n",
    "#         out = vmap(fn, in_axes=(0))(e)\n",
    "#         return out\n",
    "    \n",
    "#     def fv(n, e, s, r, sum_n_node):\n",
    "#         c1ij = jnp.hstack([n[r], e])\n",
    "#         out = vmap(lambda x: forward_pass(fv_params, x))(c1ij)\n",
    "#         return n + jax.ops.segment_sum(out, r, sum_n_node)\n",
    "    \n",
    "#     def fe(e, s, r):\n",
    "#         def fn(hi, hj):\n",
    "#             c2ij = hi * hj\n",
    "#             out = forward_pass(fe_params, c2ij, activation_fn=act_fn)\n",
    "#             return out\n",
    "#         out = e + vmap(fn, in_axes=(0, 0))(s, r)\n",
    "#         return out\n",
    "    \n",
    "#     def ff1(e):\n",
    "#         def fn(eij):\n",
    "#             out = forward_pass(ff1_params, eij, activation_fn=act_fn)\n",
    "#             return out\n",
    "#         out = vmap(fn)(e)\n",
    "#         return out\n",
    "    \n",
    "#     def ff2(n):\n",
    "#         def fn(ni):\n",
    "#             out = forward_pass(ff2_params, ni, activation_fn=act_fn)\n",
    "#             return out\n",
    "#         out = vmap(fn)(n)\n",
    "#         return out\n",
    "    \n",
    "#     def ff3(n):\n",
    "#         def fn(ni):\n",
    "#             out = forward_pass(ff3_params, ni, activation_fn=act_fn)\n",
    "#             return out\n",
    "#         out = vmap(fn)(n)\n",
    "#         return out\n",
    "    \n",
    "#     def mass(n):\n",
    "#         def fn(ni):\n",
    "#             out = forward_pass(mass_params, ni, activation_fn=act_fn)\n",
    "#             return out\n",
    "#         out = vmap(fn)(n)\n",
    "#         return out\n",
    "    \n",
    "#     # def gamma(n):\n",
    "#     #     def fn(ni):\n",
    "#     #         out = forward_pass_gamma(gamma_params, ni, activation_fn= act_fn) #lambda x: jnp.maximum(0, x)) #jnp.log(lax.add(1.0, jnp.exp(x))))#ReLU)\n",
    "#     #         return out\n",
    "#     #     out = vmap(fn)(n)\n",
    "#     #     return out\n",
    "    \n",
    "#     # ================================================================================\n",
    "    \n",
    "#     def initial_edge_emb_fn(edges, senders, receivers, globals_):\n",
    "#         del edges, globals_\n",
    "#         dr = (senders[\"position\"] - receivers[\"position\"])\n",
    "#         eij = jnp.array(dr)\n",
    "#         # eij = jnp.sqrt(jnp.square(dr).sum(axis=1, keepdims=True))\n",
    "#         emb = fb(eij)\n",
    "#         return frozendict({\"edge_embed\": emb, \"eij\": eij})\n",
    "    \n",
    "#     def initial_node_emb_fn(nodes, sent_edges, received_edges, globals_):\n",
    "#         del sent_edges, received_edges, globals_\n",
    "#         type_of_node = nodes[\"type\"]\n",
    "#         ohe = onehot(type_of_node)\n",
    "#         emb = fne(ohe)\n",
    "#         return frozendict({\"node_embed\": emb,\n",
    "#                            \"node_embed_gamma\": ohe,\n",
    "#                            })\n",
    "    \n",
    "#     def update_node_fn(nodes, edges, senders, receivers, globals_, sum_n_node):\n",
    "#         del globals_\n",
    "#         emb = fv(nodes[\"node_embed\"], edges[\"edge_embed\"],\n",
    "#                  senders, receivers, sum_n_node)\n",
    "#         n = dict(nodes)\n",
    "#         n.update({\"node_embed\": emb})\n",
    "#         return frozendict(n)\n",
    "    \n",
    "#     def update_edge_fn(edges, senders, receivers, globals_, last_step):\n",
    "#         del globals_\n",
    "#         emb = fe(edges[\"edge_embed\"], senders[\"node_embed\"],\n",
    "#                  receivers[\"node_embed\"])\n",
    "#         if last_step:\n",
    "#             if eorder is not None:\n",
    "#                 emb = (emb + fe(edges[\"edge_embed\"][eorder],\n",
    "#                        receivers[\"node_embed\"], senders[\"node_embed\"])) / 2\n",
    "#         return frozendict({\"edge_embed\": emb, \"eij\": edges[\"eij\"]})\n",
    "    \n",
    "#     def edge_node_to_force(edges, nodes, sen, rec, sum_n_node):\n",
    "#         ai = 0\n",
    "#         ai = ai + ff2(nodes[\"node_embed\"])\n",
    "#         return ai\n",
    "    \n",
    "#     def node_to_M_fn(nodes):\n",
    "#         return mass(nodes[\"node_embed\"])\n",
    "    \n",
    "#     # def node_to_gamma_fn(nodes):\n",
    "#     #     return gamma(nodes[\"node_embed_gamma\"])\n",
    "    \n",
    "#     Net = GNNet(N=mpass,\n",
    "#                 V_fn=None,\n",
    "#                 T_fn=None,\n",
    "#                 initial_edge_embed_fn=initial_edge_emb_fn,\n",
    "#                 initial_node_embed_fn=initial_node_emb_fn,\n",
    "#                 update_edge_fn=update_edge_fn,\n",
    "#                 update_node_fn=update_node_fn)\n",
    "#     graph, V, T = Net(graph)\n",
    "#     return edge_node_to_force(graph.edges, graph.nodes, graph.senders, graph.receivers, graph.n_node) #, node_to_gamma_fn(graph.nodes)\n",
    "#     # return jnp.hstack([edge_node_to_force(graph.edges, graph.nodes, graph.senders, graph.receivers, graph.n_node), node_to_gamma_fn(graph.nodes)]) #, jnp.ones((5,1))]) #\n",
    "#     # return jnp.hstack([edge_node_to_force(graph.edges, graph.nodes, graph.senders, graph.receivers, graph.n_node), NN_gamma])\n",
    "#     # edge_node_to_force(graph.edges, graph.nodes, graph.senders, graph.receivers, graph.n_node)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdgnode_cal_force_q(params, graph, eorder=None, mpass=1, useT=True, useonlyedge=False, act_fn=SquarePlus):\n",
    "    fb_params = params[\"fb\"]\n",
    "    fne_params = params[\"fne\"]\n",
    "    fneke_params = params[\"fneke\"]\n",
    "    fv_params = params[\"fv\"]\n",
    "    fe_params = params[\"fe\"]\n",
    "    ff1_params = params[\"ff1\"]\n",
    "    ff2_params = params[\"ff2\"]\n",
    "    ff3_params = params[\"ff3\"]\n",
    "    ke_params = params[\"ke\"]\n",
    "    mass_params = params[\"mass\"]\n",
    "\n",
    "    num_species = 1\n",
    "\n",
    "    def onehot(n):\n",
    "        def fn(n):\n",
    "            out = jax.nn.one_hot(n, num_species)\n",
    "            return out\n",
    "        out = vmap(fn)(n.reshape(-1,))\n",
    "        return out\n",
    "\n",
    "    def fne(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(fne_params, ni, activation_fn=lambda x: x)\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0))(n)\n",
    "        return out\n",
    "\n",
    "    def fneke(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(fneke_params, ni, activation_fn=lambda x: x)\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0))(n)\n",
    "        return out\n",
    "\n",
    "    def fb(e):\n",
    "        def fn(eij):\n",
    "            out = forward_pass(fb_params, eij, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0))(e)\n",
    "        return out\n",
    "\n",
    "    def fv(n, e, s, r, sum_n_node):\n",
    "        c1ij = jnp.hstack([n[r], e])\n",
    "        out = vmap(lambda x: forward_pass(fv_params, x))(c1ij)\n",
    "        return n + jax.ops.segment_sum(out, r, sum_n_node)\n",
    "\n",
    "    def fe(e, s, r):\n",
    "        def fn(hi, hj):\n",
    "            c2ij = hi * hj\n",
    "            out = forward_pass(fe_params, c2ij, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = e + vmap(fn, in_axes=(0, 0))(s, r)\n",
    "        return out\n",
    "\n",
    "    def ff1(e):\n",
    "        def fn(eij):\n",
    "            out = forward_pass(ff1_params, eij, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn)(e)\n",
    "        return out\n",
    "\n",
    "    def ff2(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(ff2_params, ni, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn)(n)\n",
    "        return out\n",
    "\n",
    "    def ff3(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(ff3_params, ni, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn)(n)\n",
    "        return out\n",
    "\n",
    "    def ke(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(ke_params, ni, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn)(n)\n",
    "        return out\n",
    "\n",
    "    def mass(n):\n",
    "        def fn(ni):\n",
    "            out = forward_pass(mass_params, ni, activation_fn=act_fn)\n",
    "            return out\n",
    "        out = vmap(fn)(n)\n",
    "        return out\n",
    "    \n",
    "    # ================================================================================\n",
    "\n",
    "    def initial_edge_emb_fn(edges, senders, receivers, globals_):\n",
    "        del edges, globals_\n",
    "        dr = (senders[\"position\"] - receivers[\"position\"])\n",
    "        eij = jnp.array(dr)\n",
    "        # eij = jnp.sqrt(jnp.square(dr).sum(axis=1, keepdims=True))\n",
    "        emb = fb(eij)\n",
    "        return frozendict({\"edge_embed\": emb, \"eij\": eij})\n",
    "\n",
    "    def initial_node_emb_fn(nodes, sent_edges, received_edges, globals_):\n",
    "        del sent_edges, received_edges, globals_\n",
    "        type_of_node = nodes[\"type\"]\n",
    "        ohe = onehot(type_of_node)\n",
    "        emb = fne(ohe)\n",
    "        # emb_pos_vel = jnp.hstack([emb, nodes[\"position\"], nodes[\"velocity\"]])\n",
    "        return frozendict({\"node_embed\": emb,\n",
    "                        #    \"node_pos_vel_embed\": emb_pos_vel,\n",
    "                           })\n",
    "\n",
    "    def update_node_fn(nodes, edges, senders, receivers, globals_, sum_n_node):\n",
    "        del globals_\n",
    "        emb = fv(nodes[\"node_embed\"], edges[\"edge_embed\"],\n",
    "                 senders, receivers, sum_n_node)\n",
    "        n = dict(nodes)\n",
    "        n.update({\"node_embed\": emb})\n",
    "        return frozendict(n)\n",
    "    \n",
    "    def update_edge_fn(edges, senders, receivers, globals_, last_step):\n",
    "        del globals_\n",
    "        emb = fe(edges[\"edge_embed\"], senders[\"node_embed\"],\n",
    "                 receivers[\"node_embed\"])\n",
    "        if last_step:\n",
    "            if eorder is not None:\n",
    "                emb = (emb + fe(edges[\"edge_embed\"][eorder],\n",
    "                       receivers[\"node_embed\"], senders[\"node_embed\"])) / 2\n",
    "        return frozendict({\"edge_embed\": emb, \"eij\": edges[\"eij\"]})\n",
    "    \n",
    "    def edge_node_to_force(edges, nodes, sen, rec, sum_n_node):\n",
    "        ai = 0\n",
    "        ai = ai + ff2(nodes[\"node_embed\"])\n",
    "        # ai = ai + ff3(nodes[\"node_pos_vel_embed\"])\n",
    "        return ai\n",
    "    \n",
    "    # def node_to_M_fn(nodes):\n",
    "    #     return mass(nodes[\"node_embed\"])\n",
    "    \n",
    "    Net = GNNet(N=mpass,\n",
    "                V_fn=None,\n",
    "                T_fn=None,\n",
    "                initial_edge_embed_fn=initial_edge_emb_fn,\n",
    "                initial_node_embed_fn=initial_node_emb_fn,\n",
    "                update_edge_fn=update_edge_fn,\n",
    "                update_node_fn=update_node_fn)\n",
    "    graph, V, T = Net(graph)\n",
    "    # return jnp.hstack([edge_node_to_force( graph.edges,graph.nodes,graph.senders,graph.receivers,graph.n_node), node_to_M_fn(graph.nodes)])\n",
    "    return edge_node_to_force(graph.edges, graph.nodes, graph.senders, graph.receivers, graph.n_node)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Chain\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "################### ML Model ###################\n",
    "################################################\n",
    "\n",
    "print(\"Creating Chain\")\n",
    "x, v, senders, receivers = chain(N)\n",
    "\n",
    "Ef = dim  # eij dim\n",
    "Nf = dim\n",
    "Oh = 1\n",
    "\n",
    "Eei = 5\n",
    "Nei = 5\n",
    "Nei_ = 5  ##Nei for mass\n",
    "\n",
    "hidden = 5\n",
    "nhidden = 2\n",
    "\n",
    "def get_layers(in_, out_):\n",
    "    return [in_] + [hidden]*nhidden + [out_]\n",
    "\n",
    "def mlp(in_, out_, key, **kwargs):\n",
    "    return initialize_mlp(get_layers(in_, out_), key, **kwargs)\n",
    "\n",
    "fneke_params = initialize_mlp([Oh, Nei], key)\n",
    "fne_params = initialize_mlp([Oh, Nei], key)  #\n",
    "\n",
    "# Nei = Nei+dim+dim\n",
    "fb_params = mlp(Ef, Eei, key)  #\n",
    "fv_params = mlp(Nei+Eei, Nei, key)  #\n",
    "fe_params = mlp(Nei, Eei, key)  #\n",
    "\n",
    "ff1_params = mlp(Eei, dim, key)\n",
    "ff2_params = mlp(Nei, dim, key) #\n",
    "ff3_params = mlp(Nei+dim+dim, dim, key)\n",
    "ke_params = initialize_mlp([1+Nei, 10, 10, 1], key, affine=[True])\n",
    "mass_params = initialize_mlp([Nei_, 5, 1], key, affine=[True]) #\n",
    "# gamma_params = initialize_mlp([Oh, 5, 1], key, affine=[True]) #\n",
    "\n",
    "Fparams = dict(fb=fb_params,\n",
    "                fv=fv_params,\n",
    "                fe=fe_params,\n",
    "                ff1=ff1_params,\n",
    "                ff2=ff2_params,\n",
    "                ff3=ff3_params,\n",
    "                fne=fne_params,\n",
    "                fneke=fneke_params,\n",
    "                ke=ke_params,\n",
    "                mass=mass_params)\n",
    "\n",
    "params = {\"F_pos\": Fparams}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[5.2441654],\n",
       "       [5.2441654],\n",
       "       [5.2441654],\n",
       "       [4.1636734],\n",
       "       [4.1636734],\n",
       "       [4.1636734],\n",
       "       [4.1636734],\n",
       "       [4.1636734],\n",
       "       [4.1636734],\n",
       "       [4.1636734]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"gamma\"] = initialize_mlp_gamma([1,10,5,1], key)\n",
    "\n",
    "def nngamma(type, params):\n",
    "    return forward_pass_gamma(params, type, activation_fn=models.SquarePlus)\n",
    "\n",
    "def gamma(type, params):\n",
    "    return vmap(nngamma, in_axes=(0, None))(type.reshape(-1), params).reshape(-1, 1)\n",
    "    # return nngamma(type.reshape(-1), params[\"gamma\"])#.reshape(-1, 1)\n",
    "\n",
    "ss = gamma(jax.nn.one_hot(species, 1),params[\"gamma\"])\n",
    "# gamma(species,params)\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_force_fn(params, graph):\n",
    "    _GForce = cdgnode_cal_force_q(params, graph, eorder=None, useT=True, mpass=1)\n",
    "    return _GForce\n",
    "\n",
    "R = Rs[0][0]\n",
    "\n",
    "def _force_fn(species):\n",
    "    state_graph = jraph.GraphsTuple(nodes={\n",
    "        \"position\": R,\n",
    "        \"type\": species\n",
    "    },\n",
    "        edges={},\n",
    "        senders=senders,\n",
    "        receivers=receivers,\n",
    "        n_node=jnp.array([R.shape[0]]),\n",
    "        n_edge=jnp.array([senders.shape[0]]),\n",
    "        globals={})\n",
    "    \n",
    "    def apply(R, params):\n",
    "        state_graph.nodes.update(position=R)\n",
    "        return graph_force_fn(params, state_graph)\n",
    "    return apply\n",
    "\n",
    "def gamma_fn(species):    \n",
    "    def fn(params):\n",
    "        return gamma(jax.nn.one_hot(species, 1),params)    \n",
    "    return fn\n",
    "\n",
    "\n",
    "apply_fn = _force_fn(species)\n",
    "gamma_fn = gamma_fn(species)\n",
    "\n",
    "apply_fn = _force_fn(species)\n",
    "\n",
    "def force_fn_model(x, params): return apply_fn(x, params[\"F_pos\"])\n",
    "def gamma_fn_model(params): return gamma_fn(params[\"gamma\"])\n",
    "\n",
    "# _gamma = gamma(jax.nn.one_hot(species, 1),params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_step_pos_gamma(force_fn_model, gamma_fn_model, shift, dt, kT, mass, runs, key):\n",
    "    key, split = random.split(key)\n",
    "    def fn(x, params):\n",
    "        for i in range(runs):\n",
    "            # calculate the force\n",
    "            force = force_fn_model(x, params)\n",
    "            _gamma = gamma_fn_model(params)\n",
    "            xi = random.normal(split, x.shape, x.dtype)\n",
    "            nu = f32(1) / lax.mul(mass.reshape(-1,1) , _gamma)\n",
    "            x = x+ force * dt * nu + jnp.sqrt(f32(2) * kT * dt * nu) * xi\n",
    "        return x, _gamma\n",
    "    return fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = random.PRNGKey(0)\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "\n",
    "next_step_pos_gamma_fn = next_step_pos_gamma(force_fn_model, gamma_fn_model, shift, dt, kT, masses, runs, subkey)\n",
    "v_next_step_pos_gamma_fn = vmap(next_step_pos_gamma_fn, in_axes=(0, None))\n",
    "v_v_next_step_pos_gamma_fn = vmap(v_next_step_pos_gamma_fn, in_axes=(0, None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "Epoch: 0/10000 Loss (MSE):  train=3.0504400730133057\n",
      "gammaaaaa:  [[5.2292566]\n",
      " [5.2292566]\n",
      " [5.2292566]\n",
      " [4.1524754]\n",
      " [4.1524754]\n",
      " [4.1524754]\n",
      " [4.1524754]\n",
      " [4.1524754]\n",
      " [4.1524754]\n",
      " [4.1524754]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 10/10000 Loss (MSE):  train=2.9827871322631836\n",
      "Epoch: 20/10000 Loss (MSE):  train=2.918708562850952\n",
      "Epoch: 30/10000 Loss (MSE):  train=2.85809326171875\n",
      "Epoch: 40/10000 Loss (MSE):  train=2.800704002380371\n",
      "Epoch: 50/10000 Loss (MSE):  train=2.7463037967681885\n",
      "Epoch: 60/10000 Loss (MSE):  train=2.6947035789489746\n",
      "Epoch: 70/10000 Loss (MSE):  train=2.645730495452881\n",
      "Epoch: 80/10000 Loss (MSE):  train=2.599250316619873\n",
      "Epoch: 90/10000 Loss (MSE):  train=2.5551319122314453\n",
      "Epoch: 100/10000 Loss (MSE):  train=2.5132803916931152\n",
      "gammaaaaa:  [[3.9203122]\n",
      " [3.9203122]\n",
      " [3.9203122]\n",
      " [3.1636066]\n",
      " [3.1636066]\n",
      " [3.1636066]\n",
      " [3.1636066]\n",
      " [3.1636066]\n",
      " [3.1636066]\n",
      " [3.1636066]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 110/10000 Loss (MSE):  train=2.473597526550293\n",
      "Epoch: 120/10000 Loss (MSE):  train=2.4359984397888184\n",
      "Epoch: 130/10000 Loss (MSE):  train=2.40040922164917\n",
      "Epoch: 140/10000 Loss (MSE):  train=2.366755247116089\n",
      "Epoch: 150/10000 Loss (MSE):  train=2.3349649906158447\n",
      "Epoch: 160/10000 Loss (MSE):  train=2.304981231689453\n",
      "Epoch: 170/10000 Loss (MSE):  train=2.276738405227661\n",
      "Epoch: 180/10000 Loss (MSE):  train=2.250180959701538\n",
      "Epoch: 190/10000 Loss (MSE):  train=2.2252516746520996\n",
      "Epoch: 200/10000 Loss (MSE):  train=2.201902389526367\n",
      "gammaaaaa:  [[2.935728]\n",
      " [2.935728]\n",
      " [2.935728]\n",
      " [2.417604]\n",
      " [2.417604]\n",
      " [2.417604]\n",
      " [2.417604]\n",
      " [2.417604]\n",
      " [2.417604]\n",
      " [2.417604]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 210/10000 Loss (MSE):  train=2.1800730228424072\n",
      "Epoch: 220/10000 Loss (MSE):  train=2.159712553024292\n",
      "Epoch: 230/10000 Loss (MSE):  train=2.140775442123413\n",
      "Epoch: 240/10000 Loss (MSE):  train=2.1232070922851562\n",
      "Epoch: 250/10000 Loss (MSE):  train=2.1069562435150146\n",
      "Epoch: 260/10000 Loss (MSE):  train=2.091967821121216\n",
      "Epoch: 270/10000 Loss (MSE):  train=2.07818865776062\n",
      "Epoch: 280/10000 Loss (MSE):  train=2.0655622482299805\n",
      "Epoch: 290/10000 Loss (MSE):  train=2.0540285110473633\n",
      "Epoch: 300/10000 Loss (MSE):  train=2.043527126312256\n",
      "gammaaaaa:  [[2.230424]\n",
      " [2.230424]\n",
      " [2.230424]\n",
      " [1.906254]\n",
      " [1.906254]\n",
      " [1.906254]\n",
      " [1.906254]\n",
      " [1.906254]\n",
      " [1.906254]\n",
      " [1.906254]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 310/10000 Loss (MSE):  train=2.033993721008301\n",
      "Epoch: 320/10000 Loss (MSE):  train=2.0253608226776123\n",
      "Epoch: 330/10000 Loss (MSE):  train=2.017561912536621\n",
      "Epoch: 340/10000 Loss (MSE):  train=2.010529041290283\n",
      "Epoch: 350/10000 Loss (MSE):  train=2.0041940212249756\n",
      "Epoch: 360/10000 Loss (MSE):  train=1.9984893798828125\n",
      "Epoch: 370/10000 Loss (MSE):  train=1.9933435916900635\n",
      "Epoch: 380/10000 Loss (MSE):  train=1.9886970520019531\n",
      "Epoch: 390/10000 Loss (MSE):  train=1.9844852685928345\n",
      "Epoch: 400/10000 Loss (MSE):  train=1.9806509017944336\n",
      "gammaaaaa:  [[1.795408 ]\n",
      " [1.795408 ]\n",
      " [1.795408 ]\n",
      " [1.6456095]\n",
      " [1.6456095]\n",
      " [1.6456095]\n",
      " [1.6456095]\n",
      " [1.6456095]\n",
      " [1.6456095]\n",
      " [1.6456095]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 410/10000 Loss (MSE):  train=1.9771431684494019\n",
      "Epoch: 420/10000 Loss (MSE):  train=1.973908543586731\n",
      "Epoch: 430/10000 Loss (MSE):  train=1.9709126949310303\n",
      "Epoch: 440/10000 Loss (MSE):  train=1.9681107997894287\n",
      "Epoch: 450/10000 Loss (MSE):  train=1.9654772281646729\n",
      "Epoch: 460/10000 Loss (MSE):  train=1.9629848003387451\n",
      "Epoch: 470/10000 Loss (MSE):  train=1.9606044292449951\n",
      "Epoch: 480/10000 Loss (MSE):  train=1.958321213722229\n",
      "Epoch: 490/10000 Loss (MSE):  train=1.9561243057250977\n",
      "Epoch: 500/10000 Loss (MSE):  train=1.9539902210235596\n",
      "gammaaaaa:  [[1.5687137]\n",
      " [1.5687137]\n",
      " [1.5687137]\n",
      " [1.585724 ]\n",
      " [1.585724 ]\n",
      " [1.585724 ]\n",
      " [1.585724 ]\n",
      " [1.585724 ]\n",
      " [1.585724 ]\n",
      " [1.585724 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 510/10000 Loss (MSE):  train=1.9519182443618774\n",
      "Epoch: 520/10000 Loss (MSE):  train=1.9498900175094604\n",
      "Epoch: 530/10000 Loss (MSE):  train=1.9479014873504639\n",
      "Epoch: 540/10000 Loss (MSE):  train=1.9459370374679565\n",
      "Epoch: 550/10000 Loss (MSE):  train=1.9439972639083862\n",
      "Epoch: 560/10000 Loss (MSE):  train=1.9420626163482666\n",
      "Epoch: 570/10000 Loss (MSE):  train=1.9401309490203857\n",
      "Epoch: 580/10000 Loss (MSE):  train=1.938184380531311\n",
      "Epoch: 590/10000 Loss (MSE):  train=1.936214804649353\n",
      "Epoch: 600/10000 Loss (MSE):  train=1.9342103004455566\n",
      "gammaaaaa:  [[1.4349942]\n",
      " [1.4349942]\n",
      " [1.4349942]\n",
      " [1.6150094]\n",
      " [1.6150094]\n",
      " [1.6150094]\n",
      " [1.6150094]\n",
      " [1.6150094]\n",
      " [1.6150094]\n",
      " [1.6150094]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 610/10000 Loss (MSE):  train=1.9321547746658325\n",
      "Epoch: 620/10000 Loss (MSE):  train=1.930044412612915\n",
      "Epoch: 630/10000 Loss (MSE):  train=1.9278684854507446\n",
      "Epoch: 640/10000 Loss (MSE):  train=1.9256173372268677\n",
      "Epoch: 650/10000 Loss (MSE):  train=1.9232877492904663\n",
      "Epoch: 660/10000 Loss (MSE):  train=1.9208778142929077\n",
      "Epoch: 670/10000 Loss (MSE):  train=1.9183870553970337\n",
      "Epoch: 680/10000 Loss (MSE):  train=1.9158151149749756\n",
      "Epoch: 690/10000 Loss (MSE):  train=1.9131628274917603\n",
      "Epoch: 700/10000 Loss (MSE):  train=1.9104266166687012\n",
      "gammaaaaa:  [[1.3289458]\n",
      " [1.3289458]\n",
      " [1.3289458]\n",
      " [1.6687217]\n",
      " [1.6687217]\n",
      " [1.6687217]\n",
      " [1.6687217]\n",
      " [1.6687217]\n",
      " [1.6687217]\n",
      " [1.6687217]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 710/10000 Loss (MSE):  train=1.907602310180664\n",
      "Epoch: 720/10000 Loss (MSE):  train=1.9046897888183594\n",
      "Epoch: 730/10000 Loss (MSE):  train=1.90169095993042\n",
      "Epoch: 740/10000 Loss (MSE):  train=1.8986026048660278\n",
      "Epoch: 750/10000 Loss (MSE):  train=1.895439624786377\n",
      "Epoch: 760/10000 Loss (MSE):  train=1.8922086954116821\n",
      "Epoch: 770/10000 Loss (MSE):  train=1.888918399810791\n",
      "Epoch: 780/10000 Loss (MSE):  train=1.885582447052002\n",
      "Epoch: 790/10000 Loss (MSE):  train=1.8821971416473389\n",
      "Epoch: 800/10000 Loss (MSE):  train=1.8787692785263062\n",
      "gammaaaaa:  [[1.2302016]\n",
      " [1.2302016]\n",
      " [1.2302016]\n",
      " [1.7232543]\n",
      " [1.7232543]\n",
      " [1.7232543]\n",
      " [1.7232543]\n",
      " [1.7232543]\n",
      " [1.7232544]\n",
      " [1.7232544]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 810/10000 Loss (MSE):  train=1.8752930164337158\n",
      "Epoch: 820/10000 Loss (MSE):  train=1.8717573881149292\n",
      "Epoch: 830/10000 Loss (MSE):  train=1.8681435585021973\n",
      "Epoch: 840/10000 Loss (MSE):  train=1.8644218444824219\n",
      "Epoch: 850/10000 Loss (MSE):  train=1.860543131828308\n",
      "Epoch: 860/10000 Loss (MSE):  train=1.8564351797103882\n",
      "Epoch: 870/10000 Loss (MSE):  train=1.8519659042358398\n",
      "Epoch: 880/10000 Loss (MSE):  train=1.8469210863113403\n",
      "Epoch: 890/10000 Loss (MSE):  train=1.8408751487731934\n",
      "Epoch: 900/10000 Loss (MSE):  train=1.8331305980682373\n",
      "gammaaaaa:  [[1.1409576]\n",
      " [1.1409576]\n",
      " [1.1409576]\n",
      " [1.7716467]\n",
      " [1.7716467]\n",
      " [1.7716467]\n",
      " [1.7716467]\n",
      " [1.7716467]\n",
      " [1.7716467]\n",
      " [1.7716467]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 910/10000 Loss (MSE):  train=1.823166847229004\n",
      "Epoch: 920/10000 Loss (MSE):  train=1.8121333122253418\n",
      "Epoch: 930/10000 Loss (MSE):  train=1.802118182182312\n",
      "Epoch: 940/10000 Loss (MSE):  train=1.794400691986084\n",
      "Epoch: 950/10000 Loss (MSE):  train=1.7893439531326294\n",
      "Epoch: 960/10000 Loss (MSE):  train=1.78652024269104\n",
      "Epoch: 970/10000 Loss (MSE):  train=1.7850905656814575\n",
      "Epoch: 980/10000 Loss (MSE):  train=1.7843194007873535\n",
      "Epoch: 990/10000 Loss (MSE):  train=1.7838072776794434\n",
      "Epoch: 1000/10000 Loss (MSE):  train=1.783400297164917\n",
      "gammaaaaa:  [[1.1028223]\n",
      " [1.1028223]\n",
      " [1.1028223]\n",
      " [1.8529668]\n",
      " [1.8529668]\n",
      " [1.8529668]\n",
      " [1.8529668]\n",
      " [1.8529668]\n",
      " [1.8529668]\n",
      " [1.8529668]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 1010/10000 Loss (MSE):  train=1.783037543296814\n",
      "Epoch: 1020/10000 Loss (MSE):  train=1.7827101945877075\n",
      "Epoch: 1030/10000 Loss (MSE):  train=1.7824039459228516\n",
      "Epoch: 1040/10000 Loss (MSE):  train=1.7821217775344849\n",
      "Epoch: 1050/10000 Loss (MSE):  train=1.7818561792373657\n",
      "Epoch: 1060/10000 Loss (MSE):  train=1.7816112041473389\n",
      "Epoch: 1070/10000 Loss (MSE):  train=1.7813825607299805\n",
      "Epoch: 1080/10000 Loss (MSE):  train=1.7811716794967651\n",
      "Epoch: 1090/10000 Loss (MSE):  train=1.7809782028198242\n",
      "Epoch: 1100/10000 Loss (MSE):  train=1.7807979583740234\n",
      "gammaaaaa:  [[1.0634977]\n",
      " [1.0634977]\n",
      " [1.0634977]\n",
      " [1.9113126]\n",
      " [1.9113126]\n",
      " [1.9113126]\n",
      " [1.9113126]\n",
      " [1.9113126]\n",
      " [1.9113126]\n",
      " [1.9113126]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 1110/10000 Loss (MSE):  train=1.7806313037872314\n",
      "Epoch: 1120/10000 Loss (MSE):  train=1.780480980873108\n",
      "Epoch: 1130/10000 Loss (MSE):  train=1.7803425788879395\n",
      "Epoch: 1140/10000 Loss (MSE):  train=1.7802129983901978\n",
      "Epoch: 1150/10000 Loss (MSE):  train=1.780099630355835\n",
      "Epoch: 1160/10000 Loss (MSE):  train=1.7799912691116333\n",
      "Epoch: 1170/10000 Loss (MSE):  train=1.7798950672149658\n",
      "Epoch: 1180/10000 Loss (MSE):  train=1.779807209968567\n",
      "Epoch: 1190/10000 Loss (MSE):  train=1.7797267436981201\n",
      "Epoch: 1200/10000 Loss (MSE):  train=1.7796521186828613\n",
      "gammaaaaa:  [[1.0336491]\n",
      " [1.0336491]\n",
      " [1.0336491]\n",
      " [1.9479684]\n",
      " [1.9479684]\n",
      " [1.9479684]\n",
      " [1.9479684]\n",
      " [1.9479684]\n",
      " [1.9479684]\n",
      " [1.9479684]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 1210/10000 Loss (MSE):  train=1.779584527015686\n",
      "Epoch: 1220/10000 Loss (MSE):  train=1.7795214653015137\n",
      "Epoch: 1230/10000 Loss (MSE):  train=1.7794697284698486\n",
      "Epoch: 1240/10000 Loss (MSE):  train=1.779416799545288\n",
      "Epoch: 1250/10000 Loss (MSE):  train=1.7793707847595215\n",
      "Epoch: 1260/10000 Loss (MSE):  train=1.7793278694152832\n",
      "Epoch: 1270/10000 Loss (MSE):  train=1.7792872190475464\n",
      "Epoch: 1280/10000 Loss (MSE):  train=1.7792503833770752\n",
      "Epoch: 1290/10000 Loss (MSE):  train=1.7792176008224487\n",
      "Epoch: 1300/10000 Loss (MSE):  train=1.7791855335235596\n",
      "gammaaaaa:  [[1.0167756]\n",
      " [1.0167756]\n",
      " [1.0167756]\n",
      " [1.9695781]\n",
      " [1.9695781]\n",
      " [1.9695781]\n",
      " [1.9695781]\n",
      " [1.9695781]\n",
      " [1.9695778]\n",
      " [1.9695778]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 1310/10000 Loss (MSE):  train=1.7791557312011719\n",
      "Epoch: 1320/10000 Loss (MSE):  train=1.7791292667388916\n",
      "Epoch: 1330/10000 Loss (MSE):  train=1.7791026830673218\n",
      "Epoch: 1340/10000 Loss (MSE):  train=1.7790793180465698\n",
      "Epoch: 1350/10000 Loss (MSE):  train=1.779055118560791\n",
      "Epoch: 1360/10000 Loss (MSE):  train=1.779032588005066\n",
      "Epoch: 1370/10000 Loss (MSE):  train=1.7790117263793945\n",
      "Epoch: 1380/10000 Loss (MSE):  train=1.7789905071258545\n",
      "Epoch: 1390/10000 Loss (MSE):  train=1.7789719104766846\n",
      "Epoch: 1400/10000 Loss (MSE):  train=1.7789525985717773\n",
      "gammaaaaa:  [[1.0088606]\n",
      " [1.0088606]\n",
      " [1.0088606]\n",
      " [1.9799626]\n",
      " [1.9799626]\n",
      " [1.9799626]\n",
      " [1.9799626]\n",
      " [1.9799626]\n",
      " [1.9799625]\n",
      " [1.9799625]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 1410/10000 Loss (MSE):  train=1.7789350748062134\n",
      "Epoch: 1420/10000 Loss (MSE):  train=1.7789162397384644\n",
      "Epoch: 1430/10000 Loss (MSE):  train=1.7788995504379272\n",
      "Epoch: 1440/10000 Loss (MSE):  train=1.778883934020996\n",
      "Epoch: 1450/10000 Loss (MSE):  train=1.7788678407669067\n",
      "Epoch: 1460/10000 Loss (MSE):  train=1.7788525819778442\n",
      "Epoch: 1470/10000 Loss (MSE):  train=1.7788366079330444\n",
      "Epoch: 1480/10000 Loss (MSE):  train=1.7788208723068237\n",
      "Epoch: 1490/10000 Loss (MSE):  train=1.7788045406341553\n",
      "Epoch: 1500/10000 Loss (MSE):  train=1.778787612915039\n",
      "gammaaaaa:  [[1.0058287]\n",
      " [1.0058287]\n",
      " [1.0058287]\n",
      " [1.9840064]\n",
      " [1.9840064]\n",
      " [1.9840064]\n",
      " [1.9840064]\n",
      " [1.9840064]\n",
      " [1.9840064]\n",
      " [1.9840064]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 1510/10000 Loss (MSE):  train=1.7787716388702393\n",
      "Epoch: 1520/10000 Loss (MSE):  train=1.7787590026855469\n",
      "Epoch: 1530/10000 Loss (MSE):  train=1.7787442207336426\n",
      "Epoch: 1540/10000 Loss (MSE):  train=1.7787301540374756\n",
      "Epoch: 1550/10000 Loss (MSE):  train=1.7787165641784668\n",
      "Epoch: 1560/10000 Loss (MSE):  train=1.778702974319458\n",
      "Epoch: 1570/10000 Loss (MSE):  train=1.778689980506897\n",
      "Epoch: 1580/10000 Loss (MSE):  train=1.77867591381073\n",
      "Epoch: 1590/10000 Loss (MSE):  train=1.7786632776260376\n",
      "Epoch: 1600/10000 Loss (MSE):  train=1.7786500453948975\n",
      "gammaaaaa:  [[1.0048678]\n",
      " [1.0048678]\n",
      " [1.0048678]\n",
      " [1.9853003]\n",
      " [1.9853003]\n",
      " [1.9853003]\n",
      " [1.9853003]\n",
      " [1.9853003]\n",
      " [1.9853005]\n",
      " [1.9853005]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 1610/10000 Loss (MSE):  train=1.778637170791626\n",
      "Epoch: 1620/10000 Loss (MSE):  train=1.7786223888397217\n",
      "Epoch: 1630/10000 Loss (MSE):  train=1.778609275817871\n",
      "Epoch: 1640/10000 Loss (MSE):  train=1.7785956859588623\n",
      "Epoch: 1650/10000 Loss (MSE):  train=1.7785836458206177\n",
      "Epoch: 1660/10000 Loss (MSE):  train=1.7785700559616089\n",
      "Epoch: 1670/10000 Loss (MSE):  train=1.778557538986206\n",
      "Epoch: 1680/10000 Loss (MSE):  train=1.7785441875457764\n",
      "Epoch: 1690/10000 Loss (MSE):  train=1.7785314321517944\n",
      "Epoch: 1700/10000 Loss (MSE):  train=1.7785168886184692\n",
      "gammaaaaa:  [[1.0045804]\n",
      " [1.0045804]\n",
      " [1.0045804]\n",
      " [1.9856629]\n",
      " [1.9856629]\n",
      " [1.9856629]\n",
      " [1.9856629]\n",
      " [1.9856629]\n",
      " [1.9856632]\n",
      " [1.9856632]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 1710/10000 Loss (MSE):  train=1.7785027027130127\n",
      "Epoch: 1720/10000 Loss (MSE):  train=1.7784910202026367\n",
      "Epoch: 1730/10000 Loss (MSE):  train=1.7784764766693115\n",
      "Epoch: 1740/10000 Loss (MSE):  train=1.778463363647461\n",
      "Epoch: 1750/10000 Loss (MSE):  train=1.7784497737884521\n",
      "Epoch: 1760/10000 Loss (MSE):  train=1.7784373760223389\n",
      "Epoch: 1770/10000 Loss (MSE):  train=1.7784231901168823\n",
      "Epoch: 1780/10000 Loss (MSE):  train=1.7784087657928467\n",
      "Epoch: 1790/10000 Loss (MSE):  train=1.778395652770996\n",
      "Epoch: 1800/10000 Loss (MSE):  train=1.7783820629119873\n",
      "gammaaaaa:  [[1.0044628]\n",
      " [1.0044628]\n",
      " [1.0044628]\n",
      " [1.9857502]\n",
      " [1.9857502]\n",
      " [1.9857502]\n",
      " [1.9857502]\n",
      " [1.9857502]\n",
      " [1.9857502]\n",
      " [1.9857502]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/training_loss.png ===\n",
      "Epoch: 1810/10000 Loss (MSE):  train=1.7783679962158203\n",
      "Epoch: 1820/10000 Loss (MSE):  train=1.7783548831939697\n",
      "Epoch: 1830/10000 Loss (MSE):  train=1.7783399820327759\n",
      "Epoch: 1840/10000 Loss (MSE):  train=1.7783265113830566\n",
      "Epoch: 1850/10000 Loss (MSE):  train=1.7783128023147583\n",
      "Epoch: 1860/10000 Loss (MSE):  train=1.778297781944275\n",
      "Epoch: 1870/10000 Loss (MSE):  train=1.7782835960388184\n",
      "Epoch: 1880/10000 Loss (MSE):  train=1.7782676219940186\n",
      "Epoch: 1890/10000 Loss (MSE):  train=1.778252124786377\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(bRs_in, bRs_out):\n\u001b[1;32m     66\u001b[0m     optimizer_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 67\u001b[0m     opt_state, params, l_ \u001b[39m=\u001b[39m step(\n\u001b[1;32m     68\u001b[0m         optimizer_step, (opt_state, params, \u001b[39m0\u001b[39;49m), \u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m     69\u001b[0m     l \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m l_\n\u001b[1;32m     70\u001b[0m     count\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/GitHub/BGNODE_scratch/.venv_jaxbrow/lib/python3.9/site-packages/jax/example_libraries/optimizers.py:120\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(data, xs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m# The implementation here basically works by flattening pytrees. There are two\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m# levels of pytrees to think about: the pytree of params, which we can think of\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m# as defining an \"outer pytree\", and a pytree produced by applying init_fun to\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m# each leaf of the params pytree, which we can think of as the \"inner pytrees\".\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m# Since pytrees can be flattened, that structure is isomorphic to a list of\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m# lists (with no further nesting).\u001b[39;00m\n\u001b[1;32m    115\u001b[0m OptimizerState \u001b[39m=\u001b[39m namedtuple(\u001b[39m\"\u001b[39m\u001b[39mOptimizerState\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m                             [\u001b[39m\"\u001b[39m\u001b[39mpacked_state\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtree_def\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msubtree_defs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    117\u001b[0m register_pytree_node(\n\u001b[1;32m    118\u001b[0m     OptimizerState,\n\u001b[1;32m    119\u001b[0m     \u001b[39mlambda\u001b[39;00m xs: ((xs\u001b[39m.\u001b[39mpacked_state,), (xs\u001b[39m.\u001b[39mtree_def, xs\u001b[39m.\u001b[39msubtree_defs)),\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mlambda\u001b[39;00m data, xs: OptimizerState(xs[\u001b[39m0\u001b[39m], data[\u001b[39m0\u001b[39m], data[\u001b[39m1\u001b[39m]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m    123\u001b[0m Array \u001b[39m=\u001b[39m Any\n\u001b[1;32m    124\u001b[0m Params \u001b[39m=\u001b[39m Any  \u001b[39m# Parameters are arbitrary nests of `jnp.ndarrays`.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def loss_fn(params, Rs, Rs_1_ac,A=1, B=500): # A=4, B=996 wf=0.996):\n",
    "    Rs_1_pred, gamma = v_v_next_step_pos_gamma_fn(Rs, params)\n",
    "    var = 1/gamma\n",
    "    return GaussianNLL(var, Rs_1_pred, Rs_1_ac, A, B)\n",
    "\n",
    "def gloss(*args):\n",
    "    return value_and_grad(loss_fn)(*args)\n",
    "\n",
    "def update(i, opt_state, params, loss__, *data):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads_ = gloss(params, *data)\n",
    "    opt_state = opt_update(i, grads_, opt_state)\n",
    "    return opt_state, get_params(opt_state), value\n",
    "\n",
    "@jit\n",
    "def step(i, ps, *args):\n",
    "    return update(i, *ps, *args)\n",
    "\n",
    "opt_init, opt_update_, get_params = optimizers.adam(lr)\n",
    "\n",
    "@jit\n",
    "def opt_update(i, grads_, opt_state):\n",
    "    grads_ = jax.tree_map(jnp.nan_to_num, grads_)\n",
    "    grads_ = jax.tree_map(partial(jnp.clip, a_min=-1000.0, a_max=1000.0), grads_)\n",
    "    return opt_update_(i, grads_, opt_state)\n",
    "\n",
    "def batching(*args, size=None):\n",
    "    L = len(args[0])\n",
    "    if size != None:\n",
    "        nbatches1 = int((L - 0.5) // size) + 1\n",
    "        nbatches2 = max(1, nbatches1 - 1)\n",
    "        size1 = int(L/nbatches1)\n",
    "        size2 = int(L/nbatches2)\n",
    "        if size1*nbatches1 > size2*nbatches2:\n",
    "            size = size1\n",
    "            nbatches = nbatches1\n",
    "        else:\n",
    "            size = size2\n",
    "            nbatches = nbatches2\n",
    "    else:\n",
    "        nbatches = 1\n",
    "        size = L\n",
    "    \n",
    "    newargs = []\n",
    "    for arg in args:\n",
    "        newargs += [jnp.array([arg[i*size:(i+1)*size]\n",
    "                                for i in range(nbatches)])]\n",
    "    return newargs\n",
    "\n",
    "bRs_in, bRs_out = batching(Rs_in, Rs_out, size=min(len(Rs_in), batch_size))\n",
    "\n",
    "print(f\"training ...\")\n",
    "\n",
    "opt_state = opt_init(params)\n",
    "epoch = 0\n",
    "optimizer_step = -1\n",
    "larray = []\n",
    "ltarray = []\n",
    "last_loss = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    l = 0.0\n",
    "    count = 0\n",
    "    for data in zip(bRs_in, bRs_out):\n",
    "        optimizer_step += 1\n",
    "        opt_state, params, l_ = step(\n",
    "            optimizer_step, (opt_state, params, 0), *data)\n",
    "        l += l_\n",
    "        count+=1\n",
    "    # print(\"epoch,countttttt: \", epoch,count)\n",
    "    # opt_state, params, l_ = step(optimizer_step, (opt_state, params, 0), Rs, Vs, Fs)\n",
    "    l = l/count\n",
    "    larray += [l]\n",
    "    # ltarray += [loss_fn(params, bRs_in, bVs_in, bRs_out)]\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}/{epochs} Loss (MSE):  train={larray[-1]}\")#, test={ltarray[-1]}\")\n",
    "    if epoch % 100 == 0:\n",
    "        print('gammaaaaa: ', gamma_fn_model(params))\n",
    "        metadata = {\n",
    "            \"savedat\": epoch,\n",
    "            # \"mpass\": mpass,\n",
    "            }\n",
    "        savefile(f\"fgnode_trained_model.dil\",\n",
    "                    params, metadata=metadata)\n",
    "        # savefile(f\"loss_array.dil\", (larray, ltarray), metadata=metadata)\n",
    "        savefile(f\"loss_array.dil\", larray, metadata=metadata)\n",
    "        if last_loss > larray[-1]:\n",
    "            last_loss = larray[-1]\n",
    "            savefile(f\"fgnode_trained_model_low.dil\",\n",
    "                        params, metadata=metadata)\n",
    "        fig, axs = panel(1, 1)\n",
    "        # plt.semilogy(larray, label=\"Training\")\n",
    "        plt.plot(larray, label=\"Training\")\n",
    "        # plt.semilogy(ltarray, label=\"Test\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(_filename(f\"training_loss.png\"))\n",
    "\n",
    "fig, axs = panel(1, 1)\n",
    "# plt.semilogy(larray, label=\"Training\")\n",
    "plt.plot(larray, label=\"Training\")\n",
    "# plt.semilogy(ltarray, label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(_filename(f\"training_loss.png\"))\n",
    "\n",
    "params = get_params(opt_state)\n",
    "savefile(f\"fgnode_trained_model.dil\", params, metadata=metadata)\n",
    "# savefile(f\"loss_array.dil\", (larray, ltarray), metadata=metadata)\n",
    "\n",
    "if last_loss > larray[-1]:\n",
    "    last_loss = larray[-1]\n",
    "    savefile(f\"fgnode_trained_model_low.dil\", params, metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rname=False\n",
    "\n",
    "# PSYS = f\"a-{N}-Spring-data-brownian_EM\"\n",
    "# TAG = f\"4BDGNN\"\n",
    "# out_dir = f\"../results\"\n",
    "\n",
    "def _filename(name, tag=TAG):\n",
    "    rstring = randfilename if (rname and (tag != \"data\")) else (\n",
    "        \"0\" if (tag == \"data\") or (withdata == None) else f\"0_{withdata}\")\n",
    "    filename_prefix = f\"{out_dir}/{PSYS}-{tag}/{rstring}/\"\n",
    "    file = f\"{filename_prefix}/{name}\"\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    filename = f\"{filename_prefix}/{name}\".replace(\"//\", \"/\")\n",
    "    print(\"===\", filename, \"===\")\n",
    "    return filename\n",
    "\n",
    "def OUT(f):\n",
    "    @wraps(f)\n",
    "    def func(file, *args, tag=TAG, **kwargs):\n",
    "        return f(_filename(file, tag=tag), *args, **kwargs)\n",
    "    return func\n",
    "\n",
    "loadmodel = OUT(src.models.loadmodel)\n",
    "savemodel = OUT(src.models.savemodel)\n",
    "\n",
    "loadfile = OUT(src.io.loadfile)\n",
    "savefile = OUT(src.io.savefile)\n",
    "save_ovito = OUT(src.io.save_ovito)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil ===\n",
      "Loading ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/fgnode_trained_model_low.dil\n"
     ]
    }
   ],
   "source": [
    "params, _ = loadfile(f\"fgnode_trained_model_low.dil\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.0044628],\n",
       "       [1.0044628],\n",
       "       [1.0044628],\n",
       "       [1.9857502],\n",
       "       [1.9857502],\n",
       "       [1.9857502],\n",
       "       [1.9857502],\n",
       "       [1.9857502],\n",
       "       [1.9857502],\n",
       "       [1.9857502]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_fn_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_constant = 1.0\n",
    "length_constant = 1.0\n",
    "# gamma_orig = jnp.ones(jnp.unique(species).shape)\n",
    "gamma_orig = jnp.where(jnp.arange(N) <3, 1.0, 2.0).reshape(-1,1)\n",
    "stride = 1\n",
    "runs=100\n",
    "\n",
    "def SPRING(x, stiffness=1.0, length=1.0):\n",
    "    x_ = jnp.linalg.norm(x, keepdims=True)\n",
    "    return 0.5*stiffness*(x_ - length)**2\n",
    "\n",
    "def pot_energy_orig(x):\n",
    "    dr = x[senders, :] - x[receivers, :]\n",
    "    return vmap(partial(SPRING, stiffness=spring_constant, length=length_constant))(dr).sum()\n",
    "\n",
    "def force_fn_orig(R, params):\n",
    "    return -grad(pot_energy_orig)(R)\n",
    "\n",
    "\n",
    "def get_forward_sim(params = None, force_fn = None, gamma = None, runs=10):\n",
    "        @jit\n",
    "        def fn(R,key):\n",
    "            return predition_brow(R, params, force_fn, shift, dt, kT, masses, gamma = gamma, stride=stride, runs=runs, key=key)\n",
    "        return fn\n",
    "\n",
    "sim_orig = get_forward_sim(params=None,force_fn=force_fn_orig, gamma=gamma_orig,runs=runs)\n",
    "\n",
    "gamma_model = gamma_fn_model(params)\n",
    "sim_model = get_forward_sim(params=params,force_fn=force_fn_model, gamma=gamma_model,runs=runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating trajectory 0/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/actual_0_0.xyz ===\n",
      "Saving ovito file: ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/actual_0_0.xyz\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/pred_0_0.xyz ===\n",
      "Saving ovito file: ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/pred_0_0.xyz\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "Simulating trajectory 1/100 ...\n",
      "Simulating trajectory 2/100 ...\n",
      "Simulating trajectory 3/100 ...\n",
      "Simulating trajectory 4/100 ...\n",
      "Simulating trajectory 5/100 ...\n",
      "Simulating trajectory 6/100 ...\n",
      "Simulating trajectory 7/100 ...\n",
      "Simulating trajectory 8/100 ...\n",
      "Simulating trajectory 9/100 ...\n",
      "Simulating trajectory 10/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "Simulating trajectory 11/100 ...\n",
      "Simulating trajectory 12/100 ...\n",
      "Simulating trajectory 13/100 ...\n",
      "Simulating trajectory 14/100 ...\n",
      "Simulating trajectory 15/100 ...\n",
      "Simulating trajectory 16/100 ...\n",
      "Simulating trajectory 17/100 ...\n",
      "Simulating trajectory 18/100 ...\n",
      "Simulating trajectory 19/100 ...\n",
      "Simulating trajectory 20/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "Simulating trajectory 21/100 ...\n",
      "Simulating trajectory 22/100 ...\n",
      "Simulating trajectory 23/100 ...\n",
      "Simulating trajectory 24/100 ...\n",
      "Simulating trajectory 25/100 ...\n",
      "Simulating trajectory 26/100 ...\n",
      "Simulating trajectory 27/100 ...\n",
      "Simulating trajectory 28/100 ...\n",
      "Simulating trajectory 29/100 ...\n",
      "Simulating trajectory 30/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "Simulating trajectory 31/100 ...\n",
      "Simulating trajectory 32/100 ...\n",
      "Simulating trajectory 33/100 ...\n",
      "Simulating trajectory 34/100 ...\n",
      "Simulating trajectory 35/100 ...\n",
      "Simulating trajectory 36/100 ...\n",
      "Simulating trajectory 37/100 ...\n",
      "Simulating trajectory 38/100 ...\n",
      "Simulating trajectory 39/100 ...\n",
      "Simulating trajectory 40/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "Simulating trajectory 41/100 ...\n",
      "Simulating trajectory 42/100 ...\n",
      "Simulating trajectory 43/100 ...\n",
      "Simulating trajectory 44/100 ...\n",
      "Simulating trajectory 45/100 ...\n",
      "Simulating trajectory 46/100 ...\n",
      "Simulating trajectory 47/100 ...\n",
      "Simulating trajectory 48/100 ...\n",
      "Simulating trajectory 49/100 ...\n",
      "Simulating trajectory 50/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "Simulating trajectory 51/100 ...\n",
      "Simulating trajectory 52/100 ...\n",
      "Simulating trajectory 53/100 ...\n",
      "Simulating trajectory 54/100 ...\n",
      "Simulating trajectory 55/100 ...\n",
      "Simulating trajectory 56/100 ...\n",
      "Simulating trajectory 57/100 ...\n",
      "Simulating trajectory 58/100 ...\n",
      "Simulating trajectory 59/100 ...\n",
      "Simulating trajectory 60/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "Simulating trajectory 61/100 ...\n",
      "Simulating trajectory 62/100 ...\n",
      "Simulating trajectory 63/100 ...\n",
      "Simulating trajectory 64/100 ...\n",
      "Simulating trajectory 65/100 ...\n",
      "Simulating trajectory 66/100 ...\n",
      "Simulating trajectory 67/100 ...\n",
      "Simulating trajectory 68/100 ...\n",
      "Simulating trajectory 69/100 ...\n",
      "Simulating trajectory 70/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "Simulating trajectory 71/100 ...\n",
      "Simulating trajectory 72/100 ...\n",
      "Simulating trajectory 73/100 ...\n",
      "Simulating trajectory 74/100 ...\n",
      "Simulating trajectory 75/100 ...\n",
      "Simulating trajectory 76/100 ...\n",
      "Simulating trajectory 77/100 ...\n",
      "Simulating trajectory 78/100 ...\n",
      "Simulating trajectory 79/100 ...\n",
      "Simulating trajectory 80/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "Simulating trajectory 81/100 ...\n",
      "Simulating trajectory 82/100 ...\n",
      "Simulating trajectory 83/100 ...\n",
      "Simulating trajectory 84/100 ...\n",
      "Simulating trajectory 85/100 ...\n",
      "Simulating trajectory 86/100 ...\n",
      "Simulating trajectory 87/100 ...\n",
      "Simulating trajectory 88/100 ...\n",
      "Simulating trajectory 89/100 ...\n",
      "Simulating trajectory 90/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n",
      "Simulating trajectory 91/100 ...\n",
      "Simulating trajectory 92/100 ...\n",
      "Simulating trajectory 93/100 ...\n",
      "Simulating trajectory 94/100 ...\n",
      "Simulating trajectory 95/100 ...\n",
      "Simulating trajectory 96/100 ...\n",
      "Simulating trajectory 97/100 ...\n",
      "Simulating trajectory 98/100 ...\n",
      "Simulating trajectory 99/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/error_parameter.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-4BDGNN/0/trajectories.pkl ===\n"
     ]
    }
   ],
   "source": [
    "plotthings = True\n",
    "rng_key = random.PRNGKey(0)\n",
    "maxtraj = 100\n",
    "\n",
    "_gamma = gamma_fn_model(params)\n",
    "nexp = {\n",
    "        \"dz_actual\": [],\n",
    "        \"dz_pred\": [],\n",
    "        \"z_actual\": [],\n",
    "        \"z_pred\": [],\n",
    "        \"_gamma\": [_gamma]\n",
    "        }\n",
    "\n",
    "trajectories = []\n",
    "for ind in range(maxtraj):\n",
    "    print(f\"Simulating trajectory {ind}/{maxtraj} ...\")\n",
    "    R, _ = chain(N)[:2]\n",
    "    for rand in range(10):\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        actual_traj = sim_orig(R,(ind+13)*subkey)\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        pred_traj = sim_model(R, (ind+13)*subkey)\n",
    "        \n",
    "        nexp[\"dz_actual\"] += [actual_traj.position-R]\n",
    "        nexp[\"dz_pred\"] += [pred_traj.position-R]\n",
    "        \n",
    "        nexp[\"z_actual\"] += [actual_traj.position]\n",
    "        nexp[\"z_pred\"] += [pred_traj.position]\n",
    "        \n",
    "        if save_ovito:\n",
    "            if ind<1 and rand<1:\n",
    "                save_ovito(f\"actual_{ind}_{rand}.xyz\", [state for state in BrownianStates(actual_traj)], lattice=\"\")\n",
    "                save_ovito(f\"pred_{ind}_{rand}.xyz\", [state for state in BrownianStates(pred_traj)], lattice=\"\")\n",
    "        \n",
    "        trajectories += [(actual_traj, pred_traj)]\n",
    "        if ind%10==0:\n",
    "            savefile(\"trajectories.pkl\", trajectories)\n",
    "\n",
    "savefile(f\"error_parameter.pkl\", nexp)\n",
    "savefile(\"trajectories.pkl\", trajectories)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_jaxbrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
