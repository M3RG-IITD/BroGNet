{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## IMPORT ######################\n",
    "import json\n",
    "from datetime import datetime\n",
    "from functools import partial, wraps\n",
    "\n",
    "import fire\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import jit, random, value_and_grad, vmap\n",
    "# from jax.experimental import optimizers\n",
    "from jax.example_libraries import optimizers\n",
    "from jax_md import space\n",
    "from shadow.plot import *\n",
    "from sklearn.metrics import r2_score\n",
    "from psystems.nsprings import (chain, edge_order, get_connections,\n",
    "                               get_fully_connected_senders_and_receivers,\n",
    "                               get_fully_edge_order)\n",
    "# from statistics import mode\n",
    "# from sympy import LM\n",
    "# from torch import batch_norm_gather_stats_with_counts\n",
    "import sys\n",
    "MAINPATH = \"..\"  # nopep8\n",
    "sys.path.append(MAINPATH)  # nopep8\n",
    "import jraph\n",
    "import src\n",
    "from jax.config import config\n",
    "# from src import fgn, lnn\n",
    "from src.graph import *\n",
    "# from src.lnn import acceleration, accelerationFull, accelerationTV\n",
    "from src.md import *\n",
    "from src.models import MSE, initialize_mlp, GaussianNLL, initialize_mlp_gamma, forward_pass_gamma\n",
    "from src.nve import NVEStates, nve, BrownianStates\n",
    "from src.utils import *\n",
    "\n",
    "# config.update(\"jax_enable_x64\", True)\n",
    "# config.update(\"jax_debug_nans\", True)\n",
    "# jax.config.update('jax_platform_name', 'gpu')\n",
    "\n",
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "\n",
    "def pprint(*args, namespace=globals()):\n",
    "    for arg in args:\n",
    "        print(f\"{namestr(arg, namespace)[0]}: {arg}\")\n",
    "\n",
    "f32 = jnp.float32\n",
    "f64 = jnp.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs: \n",
      "N: 5\n",
      "epochs: 10000\n",
      "seed: 42\n",
      "rname: True\n",
      "dt: 0.001\n",
      "lr: 0.0001\n",
      "batch_size: 20\n"
     ]
    }
   ],
   "source": [
    "N = 5  # number of particles\n",
    "dim = 2  # dimensions\n",
    "runs = 1\n",
    "kT = 1 #1.380649e-23*T  # boltzmann constant*temperature\n",
    "# spring_constant = 1.0\n",
    "# length_constant = 1.0\n",
    "# nconfig=100\n",
    "seed=42\n",
    "dt = 1.0e-3 # time step*stride \n",
    "lr=1e-4\n",
    "batch_size=20\n",
    "epochs = 10000\n",
    "# node_type = jnp.array([0,0,0,0,0])\n",
    "masses = jnp.ones(N)\n",
    "species = jnp.zeros(N, dtype=int).reshape(-1,1)\n",
    "# gamma = jnp.ones(jnp.unique(species).shape)  # damping constant\n",
    "\n",
    "rname=True\n",
    "withdata = None\n",
    "\n",
    "print(\"Configs: \")\n",
    "pprint(N, epochs, seed, rname, dt, lr, batch_size, namespace=locals())\n",
    "\n",
    "randfilename = datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "\n",
    "PSYS = f\"a-{N}-Spring-data-brownian_EM\"\n",
    "TAG = f\"1NN\"\n",
    "out_dir = f\"../results\"\n",
    "\n",
    "def _filename(name, tag=TAG):\n",
    "    rstring = randfilename if (rname and (tag != \"data\")) else (\n",
    "        \"0\" if (tag == \"data\") or (withdata == None) else f\"0_{withdata}\")\n",
    "    filename_prefix = f\"{out_dir}/{PSYS}-{tag}/{rstring}/\"\n",
    "    file = f\"{filename_prefix}/{name}\"\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    filename = f\"{filename_prefix}/{name}\".replace(\"//\", \"/\")\n",
    "    print(\"===\", filename, \"===\")\n",
    "    return filename\n",
    "\n",
    "def displacement(a, b):\n",
    "    return a - b\n",
    "\n",
    "def shift(R, dR):\n",
    "    return R+dR\n",
    "\n",
    "def OUT(f):\n",
    "    @wraps(f)\n",
    "    def func(file, *args, tag=TAG, **kwargs):\n",
    "        return f(_filename(file, tag=tag), *args, **kwargs)\n",
    "    return func\n",
    "\n",
    "loadmodel = OUT(src.models.loadmodel)\n",
    "savemodel = OUT(src.models.savemodel)\n",
    "\n",
    "loadfile = OUT(src.io.loadfile)\n",
    "savefile = OUT(src.io.savefile)\n",
    "save_ovito = OUT(src.io.save_ovito)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../results/a-5-Spring-data-brownian_EM-data/0/model_states_brownian.pkl ===\n",
      "Total number of data points: 100x100\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "################## CONFIG ######################\n",
    "################################################\n",
    "np.random.seed(seed)\n",
    "key = random.PRNGKey(seed)\n",
    "\n",
    "try:\n",
    "    dataset_states = loadfile(f\"model_states_brownian.pkl\", tag=\"data\")[0]\n",
    "except:\n",
    "    raise Exception(\"Generate dataset first.\")\n",
    "\n",
    "model_states = dataset_states[0]\n",
    "\n",
    "print(f\"Total number of data points: {len(dataset_states)}x{model_states.position.shape[0]}\")\n",
    "\n",
    "Rs = States_Brow().fromlist(dataset_states).get_array()\n",
    "\n",
    "Rs_in = Rs[:,:99,:,:]\n",
    "Rs_out = Rs[:,1:100,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################### ML Model ###################\n",
    "################################################\n",
    "# print(\"Creating Chain\")\n",
    "x, _, senders, receivers = chain(N)\n",
    "\n",
    "hidden = 16\n",
    "nhidden = 2\n",
    "\n",
    "def get_layers(in_, out_):\n",
    "    return [in_] + [hidden]*nhidden + [out_]\n",
    "\n",
    "def mlp(in_, out_, key, **kwargs):\n",
    "    return initialize_mlp(get_layers(in_, out_), key, **kwargs)\n",
    "\n",
    "params = {\"F_pos\": mlp(N*dim, N*dim, key)}\n",
    "\n",
    "def acceleration_node(x, params, **kwargs):\n",
    "    n,dim = x.shape\n",
    "    inp = x.flatten() #jnp.hstack([x.flatten(),v.flatten()])\n",
    "    out = forward_pass(params, inp)\n",
    "    return out.reshape(-1,dim)\n",
    "\n",
    "def _force_fn():    \n",
    "    def apply(R, params):\n",
    "        return acceleration_node(R, params)\n",
    "    return apply\n",
    "\n",
    "apply_fn = _force_fn()\n",
    "\n",
    "def next_step_fn_model(x, params): return apply_fn(x, params['F_pos'])\n",
    "v_next_step_fn_model = vmap(next_step_fn_model, in_axes=(0, None))\n",
    "v_v_next_step_fn_model = vmap(v_next_step_fn_model, in_axes=(0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.3587485 , -5.5219827 ],\n",
       "       [-0.16316819, -2.8957014 ],\n",
       "       [ 2.7990637 , -0.8542066 ],\n",
       "       [ 0.00590687, -0.661735  ],\n",
       "       [-1.1160023 , -2.2723567 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_step_fn_model(x, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "Epoch: 0/10000 Loss (MSE):  train=12.38925552368164\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 10/10000 Loss (MSE):  train=11.182730674743652\n",
      "Epoch: 20/10000 Loss (MSE):  train=10.11342716217041\n",
      "Epoch: 30/10000 Loss (MSE):  train=9.166768074035645\n",
      "Epoch: 40/10000 Loss (MSE):  train=8.324546813964844\n",
      "Epoch: 50/10000 Loss (MSE):  train=7.571939945220947\n",
      "Epoch: 60/10000 Loss (MSE):  train=6.896720886230469\n",
      "Epoch: 70/10000 Loss (MSE):  train=6.28859806060791\n",
      "Epoch: 80/10000 Loss (MSE):  train=5.738780975341797\n",
      "Epoch: 90/10000 Loss (MSE):  train=5.239773750305176\n",
      "Epoch: 100/10000 Loss (MSE):  train=4.785202503204346\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 110/10000 Loss (MSE):  train=4.36964225769043\n",
      "Epoch: 120/10000 Loss (MSE):  train=3.9885201454162598\n",
      "Epoch: 130/10000 Loss (MSE):  train=3.637991189956665\n",
      "Epoch: 140/10000 Loss (MSE):  train=3.3148770332336426\n",
      "Epoch: 150/10000 Loss (MSE):  train=3.016564130783081\n",
      "Epoch: 160/10000 Loss (MSE):  train=2.740963935852051\n",
      "Epoch: 170/10000 Loss (MSE):  train=2.486453056335449\n",
      "Epoch: 180/10000 Loss (MSE):  train=2.2518129348754883\n",
      "Epoch: 190/10000 Loss (MSE):  train=2.0361599922180176\n",
      "Epoch: 200/10000 Loss (MSE):  train=1.8388469219207764\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 210/10000 Loss (MSE):  train=1.659381628036499\n",
      "Epoch: 220/10000 Loss (MSE):  train=1.4973028898239136\n",
      "Epoch: 230/10000 Loss (MSE):  train=1.3520982265472412\n",
      "Epoch: 240/10000 Loss (MSE):  train=1.2231273651123047\n",
      "Epoch: 250/10000 Loss (MSE):  train=1.109581470489502\n",
      "Epoch: 260/10000 Loss (MSE):  train=1.0104894638061523\n",
      "Epoch: 270/10000 Loss (MSE):  train=0.9247363805770874\n",
      "Epoch: 280/10000 Loss (MSE):  train=0.8511080741882324\n",
      "Epoch: 290/10000 Loss (MSE):  train=0.788335919380188\n",
      "Epoch: 300/10000 Loss (MSE):  train=0.7351517677307129\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 310/10000 Loss (MSE):  train=0.6903239488601685\n",
      "Epoch: 320/10000 Loss (MSE):  train=0.6526877880096436\n",
      "Epoch: 330/10000 Loss (MSE):  train=0.6211704015731812\n",
      "Epoch: 340/10000 Loss (MSE):  train=0.5948025584220886\n",
      "Epoch: 350/10000 Loss (MSE):  train=0.5727249979972839\n",
      "Epoch: 360/10000 Loss (MSE):  train=0.5541878938674927\n",
      "Epoch: 370/10000 Loss (MSE):  train=0.5385484099388123\n",
      "Epoch: 380/10000 Loss (MSE):  train=0.5252615213394165\n",
      "Epoch: 390/10000 Loss (MSE):  train=0.5138720273971558\n",
      "Epoch: 400/10000 Loss (MSE):  train=0.5040042400360107\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 410/10000 Loss (MSE):  train=0.495350182056427\n",
      "Epoch: 420/10000 Loss (MSE):  train=0.48766130208969116\n",
      "Epoch: 430/10000 Loss (MSE):  train=0.48073795437812805\n",
      "Epoch: 440/10000 Loss (MSE):  train=0.4744219183921814\n",
      "Epoch: 450/10000 Loss (MSE):  train=0.4685875177383423\n",
      "Epoch: 460/10000 Loss (MSE):  train=0.46313655376434326\n",
      "Epoch: 470/10000 Loss (MSE):  train=0.457992821931839\n",
      "Epoch: 480/10000 Loss (MSE):  train=0.453096479177475\n",
      "Epoch: 490/10000 Loss (MSE):  train=0.44840145111083984\n",
      "Epoch: 500/10000 Loss (MSE):  train=0.44387295842170715\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 510/10000 Loss (MSE):  train=0.4394832253456116\n",
      "Epoch: 520/10000 Loss (MSE):  train=0.4352114498615265\n",
      "Epoch: 530/10000 Loss (MSE):  train=0.4310419261455536\n",
      "Epoch: 540/10000 Loss (MSE):  train=0.4269617199897766\n",
      "Epoch: 550/10000 Loss (MSE):  train=0.42296114563941956\n",
      "Epoch: 560/10000 Loss (MSE):  train=0.4190329313278198\n",
      "Epoch: 570/10000 Loss (MSE):  train=0.41517114639282227\n",
      "Epoch: 580/10000 Loss (MSE):  train=0.41137051582336426\n",
      "Epoch: 590/10000 Loss (MSE):  train=0.4076274335384369\n",
      "Epoch: 600/10000 Loss (MSE):  train=0.4039384722709656\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 610/10000 Loss (MSE):  train=0.4003005921840668\n",
      "Epoch: 620/10000 Loss (MSE):  train=0.39671167731285095\n",
      "Epoch: 630/10000 Loss (MSE):  train=0.3931695818901062\n",
      "Epoch: 640/10000 Loss (MSE):  train=0.38967230916023254\n",
      "Epoch: 650/10000 Loss (MSE):  train=0.3862181305885315\n",
      "Epoch: 660/10000 Loss (MSE):  train=0.38280534744262695\n",
      "Epoch: 670/10000 Loss (MSE):  train=0.37943291664123535\n",
      "Epoch: 680/10000 Loss (MSE):  train=0.3760988712310791\n",
      "Epoch: 690/10000 Loss (MSE):  train=0.3728024661540985\n",
      "Epoch: 700/10000 Loss (MSE):  train=0.36954212188720703\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 710/10000 Loss (MSE):  train=0.36631709337234497\n",
      "Epoch: 720/10000 Loss (MSE):  train=0.3631258010864258\n",
      "Epoch: 730/10000 Loss (MSE):  train=0.35996729135513306\n",
      "Epoch: 740/10000 Loss (MSE):  train=0.35684096813201904\n",
      "Epoch: 750/10000 Loss (MSE):  train=0.35374531149864197\n",
      "Epoch: 760/10000 Loss (MSE):  train=0.35068055987358093\n",
      "Epoch: 770/10000 Loss (MSE):  train=0.3476448357105255\n",
      "Epoch: 780/10000 Loss (MSE):  train=0.34463751316070557\n",
      "Epoch: 790/10000 Loss (MSE):  train=0.3416582942008972\n",
      "Epoch: 800/10000 Loss (MSE):  train=0.3387061357498169\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 810/10000 Loss (MSE):  train=0.3357807397842407\n",
      "Epoch: 820/10000 Loss (MSE):  train=0.33288106322288513\n",
      "Epoch: 830/10000 Loss (MSE):  train=0.33000677824020386\n",
      "Epoch: 840/10000 Loss (MSE):  train=0.32715746760368347\n",
      "Epoch: 850/10000 Loss (MSE):  train=0.32433247566223145\n",
      "Epoch: 860/10000 Loss (MSE):  train=0.32153117656707764\n",
      "Epoch: 870/10000 Loss (MSE):  train=0.3187533915042877\n",
      "Epoch: 880/10000 Loss (MSE):  train=0.31599846482276917\n",
      "Epoch: 890/10000 Loss (MSE):  train=0.313266396522522\n",
      "Epoch: 900/10000 Loss (MSE):  train=0.31055670976638794\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 910/10000 Loss (MSE):  train=0.30786874890327454\n",
      "Epoch: 920/10000 Loss (MSE):  train=0.305202454328537\n",
      "Epoch: 930/10000 Loss (MSE):  train=0.3025575578212738\n",
      "Epoch: 940/10000 Loss (MSE):  train=0.29993367195129395\n",
      "Epoch: 950/10000 Loss (MSE):  train=0.29733091592788696\n",
      "Epoch: 960/10000 Loss (MSE):  train=0.2947485148906708\n",
      "Epoch: 970/10000 Loss (MSE):  train=0.2921866774559021\n",
      "Epoch: 980/10000 Loss (MSE):  train=0.2896450161933899\n",
      "Epoch: 990/10000 Loss (MSE):  train=0.2871234118938446\n",
      "Epoch: 1000/10000 Loss (MSE):  train=0.28462162613868713\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 1010/10000 Loss (MSE):  train=0.28213950991630554\n",
      "Epoch: 1020/10000 Loss (MSE):  train=0.2796773612499237\n",
      "Epoch: 1030/10000 Loss (MSE):  train=0.2772344648838043\n",
      "Epoch: 1040/10000 Loss (MSE):  train=0.27481094002723694\n",
      "Epoch: 1050/10000 Loss (MSE):  train=0.2724066972732544\n",
      "Epoch: 1060/10000 Loss (MSE):  train=0.2700215280056\n",
      "Epoch: 1070/10000 Loss (MSE):  train=0.26765578985214233\n",
      "Epoch: 1080/10000 Loss (MSE):  train=0.26530876755714417\n",
      "Epoch: 1090/10000 Loss (MSE):  train=0.26298069953918457\n",
      "Epoch: 1100/10000 Loss (MSE):  train=0.2606716454029083\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 1110/10000 Loss (MSE):  train=0.25838127732276917\n",
      "Epoch: 1120/10000 Loss (MSE):  train=0.2561095356941223\n",
      "Epoch: 1130/10000 Loss (MSE):  train=0.2538564205169678\n",
      "Epoch: 1140/10000 Loss (MSE):  train=0.25162193179130554\n",
      "Epoch: 1150/10000 Loss (MSE):  train=0.24940580129623413\n",
      "Epoch: 1160/10000 Loss (MSE):  train=0.24720822274684906\n",
      "Epoch: 1170/10000 Loss (MSE):  train=0.24502909183502197\n",
      "Epoch: 1180/10000 Loss (MSE):  train=0.24286800622940063\n",
      "Epoch: 1190/10000 Loss (MSE):  train=0.2407250702381134\n",
      "Epoch: 1200/10000 Loss (MSE):  train=0.2386000156402588\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 1210/10000 Loss (MSE):  train=0.23649322986602783\n",
      "Epoch: 1220/10000 Loss (MSE):  train=0.2344040870666504\n",
      "Epoch: 1230/10000 Loss (MSE):  train=0.2323325127363205\n",
      "Epoch: 1240/10000 Loss (MSE):  train=0.2302786111831665\n",
      "Epoch: 1250/10000 Loss (MSE):  train=0.22824178636074066\n",
      "Epoch: 1260/10000 Loss (MSE):  train=0.22622233629226685\n",
      "Epoch: 1270/10000 Loss (MSE):  train=0.2242199182510376\n",
      "Epoch: 1280/10000 Loss (MSE):  train=0.22223415970802307\n",
      "Epoch: 1290/10000 Loss (MSE):  train=0.22026510536670685\n",
      "Epoch: 1300/10000 Loss (MSE):  train=0.2183123230934143\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 1310/10000 Loss (MSE):  train=0.21637582778930664\n",
      "Epoch: 1320/10000 Loss (MSE):  train=0.21445497870445251\n",
      "Epoch: 1330/10000 Loss (MSE):  train=0.21254970133304596\n",
      "Epoch: 1340/10000 Loss (MSE):  train=0.210659921169281\n",
      "Epoch: 1350/10000 Loss (MSE):  train=0.20878511667251587\n",
      "Epoch: 1360/10000 Loss (MSE):  train=0.2069249302148819\n",
      "Epoch: 1370/10000 Loss (MSE):  train=0.2050793319940567\n",
      "Epoch: 1380/10000 Loss (MSE):  train=0.20324759185314178\n",
      "Epoch: 1390/10000 Loss (MSE):  train=0.20142967998981476\n",
      "Epoch: 1400/10000 Loss (MSE):  train=0.19962488114833832\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 1410/10000 Loss (MSE):  train=0.19783331453800201\n",
      "Epoch: 1420/10000 Loss (MSE):  train=0.19605425000190735\n",
      "Epoch: 1430/10000 Loss (MSE):  train=0.19428750872612\n",
      "Epoch: 1440/10000 Loss (MSE):  train=0.1925325095653534\n",
      "Epoch: 1450/10000 Loss (MSE):  train=0.19078902900218964\n",
      "Epoch: 1460/10000 Loss (MSE):  train=0.18905659019947052\n",
      "Epoch: 1470/10000 Loss (MSE):  train=0.1873348206281662\n",
      "Epoch: 1480/10000 Loss (MSE):  train=0.1856234073638916\n",
      "Epoch: 1490/10000 Loss (MSE):  train=0.1839216649532318\n",
      "Epoch: 1500/10000 Loss (MSE):  train=0.18222929537296295\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 1510/10000 Loss (MSE):  train=0.18054625391960144\n",
      "Epoch: 1520/10000 Loss (MSE):  train=0.17887158691883087\n",
      "Epoch: 1530/10000 Loss (MSE):  train=0.17720529437065125\n",
      "Epoch: 1540/10000 Loss (MSE):  train=0.17554692924022675\n",
      "Epoch: 1550/10000 Loss (MSE):  train=0.17389574646949768\n",
      "Epoch: 1560/10000 Loss (MSE):  train=0.17225201427936554\n",
      "Epoch: 1570/10000 Loss (MSE):  train=0.1706148087978363\n",
      "Epoch: 1580/10000 Loss (MSE):  train=0.16898424923419952\n",
      "Epoch: 1590/10000 Loss (MSE):  train=0.1673593819141388\n",
      "Epoch: 1600/10000 Loss (MSE):  train=0.16574043035507202\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 1610/10000 Loss (MSE):  train=0.16412682831287384\n",
      "Epoch: 1620/10000 Loss (MSE):  train=0.16251838207244873\n",
      "Epoch: 1630/10000 Loss (MSE):  train=0.16091477870941162\n",
      "Epoch: 1640/10000 Loss (MSE):  train=0.15931572020053864\n",
      "Epoch: 1650/10000 Loss (MSE):  train=0.15772098302841187\n",
      "Epoch: 1660/10000 Loss (MSE):  train=0.15613043308258057\n",
      "Epoch: 1670/10000 Loss (MSE):  train=0.15454396605491638\n",
      "Epoch: 1680/10000 Loss (MSE):  train=0.15296120941638947\n",
      "Epoch: 1690/10000 Loss (MSE):  train=0.15138202905654907\n",
      "Epoch: 1700/10000 Loss (MSE):  train=0.14980654418468475\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 1710/10000 Loss (MSE):  train=0.14823457598686218\n",
      "Epoch: 1720/10000 Loss (MSE):  train=0.14666590094566345\n",
      "Epoch: 1730/10000 Loss (MSE):  train=0.14510084688663483\n",
      "Epoch: 1740/10000 Loss (MSE):  train=0.14353933930397034\n",
      "Epoch: 1750/10000 Loss (MSE):  train=0.14198115468025208\n",
      "Epoch: 1760/10000 Loss (MSE):  train=0.14042678475379944\n",
      "Epoch: 1770/10000 Loss (MSE):  train=0.13887611031532288\n",
      "Epoch: 1780/10000 Loss (MSE):  train=0.1373293399810791\n",
      "Epoch: 1790/10000 Loss (MSE):  train=0.13578681647777557\n",
      "Epoch: 1800/10000 Loss (MSE):  train=0.1342485547065735\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 1810/10000 Loss (MSE):  train=0.13271507620811462\n",
      "Epoch: 1820/10000 Loss (MSE):  train=0.13118648529052734\n",
      "Epoch: 1830/10000 Loss (MSE):  train=0.12966330349445343\n",
      "Epoch: 1840/10000 Loss (MSE):  train=0.1281457245349884\n",
      "Epoch: 1850/10000 Loss (MSE):  train=0.126634418964386\n",
      "Epoch: 1860/10000 Loss (MSE):  train=0.1251296103000641\n",
      "Epoch: 1870/10000 Loss (MSE):  train=0.12363182008266449\n",
      "Epoch: 1880/10000 Loss (MSE):  train=0.12214190512895584\n",
      "Epoch: 1890/10000 Loss (MSE):  train=0.12065990269184113\n",
      "Epoch: 1900/10000 Loss (MSE):  train=0.11918674409389496\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 1910/10000 Loss (MSE):  train=0.11772292107343674\n",
      "Epoch: 1920/10000 Loss (MSE):  train=0.11626899987459183\n",
      "Epoch: 1930/10000 Loss (MSE):  train=0.11482563614845276\n",
      "Epoch: 1940/10000 Loss (MSE):  train=0.11339354515075684\n",
      "Epoch: 1950/10000 Loss (MSE):  train=0.1119733601808548\n",
      "Epoch: 1960/10000 Loss (MSE):  train=0.1105656549334526\n",
      "Epoch: 1970/10000 Loss (MSE):  train=0.10917118191719055\n",
      "Epoch: 1980/10000 Loss (MSE):  train=0.10779055953025818\n",
      "Epoch: 1990/10000 Loss (MSE):  train=0.10642445087432861\n",
      "Epoch: 2000/10000 Loss (MSE):  train=0.1050734594464302\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sureshjyoti/GitHub/BGNODE_scratch/.venv_jaxbrow/lib/python3.9/site-packages/shadow/plot.py:181: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=figsize, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2010/10000 Loss (MSE):  train=0.10373825579881668\n",
      "Epoch: 2020/10000 Loss (MSE):  train=0.10241933912038803\n",
      "Epoch: 2030/10000 Loss (MSE):  train=0.10111739486455917\n",
      "Epoch: 2040/10000 Loss (MSE):  train=0.09983286261558533\n",
      "Epoch: 2050/10000 Loss (MSE):  train=0.09856637567281723\n",
      "Epoch: 2060/10000 Loss (MSE):  train=0.09731829166412354\n",
      "Epoch: 2070/10000 Loss (MSE):  train=0.0960889607667923\n",
      "Epoch: 2080/10000 Loss (MSE):  train=0.09487900137901306\n",
      "Epoch: 2090/10000 Loss (MSE):  train=0.09368845075368881\n",
      "Epoch: 2100/10000 Loss (MSE):  train=0.09251765161752701\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 2110/10000 Loss (MSE):  train=0.09136699140071869\n",
      "Epoch: 2120/10000 Loss (MSE):  train=0.09023646265268326\n",
      "Epoch: 2130/10000 Loss (MSE):  train=0.08912626653909683\n",
      "Epoch: 2140/10000 Loss (MSE):  train=0.08803638815879822\n",
      "Epoch: 2150/10000 Loss (MSE):  train=0.0869668573141098\n",
      "Epoch: 2160/10000 Loss (MSE):  train=0.085917629301548\n",
      "Epoch: 2170/10000 Loss (MSE):  train=0.08488859981298447\n",
      "Epoch: 2180/10000 Loss (MSE):  train=0.08387942612171173\n",
      "Epoch: 2190/10000 Loss (MSE):  train=0.08289001882076263\n",
      "Epoch: 2200/10000 Loss (MSE):  train=0.0819200873374939\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 2210/10000 Loss (MSE):  train=0.08096930384635925\n",
      "Epoch: 2220/10000 Loss (MSE):  train=0.0800371989607811\n",
      "Epoch: 2230/10000 Loss (MSE):  train=0.07912345230579376\n",
      "Epoch: 2240/10000 Loss (MSE):  train=0.07822749763727188\n",
      "Epoch: 2250/10000 Loss (MSE):  train=0.07734887301921844\n",
      "Epoch: 2260/10000 Loss (MSE):  train=0.0764869675040245\n",
      "Epoch: 2270/10000 Loss (MSE):  train=0.07564134895801544\n",
      "Epoch: 2280/10000 Loss (MSE):  train=0.07481129467487335\n",
      "Epoch: 2290/10000 Loss (MSE):  train=0.07399622350931168\n",
      "Epoch: 2300/10000 Loss (MSE):  train=0.07319548726081848\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 2310/10000 Loss (MSE):  train=0.07240839302539825\n",
      "Epoch: 2320/10000 Loss (MSE):  train=0.07163437455892563\n",
      "Epoch: 2330/10000 Loss (MSE):  train=0.07087263464927673\n",
      "Epoch: 2340/10000 Loss (MSE):  train=0.0701226219534874\n",
      "Epoch: 2350/10000 Loss (MSE):  train=0.06938354671001434\n",
      "Epoch: 2360/10000 Loss (MSE):  train=0.06865479052066803\n",
      "Epoch: 2370/10000 Loss (MSE):  train=0.06793566048145294\n",
      "Epoch: 2380/10000 Loss (MSE):  train=0.06722550094127655\n",
      "Epoch: 2390/10000 Loss (MSE):  train=0.0665237307548523\n",
      "Epoch: 2400/10000 Loss (MSE):  train=0.06582958251237869\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 2410/10000 Loss (MSE):  train=0.06514259427785873\n",
      "Epoch: 2420/10000 Loss (MSE):  train=0.06446202099323273\n",
      "Epoch: 2430/10000 Loss (MSE):  train=0.06378737837076187\n",
      "Epoch: 2440/10000 Loss (MSE):  train=0.0631180927157402\n",
      "Epoch: 2450/10000 Loss (MSE):  train=0.06245366483926773\n",
      "Epoch: 2460/10000 Loss (MSE):  train=0.0617934986948967\n",
      "Epoch: 2470/10000 Loss (MSE):  train=0.06113721802830696\n",
      "Epoch: 2480/10000 Loss (MSE):  train=0.06048426404595375\n",
      "Epoch: 2490/10000 Loss (MSE):  train=0.05983426421880722\n",
      "Epoch: 2500/10000 Loss (MSE):  train=0.05918681249022484\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 2510/10000 Loss (MSE):  train=0.058541521430015564\n",
      "Epoch: 2520/10000 Loss (MSE):  train=0.05789801850914955\n",
      "Epoch: 2530/10000 Loss (MSE):  train=0.05725601315498352\n",
      "Epoch: 2540/10000 Loss (MSE):  train=0.05661522597074509\n",
      "Epoch: 2550/10000 Loss (MSE):  train=0.0559752956032753\n",
      "Epoch: 2560/10000 Loss (MSE):  train=0.0553361251950264\n",
      "Epoch: 2570/10000 Loss (MSE):  train=0.054697372019290924\n",
      "Epoch: 2580/10000 Loss (MSE):  train=0.05405891314148903\n",
      "Epoch: 2590/10000 Loss (MSE):  train=0.0534205287694931\n",
      "Epoch: 2600/10000 Loss (MSE):  train=0.05278215557336807\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 2610/10000 Loss (MSE):  train=0.052143558859825134\n",
      "Epoch: 2620/10000 Loss (MSE):  train=0.051504768431186676\n",
      "Epoch: 2630/10000 Loss (MSE):  train=0.05086563527584076\n",
      "Epoch: 2640/10000 Loss (MSE):  train=0.05022614449262619\n",
      "Epoch: 2650/10000 Loss (MSE):  train=0.049586281180381775\n",
      "Epoch: 2660/10000 Loss (MSE):  train=0.048945993185043335\n",
      "Epoch: 2670/10000 Loss (MSE):  train=0.04830534756183624\n",
      "Epoch: 2680/10000 Loss (MSE):  train=0.04766435921192169\n",
      "Epoch: 2690/10000 Loss (MSE):  train=0.04702315479516983\n",
      "Epoch: 2700/10000 Loss (MSE):  train=0.04638165980577469\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 2710/10000 Loss (MSE):  train=0.04574016481637955\n",
      "Epoch: 2720/10000 Loss (MSE):  train=0.0450986847281456\n",
      "Epoch: 2730/10000 Loss (MSE):  train=0.044457390904426575\n",
      "Epoch: 2740/10000 Loss (MSE):  train=0.0438164621591568\n",
      "Epoch: 2750/10000 Loss (MSE):  train=0.04317603260278702\n",
      "Epoch: 2760/10000 Loss (MSE):  train=0.042536329478025436\n",
      "Epoch: 2770/10000 Loss (MSE):  train=0.04189756512641907\n",
      "Epoch: 2780/10000 Loss (MSE):  train=0.04125995561480522\n",
      "Epoch: 2790/10000 Loss (MSE):  train=0.04062380641698837\n",
      "Epoch: 2800/10000 Loss (MSE):  train=0.03998930752277374\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 2810/10000 Loss (MSE):  train=0.03935679793357849\n",
      "Epoch: 2820/10000 Loss (MSE):  train=0.03872654214501381\n",
      "Epoch: 2830/10000 Loss (MSE):  train=0.038098834455013275\n",
      "Epoch: 2840/10000 Loss (MSE):  train=0.03747401013970375\n",
      "Epoch: 2850/10000 Loss (MSE):  train=0.03685237094759941\n",
      "Epoch: 2860/10000 Loss (MSE):  train=0.03623419627547264\n",
      "Epoch: 2870/10000 Loss (MSE):  train=0.03561992570757866\n",
      "Epoch: 2880/10000 Loss (MSE):  train=0.035009801387786865\n",
      "Epoch: 2890/10000 Loss (MSE):  train=0.03440423309803009\n",
      "Epoch: 2900/10000 Loss (MSE):  train=0.03380348160862923\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 2910/10000 Loss (MSE):  train=0.03320790082216263\n",
      "Epoch: 2920/10000 Loss (MSE):  train=0.03261785954236984\n",
      "Epoch: 2930/10000 Loss (MSE):  train=0.03203365579247475\n",
      "Epoch: 2940/10000 Loss (MSE):  train=0.03145561367273331\n",
      "Epoch: 2950/10000 Loss (MSE):  train=0.030884061008691788\n",
      "Epoch: 2960/10000 Loss (MSE):  train=0.03031925857067108\n",
      "Epoch: 2970/10000 Loss (MSE):  train=0.0297615397721529\n",
      "Epoch: 2980/10000 Loss (MSE):  train=0.029211144894361496\n",
      "Epoch: 2990/10000 Loss (MSE):  train=0.02866833284497261\n",
      "Epoch: 3000/10000 Loss (MSE):  train=0.028133392333984375\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 3010/10000 Loss (MSE):  train=0.027606522664427757\n",
      "Epoch: 3020/10000 Loss (MSE):  train=0.027087941765785217\n",
      "Epoch: 3030/10000 Loss (MSE):  train=0.026577863842248917\n",
      "Epoch: 3040/10000 Loss (MSE):  train=0.026076413691043854\n",
      "Epoch: 3050/10000 Loss (MSE):  train=0.025583796203136444\n",
      "Epoch: 3060/10000 Loss (MSE):  train=0.02510015107691288\n",
      "Epoch: 3070/10000 Loss (MSE):  train=0.02462555095553398\n",
      "Epoch: 3080/10000 Loss (MSE):  train=0.02416013926267624\n",
      "Epoch: 3090/10000 Loss (MSE):  train=0.02370394766330719\n",
      "Epoch: 3100/10000 Loss (MSE):  train=0.023257087916135788\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 3110/10000 Loss (MSE):  train=0.022819552570581436\n",
      "Epoch: 3120/10000 Loss (MSE):  train=0.022391386330127716\n",
      "Epoch: 3130/10000 Loss (MSE):  train=0.021972578018903732\n",
      "Epoch: 3140/10000 Loss (MSE):  train=0.021563110873103142\n",
      "Epoch: 3150/10000 Loss (MSE):  train=0.02116294391453266\n",
      "Epoch: 3160/10000 Loss (MSE):  train=0.02077203243970871\n",
      "Epoch: 3170/10000 Loss (MSE):  train=0.020390305668115616\n",
      "Epoch: 3180/10000 Loss (MSE):  train=0.020017685368657112\n",
      "Epoch: 3190/10000 Loss (MSE):  train=0.01965409144759178\n",
      "Epoch: 3200/10000 Loss (MSE):  train=0.019299406558275223\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 3210/10000 Loss (MSE):  train=0.018953517079353333\n",
      "Epoch: 3220/10000 Loss (MSE):  train=0.018616266548633575\n",
      "Epoch: 3230/10000 Loss (MSE):  train=0.01828758232295513\n",
      "Epoch: 3240/10000 Loss (MSE):  train=0.01796726882457733\n",
      "Epoch: 3250/10000 Loss (MSE):  train=0.017655186355113983\n",
      "Epoch: 3260/10000 Loss (MSE):  train=0.017351195216178894\n",
      "Epoch: 3270/10000 Loss (MSE):  train=0.01705513335764408\n",
      "Epoch: 3280/10000 Loss (MSE):  train=0.01676684245467186\n",
      "Epoch: 3290/10000 Loss (MSE):  train=0.016486136242747307\n",
      "Epoch: 3300/10000 Loss (MSE):  train=0.01621284894645214\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 3310/10000 Loss (MSE):  train=0.015946829691529274\n",
      "Epoch: 3320/10000 Loss (MSE):  train=0.015687918290495872\n",
      "Epoch: 3330/10000 Loss (MSE):  train=0.01543591171503067\n",
      "Epoch: 3340/10000 Loss (MSE):  train=0.01519064698368311\n",
      "Epoch: 3350/10000 Loss (MSE):  train=0.014951979741454124\n",
      "Epoch: 3360/10000 Loss (MSE):  train=0.014719726517796516\n",
      "Epoch: 3370/10000 Loss (MSE):  train=0.014493724331259727\n",
      "Epoch: 3380/10000 Loss (MSE):  train=0.01427380833774805\n",
      "Epoch: 3390/10000 Loss (MSE):  train=0.014059825800359249\n",
      "Epoch: 3400/10000 Loss (MSE):  train=0.013851610012352467\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 3410/10000 Loss (MSE):  train=0.01364902500063181\n",
      "Epoch: 3420/10000 Loss (MSE):  train=0.013451901264488697\n",
      "Epoch: 3430/10000 Loss (MSE):  train=0.013260094448924065\n",
      "Epoch: 3440/10000 Loss (MSE):  train=0.013073466718196869\n",
      "Epoch: 3450/10000 Loss (MSE):  train=0.012891878373920918\n",
      "Epoch: 3460/10000 Loss (MSE):  train=0.012715176679193974\n",
      "Epoch: 3470/10000 Loss (MSE):  train=0.012543239630758762\n",
      "Epoch: 3480/10000 Loss (MSE):  train=0.012375932186841965\n",
      "Epoch: 3490/10000 Loss (MSE):  train=0.012213131412863731\n",
      "Epoch: 3500/10000 Loss (MSE):  train=0.012054706923663616\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 3510/10000 Loss (MSE):  train=0.01190053392201662\n",
      "Epoch: 3520/10000 Loss (MSE):  train=0.01175050437450409\n",
      "Epoch: 3530/10000 Loss (MSE):  train=0.011604491621255875\n",
      "Epoch: 3540/10000 Loss (MSE):  train=0.01146238949149847\n",
      "Epoch: 3550/10000 Loss (MSE):  train=0.011324085295200348\n",
      "Epoch: 3560/10000 Loss (MSE):  train=0.011189475655555725\n",
      "Epoch: 3570/10000 Loss (MSE):  train=0.011058454401791096\n",
      "Epoch: 3580/10000 Loss (MSE):  train=0.010930914431810379\n",
      "Epoch: 3590/10000 Loss (MSE):  train=0.010806763544678688\n",
      "Epoch: 3600/10000 Loss (MSE):  train=0.010685902088880539\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 3610/10000 Loss (MSE):  train=0.010568231344223022\n",
      "Epoch: 3620/10000 Loss (MSE):  train=0.0104536646977067\n",
      "Epoch: 3630/10000 Loss (MSE):  train=0.010342110879719257\n",
      "Epoch: 3640/10000 Loss (MSE):  train=0.010233470238745213\n",
      "Epoch: 3650/10000 Loss (MSE):  train=0.010127676650881767\n",
      "Epoch: 3660/10000 Loss (MSE):  train=0.010024629533290863\n",
      "Epoch: 3670/10000 Loss (MSE):  train=0.009924259036779404\n",
      "Epoch: 3680/10000 Loss (MSE):  train=0.00982646644115448\n",
      "Epoch: 3690/10000 Loss (MSE):  train=0.009731183759868145\n",
      "Epoch: 3700/10000 Loss (MSE):  train=0.009638339281082153\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 3710/10000 Loss (MSE):  train=0.009547846391797066\n",
      "Epoch: 3720/10000 Loss (MSE):  train=0.00945964828133583\n",
      "Epoch: 3730/10000 Loss (MSE):  train=0.009373648092150688\n",
      "Epoch: 3740/10000 Loss (MSE):  train=0.00928979180753231\n",
      "Epoch: 3750/10000 Loss (MSE):  train=0.009208021685481071\n",
      "Epoch: 3760/10000 Loss (MSE):  train=0.009128240868449211\n",
      "Epoch: 3770/10000 Loss (MSE):  train=0.009050417691469193\n",
      "Epoch: 3780/10000 Loss (MSE):  train=0.008974453434348106\n",
      "Epoch: 3790/10000 Loss (MSE):  train=0.008900308050215244\n",
      "Epoch: 3800/10000 Loss (MSE):  train=0.008827926591038704\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 3810/10000 Loss (MSE):  train=0.008757228963077068\n",
      "Epoch: 3820/10000 Loss (MSE):  train=0.008688167668879032\n",
      "Epoch: 3830/10000 Loss (MSE):  train=0.008620686829090118\n",
      "Epoch: 3840/10000 Loss (MSE):  train=0.008554726839065552\n",
      "Epoch: 3850/10000 Loss (MSE):  train=0.00849025510251522\n",
      "Epoch: 3860/10000 Loss (MSE):  train=0.008427190594375134\n",
      "Epoch: 3870/10000 Loss (MSE):  train=0.008365500718355179\n",
      "Epoch: 3880/10000 Loss (MSE):  train=0.008305128663778305\n",
      "Epoch: 3890/10000 Loss (MSE):  train=0.008246033452451229\n",
      "Epoch: 3900/10000 Loss (MSE):  train=0.008188175037503242\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 3910/10000 Loss (MSE):  train=0.008131502196192741\n",
      "Epoch: 3920/10000 Loss (MSE):  train=0.008075963705778122\n",
      "Epoch: 3930/10000 Loss (MSE):  train=0.008021526038646698\n",
      "Epoch: 3940/10000 Loss (MSE):  train=0.007968161255121231\n",
      "Epoch: 3950/10000 Loss (MSE):  train=0.007915811613202095\n",
      "Epoch: 3960/10000 Loss (MSE):  train=0.007864451967179775\n",
      "Epoch: 3970/10000 Loss (MSE):  train=0.00781403947621584\n",
      "Epoch: 3980/10000 Loss (MSE):  train=0.0077645438723266125\n",
      "Epoch: 3990/10000 Loss (MSE):  train=0.007715935818850994\n",
      "Epoch: 4000/10000 Loss (MSE):  train=0.007668175268918276\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 4010/10000 Loss (MSE):  train=0.007621226832270622\n",
      "Epoch: 4020/10000 Loss (MSE):  train=0.007575085386633873\n",
      "Epoch: 4030/10000 Loss (MSE):  train=0.007529696449637413\n",
      "Epoch: 4040/10000 Loss (MSE):  train=0.0074850465171039104\n",
      "Epoch: 4050/10000 Loss (MSE):  train=0.00744110532104969\n",
      "Epoch: 4060/10000 Loss (MSE):  train=0.007397858425974846\n",
      "Epoch: 4070/10000 Loss (MSE):  train=0.0073552681133151054\n",
      "Epoch: 4080/10000 Loss (MSE):  train=0.007313314825296402\n",
      "Epoch: 4090/10000 Loss (MSE):  train=0.007271988317370415\n",
      "Epoch: 4100/10000 Loss (MSE):  train=0.0072312564589083195\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 4110/10000 Loss (MSE):  train=0.007191098760813475\n",
      "Epoch: 4120/10000 Loss (MSE):  train=0.007151507306843996\n",
      "Epoch: 4130/10000 Loss (MSE):  train=0.007112456019967794\n",
      "Epoch: 4140/10000 Loss (MSE):  train=0.007073928602039814\n",
      "Epoch: 4150/10000 Loss (MSE):  train=0.0070359124802052975\n",
      "Epoch: 4160/10000 Loss (MSE):  train=0.006998387165367603\n",
      "Epoch: 4170/10000 Loss (MSE):  train=0.006961349863559008\n",
      "Epoch: 4180/10000 Loss (MSE):  train=0.006924774497747421\n",
      "Epoch: 4190/10000 Loss (MSE):  train=0.0068886433728039265\n",
      "Epoch: 4200/10000 Loss (MSE):  train=0.006852967664599419\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 4210/10000 Loss (MSE):  train=0.006817702203989029\n",
      "Epoch: 4220/10000 Loss (MSE):  train=0.0067828623577952385\n",
      "Epoch: 4230/10000 Loss (MSE):  train=0.006748425308614969\n",
      "Epoch: 4240/10000 Loss (MSE):  train=0.006714385934174061\n",
      "Epoch: 4250/10000 Loss (MSE):  train=0.006680732127279043\n",
      "Epoch: 4260/10000 Loss (MSE):  train=0.006647453643381596\n",
      "Epoch: 4270/10000 Loss (MSE):  train=0.006614547222852707\n",
      "Epoch: 4280/10000 Loss (MSE):  train=0.0065820044837892056\n",
      "Epoch: 4290/10000 Loss (MSE):  train=0.006549805402755737\n",
      "Epoch: 4300/10000 Loss (MSE):  train=0.006517951376736164\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 4310/10000 Loss (MSE):  train=0.006486441008746624\n",
      "Epoch: 4320/10000 Loss (MSE):  train=0.006455256137996912\n",
      "Epoch: 4330/10000 Loss (MSE):  train=0.0064243958331644535\n",
      "Epoch: 4340/10000 Loss (MSE):  train=0.006393852643668652\n",
      "Epoch: 4350/10000 Loss (MSE):  train=0.006363623775541782\n",
      "Epoch: 4360/10000 Loss (MSE):  train=0.006333701312541962\n",
      "Epoch: 4370/10000 Loss (MSE):  train=0.0063040778040885925\n",
      "Epoch: 4380/10000 Loss (MSE):  train=0.00627474719658494\n",
      "Epoch: 4390/10000 Loss (MSE):  train=0.006245714612305164\n",
      "Epoch: 4400/10000 Loss (MSE):  train=0.006216963287442923\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 4410/10000 Loss (MSE):  train=0.006188489031046629\n",
      "Epoch: 4420/10000 Loss (MSE):  train=0.006160296034067869\n",
      "Epoch: 4430/10000 Loss (MSE):  train=0.006132373586297035\n",
      "Epoch: 4440/10000 Loss (MSE):  train=0.006104718893766403\n",
      "Epoch: 4450/10000 Loss (MSE):  train=0.006077327765524387\n",
      "Epoch: 4460/10000 Loss (MSE):  train=0.0060502043925225735\n",
      "Epoch: 4470/10000 Loss (MSE):  train=0.006023331079632044\n",
      "Epoch: 4480/10000 Loss (MSE):  train=0.005996717140078545\n",
      "Epoch: 4490/10000 Loss (MSE):  train=0.005970352329313755\n",
      "Epoch: 4500/10000 Loss (MSE):  train=0.005944231059402227\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 4510/10000 Loss (MSE):  train=0.0059183500707149506\n",
      "Epoch: 4520/10000 Loss (MSE):  train=0.005892714951187372\n",
      "Epoch: 4530/10000 Loss (MSE):  train=0.005867321044206619\n",
      "Epoch: 4540/10000 Loss (MSE):  train=0.005842157639563084\n",
      "Epoch: 4550/10000 Loss (MSE):  train=0.0058172279968857765\n",
      "Epoch: 4560/10000 Loss (MSE):  train=0.00579252140596509\n",
      "Epoch: 4570/10000 Loss (MSE):  train=0.0057680485770106316\n",
      "Epoch: 4580/10000 Loss (MSE):  train=0.005743795074522495\n",
      "Epoch: 4590/10000 Loss (MSE):  train=0.005719759501516819\n",
      "Epoch: 4600/10000 Loss (MSE):  train=0.005695946514606476\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 4610/10000 Loss (MSE):  train=0.005672350525856018\n",
      "Epoch: 4620/10000 Loss (MSE):  train=0.005648970603942871\n",
      "Epoch: 4630/10000 Loss (MSE):  train=0.005625797435641289\n",
      "Epoch: 4640/10000 Loss (MSE):  train=0.005602831952273846\n",
      "Epoch: 4650/10000 Loss (MSE):  train=0.00558007275685668\n",
      "Epoch: 4660/10000 Loss (MSE):  train=0.0055575198493897915\n",
      "Epoch: 4670/10000 Loss (MSE):  train=0.005535169970244169\n",
      "Epoch: 4680/10000 Loss (MSE):  train=0.005513020325452089\n",
      "Epoch: 4690/10000 Loss (MSE):  train=0.005491064395755529\n",
      "Epoch: 4700/10000 Loss (MSE):  train=0.005469305440783501\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 4710/10000 Loss (MSE):  train=0.005447740200906992\n",
      "Epoch: 4720/10000 Loss (MSE):  train=0.005426367744803429\n",
      "Epoch: 4730/10000 Loss (MSE):  train=0.005405179690569639\n",
      "Epoch: 4740/10000 Loss (MSE):  train=0.005384183023124933\n",
      "Epoch: 4750/10000 Loss (MSE):  train=0.005363370291888714\n",
      "Epoch: 4760/10000 Loss (MSE):  train=0.005342739634215832\n",
      "Epoch: 4770/10000 Loss (MSE):  train=0.0053222873248159885\n",
      "Epoch: 4780/10000 Loss (MSE):  train=0.005302019417285919\n",
      "Epoch: 4790/10000 Loss (MSE):  train=0.005281927529722452\n",
      "Epoch: 4800/10000 Loss (MSE):  train=0.005262010730803013\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 4810/10000 Loss (MSE):  train=0.005242268089205027\n",
      "Epoch: 4820/10000 Loss (MSE):  train=0.005222700536251068\n",
      "Epoch: 4830/10000 Loss (MSE):  train=0.005203301552683115\n",
      "Epoch: 4840/10000 Loss (MSE):  train=0.005184065084904432\n",
      "Epoch: 4850/10000 Loss (MSE):  train=0.005164997652173042\n",
      "Epoch: 4860/10000 Loss (MSE):  train=0.005146099720150232\n",
      "Epoch: 4870/10000 Loss (MSE):  train=0.00512735964730382\n",
      "Epoch: 4880/10000 Loss (MSE):  train=0.005108784884214401\n",
      "Epoch: 4890/10000 Loss (MSE):  train=0.0050903670489788055\n",
      "Epoch: 4900/10000 Loss (MSE):  train=0.005072108469903469\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 4910/10000 Loss (MSE):  train=0.005054006353020668\n",
      "Epoch: 4920/10000 Loss (MSE):  train=0.005036060698330402\n",
      "Epoch: 4930/10000 Loss (MSE):  train=0.005018267314881086\n",
      "Epoch: 4940/10000 Loss (MSE):  train=0.005000625737011433\n",
      "Epoch: 4950/10000 Loss (MSE):  train=0.00498313270509243\n",
      "Epoch: 4960/10000 Loss (MSE):  train=0.004965791013091803\n",
      "Epoch: 4970/10000 Loss (MSE):  train=0.004948591813445091\n",
      "Epoch: 4980/10000 Loss (MSE):  train=0.004931539762765169\n",
      "Epoch: 4990/10000 Loss (MSE):  train=0.004914635792374611\n",
      "Epoch: 5000/10000 Loss (MSE):  train=0.004897870123386383\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 5010/10000 Loss (MSE):  train=0.004881246481090784\n",
      "Epoch: 5020/10000 Loss (MSE):  train=0.004864761605858803\n",
      "Epoch: 5030/10000 Loss (MSE):  train=0.004848412703722715\n",
      "Epoch: 5040/10000 Loss (MSE):  train=0.004832202568650246\n",
      "Epoch: 5050/10000 Loss (MSE):  train=0.004816134460270405\n",
      "Epoch: 5060/10000 Loss (MSE):  train=0.004800196271389723\n",
      "Epoch: 5070/10000 Loss (MSE):  train=0.004784385673701763\n",
      "Epoch: 5080/10000 Loss (MSE):  train=0.004768709652125835\n",
      "Epoch: 5090/10000 Loss (MSE):  train=0.004753161687403917\n",
      "Epoch: 5100/10000 Loss (MSE):  train=0.004737746901810169\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 5110/10000 Loss (MSE):  train=0.004722457379102707\n",
      "Epoch: 5120/10000 Loss (MSE):  train=0.004707292653620243\n",
      "Epoch: 5130/10000 Loss (MSE):  train=0.00469225225970149\n",
      "Epoch: 5140/10000 Loss (MSE):  train=0.004677337594330311\n",
      "Epoch: 5150/10000 Loss (MSE):  train=0.004662546329200268\n",
      "Epoch: 5160/10000 Loss (MSE):  train=0.0046478742733597755\n",
      "Epoch: 5170/10000 Loss (MSE):  train=0.0046333251520991325\n",
      "Epoch: 5180/10000 Loss (MSE):  train=0.00461889011785388\n",
      "Epoch: 5190/10000 Loss (MSE):  train=0.004604571498930454\n",
      "Epoch: 5200/10000 Loss (MSE):  train=0.004590372554957867\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 5210/10000 Loss (MSE):  train=0.004576284438371658\n",
      "Epoch: 5220/10000 Loss (MSE):  train=0.004562315531075001\n",
      "Epoch: 5230/10000 Loss (MSE):  train=0.004548455122858286\n",
      "Epoch: 5240/10000 Loss (MSE):  train=0.0045347088016569614\n",
      "Epoch: 5250/10000 Loss (MSE):  train=0.004521076567471027\n",
      "Epoch: 5260/10000 Loss (MSE):  train=0.004507545381784439\n",
      "Epoch: 5270/10000 Loss (MSE):  train=0.004494125489145517\n",
      "Epoch: 5280/10000 Loss (MSE):  train=0.0044808154925704\n",
      "Epoch: 5290/10000 Loss (MSE):  train=0.0044676135294139385\n",
      "Epoch: 5300/10000 Loss (MSE):  train=0.004454511217772961\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 5310/10000 Loss (MSE):  train=0.004441514145582914\n",
      "Epoch: 5320/10000 Loss (MSE):  train=0.004428623244166374\n",
      "Epoch: 5330/10000 Loss (MSE):  train=0.004415830597281456\n",
      "Epoch: 5340/10000 Loss (MSE):  train=0.004403139464557171\n",
      "Epoch: 5350/10000 Loss (MSE):  train=0.004390551708638668\n",
      "Epoch: 5360/10000 Loss (MSE):  train=0.004378057550638914\n",
      "Epoch: 5370/10000 Loss (MSE):  train=0.004365664441138506\n",
      "Epoch: 5380/10000 Loss (MSE):  train=0.004353371448814869\n",
      "Epoch: 5390/10000 Loss (MSE):  train=0.004341169726103544\n",
      "Epoch: 5400/10000 Loss (MSE):  train=0.004329065792262554\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 5410/10000 Loss (MSE):  train=0.004317060578614473\n",
      "Epoch: 5420/10000 Loss (MSE):  train=0.004305144306272268\n",
      "Epoch: 5430/10000 Loss (MSE):  train=0.0042933207005262375\n",
      "Epoch: 5440/10000 Loss (MSE):  train=0.004281584173440933\n",
      "Epoch: 5450/10000 Loss (MSE):  train=0.004269945435225964\n",
      "Epoch: 5460/10000 Loss (MSE):  train=0.004258394706994295\n",
      "Epoch: 5470/10000 Loss (MSE):  train=0.004246929660439491\n",
      "Epoch: 5480/10000 Loss (MSE):  train=0.0042355600744485855\n",
      "Epoch: 5490/10000 Loss (MSE):  train=0.004224269650876522\n",
      "Epoch: 5500/10000 Loss (MSE):  train=0.004213068634271622\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 5510/10000 Loss (MSE):  train=0.00420195609331131\n",
      "Epoch: 5520/10000 Loss (MSE):  train=0.004190926440060139\n",
      "Epoch: 5530/10000 Loss (MSE):  train=0.004179977346211672\n",
      "Epoch: 5540/10000 Loss (MSE):  train=0.00416911393404007\n",
      "Epoch: 5550/10000 Loss (MSE):  train=0.004158335737884045\n",
      "Epoch: 5560/10000 Loss (MSE):  train=0.004147636238485575\n",
      "Epoch: 5570/10000 Loss (MSE):  train=0.004137016832828522\n",
      "Epoch: 5580/10000 Loss (MSE):  train=0.004126477520912886\n",
      "Epoch: 5590/10000 Loss (MSE):  train=0.004116022028028965\n",
      "Epoch: 5600/10000 Loss (MSE):  train=0.004105640109628439\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 5610/10000 Loss (MSE):  train=0.00409533828496933\n",
      "Epoch: 5620/10000 Loss (MSE):  train=0.0040851132944226265\n",
      "Epoch: 5630/10000 Loss (MSE):  train=0.0040749674662947655\n",
      "Epoch: 5640/10000 Loss (MSE):  train=0.004064890556037426\n",
      "Epoch: 5650/10000 Loss (MSE):  train=0.004054891411215067\n",
      "Epoch: 5660/10000 Loss (MSE):  train=0.004044969566166401\n",
      "Epoch: 5670/10000 Loss (MSE):  train=0.004035117570310831\n",
      "Epoch: 5680/10000 Loss (MSE):  train=0.004025341477245092\n",
      "Epoch: 5690/10000 Loss (MSE):  train=0.004015637096017599\n",
      "Epoch: 5700/10000 Loss (MSE):  train=0.004005999770015478\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 5710/10000 Loss (MSE):  train=0.003996439278125763\n",
      "Epoch: 5720/10000 Loss (MSE):  train=0.0039869435131549835\n",
      "Epoch: 5730/10000 Loss (MSE):  train=0.003977520391345024\n",
      "Epoch: 5740/10000 Loss (MSE):  train=0.003968169447034597\n",
      "Epoch: 5750/10000 Loss (MSE):  train=0.003958879038691521\n",
      "Epoch: 5760/10000 Loss (MSE):  train=0.00394965847954154\n",
      "Epoch: 5770/10000 Loss (MSE):  train=0.003940506838262081\n",
      "Epoch: 5780/10000 Loss (MSE):  train=0.003931420389562845\n",
      "Epoch: 5790/10000 Loss (MSE):  train=0.003922400064766407\n",
      "Epoch: 5800/10000 Loss (MSE):  train=0.003913446329534054\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 5810/10000 Loss (MSE):  train=0.003904550801962614\n",
      "Epoch: 5820/10000 Loss (MSE):  train=0.0038957272190600634\n",
      "Epoch: 5830/10000 Loss (MSE):  train=0.003886961378157139\n",
      "Epoch: 5840/10000 Loss (MSE):  train=0.0038782600313425064\n",
      "Epoch: 5850/10000 Loss (MSE):  train=0.0038696203846484423\n",
      "Epoch: 5860/10000 Loss (MSE):  train=0.003861041972413659\n",
      "Epoch: 5870/10000 Loss (MSE):  train=0.0038525243289768696\n",
      "Epoch: 5880/10000 Loss (MSE):  train=0.003844066523015499\n",
      "Epoch: 5890/10000 Loss (MSE):  train=0.0038356694858521223\n",
      "Epoch: 5900/10000 Loss (MSE):  train=0.00382733135484159\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 5910/10000 Loss (MSE):  train=0.0038190516643226147\n",
      "Epoch: 5920/10000 Loss (MSE):  train=0.003810829482972622\n",
      "Epoch: 5930/10000 Loss (MSE):  train=0.0038026636466383934\n",
      "Epoch: 5940/10000 Loss (MSE):  train=0.003794554155319929\n",
      "Epoch: 5950/10000 Loss (MSE):  train=0.0037865054327994585\n",
      "Epoch: 5960/10000 Loss (MSE):  train=0.0037785095628350973\n",
      "Epoch: 5970/10000 Loss (MSE):  train=0.003770568873733282\n",
      "Epoch: 5980/10000 Loss (MSE):  train=0.0037626847624778748\n",
      "Epoch: 5990/10000 Loss (MSE):  train=0.0037548525724560022\n",
      "Epoch: 6000/10000 Loss (MSE):  train=0.003747074631974101\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 6010/10000 Loss (MSE):  train=0.0037393528036773205\n",
      "Epoch: 6020/10000 Loss (MSE):  train=0.0037316803354769945\n",
      "Epoch: 6030/10000 Loss (MSE):  train=0.003724062815308571\n",
      "Epoch: 6040/10000 Loss (MSE):  train=0.0037164981476962566\n",
      "Epoch: 6050/10000 Loss (MSE):  train=0.003708980744704604\n",
      "Epoch: 6060/10000 Loss (MSE):  train=0.0037015145644545555\n",
      "Epoch: 6070/10000 Loss (MSE):  train=0.0036941005382686853\n",
      "Epoch: 6080/10000 Loss (MSE):  train=0.0036867379676550627\n",
      "Epoch: 6090/10000 Loss (MSE):  train=0.003679424524307251\n",
      "Epoch: 6100/10000 Loss (MSE):  train=0.00367215764708817\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 6110/10000 Loss (MSE):  train=0.0036649408284574747\n",
      "Epoch: 6120/10000 Loss (MSE):  train=0.0036577717401087284\n",
      "Epoch: 6130/10000 Loss (MSE):  train=0.003650648519396782\n",
      "Epoch: 6140/10000 Loss (MSE):  train=0.003643572796136141\n",
      "Epoch: 6150/10000 Loss (MSE):  train=0.0036365489941090345\n",
      "Epoch: 6160/10000 Loss (MSE):  train=0.0036295668687671423\n",
      "Epoch: 6170/10000 Loss (MSE):  train=0.0036226327065378428\n",
      "Epoch: 6180/10000 Loss (MSE):  train=0.003615740453824401\n",
      "Epoch: 6190/10000 Loss (MSE):  train=0.0036088996566832066\n",
      "Epoch: 6200/10000 Loss (MSE):  train=0.003602100070565939\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 6210/10000 Loss (MSE):  train=0.0035953440237790346\n",
      "Epoch: 6220/10000 Loss (MSE):  train=0.0035886322148144245\n",
      "Epoch: 6230/10000 Loss (MSE):  train=0.0035819646436721087\n",
      "Epoch: 6240/10000 Loss (MSE):  train=0.0035753403790295124\n",
      "Epoch: 6250/10000 Loss (MSE):  train=0.00356875779107213\n",
      "Epoch: 6260/10000 Loss (MSE):  train=0.003562221536412835\n",
      "Epoch: 6270/10000 Loss (MSE):  train=0.0035557206720113754\n",
      "Epoch: 6280/10000 Loss (MSE):  train=0.0035492684692144394\n",
      "Epoch: 6290/10000 Loss (MSE):  train=0.0035428525879979134\n",
      "Epoch: 6300/10000 Loss (MSE):  train=0.0035364776849746704\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 6310/10000 Loss (MSE):  train=0.0035301470197737217\n",
      "Epoch: 6320/10000 Loss (MSE):  train=0.0035238550044596195\n",
      "Epoch: 6330/10000 Loss (MSE):  train=0.003517600242048502\n",
      "Epoch: 6340/10000 Loss (MSE):  train=0.0035113890189677477\n",
      "Epoch: 6350/10000 Loss (MSE):  train=0.0035052145831286907\n",
      "Epoch: 6360/10000 Loss (MSE):  train=0.003499080194160342\n",
      "Epoch: 6370/10000 Loss (MSE):  train=0.003492982592433691\n",
      "Epoch: 6380/10000 Loss (MSE):  train=0.0034869255032390356\n",
      "Epoch: 6390/10000 Loss (MSE):  train=0.0034809045027941465\n",
      "Epoch: 6400/10000 Loss (MSE):  train=0.003474922850728035\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 6410/10000 Loss (MSE):  train=0.0034689735621213913\n",
      "Epoch: 6420/10000 Loss (MSE):  train=0.0034630666486918926\n",
      "Epoch: 6430/10000 Loss (MSE):  train=0.0034571934957057238\n",
      "Epoch: 6440/10000 Loss (MSE):  train=0.003451359923928976\n",
      "Epoch: 6450/10000 Loss (MSE):  train=0.0034455587156116962\n",
      "Epoch: 6460/10000 Loss (MSE):  train=0.0034397938288748264\n",
      "Epoch: 6470/10000 Loss (MSE):  train=0.0034340654965490103\n",
      "Epoch: 6480/10000 Loss (MSE):  train=0.0034283713903278112\n",
      "Epoch: 6490/10000 Loss (MSE):  train=0.003422715235501528\n",
      "Epoch: 6500/10000 Loss (MSE):  train=0.003417088184505701\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 6510/10000 Loss (MSE):  train=0.0034114967565983534\n",
      "Epoch: 6520/10000 Loss (MSE):  train=0.0034059383906424046\n",
      "Epoch: 6530/10000 Loss (MSE):  train=0.003400414949283004\n",
      "Epoch: 6540/10000 Loss (MSE):  train=0.003394926432520151\n",
      "Epoch: 6550/10000 Loss (MSE):  train=0.0033894686494022608\n",
      "Epoch: 6560/10000 Loss (MSE):  train=0.003384043462574482\n",
      "Epoch: 6570/10000 Loss (MSE):  train=0.0033786522690206766\n",
      "Epoch: 6580/10000 Loss (MSE):  train=0.003373293438926339\n",
      "Epoch: 6590/10000 Loss (MSE):  train=0.003367966040968895\n",
      "Epoch: 6600/10000 Loss (MSE):  train=0.0033626677468419075\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 6610/10000 Loss (MSE):  train=0.0033574048429727554\n",
      "Epoch: 6620/10000 Loss (MSE):  train=0.0033521701116114855\n",
      "Epoch: 6630/10000 Loss (MSE):  train=0.003346967976540327\n",
      "Epoch: 6640/10000 Loss (MSE):  train=0.0033417977392673492\n",
      "Epoch: 6650/10000 Loss (MSE):  train=0.003336656605824828\n",
      "Epoch: 6660/10000 Loss (MSE):  train=0.0033315434120595455\n",
      "Epoch: 6670/10000 Loss (MSE):  train=0.003326463047415018\n",
      "Epoch: 6680/10000 Loss (MSE):  train=0.003321410156786442\n",
      "Epoch: 6690/10000 Loss (MSE):  train=0.003316387999802828\n",
      "Epoch: 6700/10000 Loss (MSE):  train=0.0033113951794803143\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 6710/10000 Loss (MSE):  train=0.0033064312301576138\n",
      "Epoch: 6720/10000 Loss (MSE):  train=0.003301494289189577\n",
      "Epoch: 6730/10000 Loss (MSE):  train=0.0032965855207294226\n",
      "Epoch: 6740/10000 Loss (MSE):  train=0.003291707020252943\n",
      "Epoch: 6750/10000 Loss (MSE):  train=0.0032868573907762766\n",
      "Epoch: 6760/10000 Loss (MSE):  train=0.0032820345368236303\n",
      "Epoch: 6770/10000 Loss (MSE):  train=0.0032772370614111423\n",
      "Epoch: 6780/10000 Loss (MSE):  train=0.0032724710181355476\n",
      "Epoch: 6790/10000 Loss (MSE):  train=0.0032677287235856056\n",
      "Epoch: 6800/10000 Loss (MSE):  train=0.003263015765696764\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 6810/10000 Loss (MSE):  train=0.0032583274878561497\n",
      "Epoch: 6820/10000 Loss (MSE):  train=0.00325366691686213\n",
      "Epoch: 6830/10000 Loss (MSE):  train=0.0032490312587469816\n",
      "Epoch: 6840/10000 Loss (MSE):  train=0.0032444261014461517\n",
      "Epoch: 6850/10000 Loss (MSE):  train=0.003239840269088745\n",
      "Epoch: 6860/10000 Loss (MSE):  train=0.0032352835405617952\n",
      "Epoch: 6870/10000 Loss (MSE):  train=0.0032307528890669346\n",
      "Epoch: 6880/10000 Loss (MSE):  train=0.0032262434251606464\n",
      "Epoch: 6890/10000 Loss (MSE):  train=0.0032217635307461023\n",
      "Epoch: 6900/10000 Loss (MSE):  train=0.0032173097133636475\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 6910/10000 Loss (MSE):  train=0.0032128761522471905\n",
      "Epoch: 6920/10000 Loss (MSE):  train=0.003208467271178961\n",
      "Epoch: 6930/10000 Loss (MSE):  train=0.0032040877267718315\n",
      "Epoch: 6940/10000 Loss (MSE):  train=0.0031997300684452057\n",
      "Epoch: 6950/10000 Loss (MSE):  train=0.0031953947618603706\n",
      "Epoch: 6960/10000 Loss (MSE):  train=0.0031910836696624756\n",
      "Epoch: 6970/10000 Loss (MSE):  train=0.003186795860528946\n",
      "Epoch: 6980/10000 Loss (MSE):  train=0.0031825334299355745\n",
      "Epoch: 6990/10000 Loss (MSE):  train=0.0031782914884388447\n",
      "Epoch: 7000/10000 Loss (MSE):  train=0.0031740760896354914\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 7010/10000 Loss (MSE):  train=0.0031698811799287796\n",
      "Epoch: 7020/10000 Loss (MSE):  train=0.003165709786117077\n",
      "Epoch: 7030/10000 Loss (MSE):  train=0.0031615591142326593\n",
      "Epoch: 7040/10000 Loss (MSE):  train=0.0031574321910738945\n",
      "Epoch: 7050/10000 Loss (MSE):  train=0.003153328550979495\n",
      "Epoch: 7060/10000 Loss (MSE):  train=0.0031492458656430244\n",
      "Epoch: 7070/10000 Loss (MSE):  train=0.0031451834365725517\n",
      "Epoch: 7080/10000 Loss (MSE):  train=0.003141148015856743\n",
      "Epoch: 7090/10000 Loss (MSE):  train=0.003137127263471484\n",
      "Epoch: 7100/10000 Loss (MSE):  train=0.0031331321224570274\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 7110/10000 Loss (MSE):  train=0.003129156306385994\n",
      "Epoch: 7120/10000 Loss (MSE):  train=0.003125203540548682\n",
      "Epoch: 7130/10000 Loss (MSE):  train=0.0031212717294692993\n",
      "Epoch: 7140/10000 Loss (MSE):  train=0.0031173601746559143\n",
      "Epoch: 7150/10000 Loss (MSE):  train=0.003113468876108527\n",
      "Epoch: 7160/10000 Loss (MSE):  train=0.003109598532319069\n",
      "Epoch: 7170/10000 Loss (MSE):  train=0.0031057470478117466\n",
      "Epoch: 7180/10000 Loss (MSE):  train=0.0031019155867397785\n",
      "Epoch: 7190/10000 Loss (MSE):  train=0.0030981029849499464\n",
      "Epoch: 7200/10000 Loss (MSE):  train=0.0030943136662244797\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 7210/10000 Loss (MSE):  train=0.003090544603765011\n",
      "Epoch: 7220/10000 Loss (MSE):  train=0.0030867925379425287\n",
      "Epoch: 7230/10000 Loss (MSE):  train=0.0030830595642328262\n",
      "Epoch: 7240/10000 Loss (MSE):  train=0.003079345216974616\n",
      "Epoch: 7250/10000 Loss (MSE):  train=0.0030756539199501276\n",
      "Epoch: 7260/10000 Loss (MSE):  train=0.003071980085223913\n",
      "Epoch: 7270/10000 Loss (MSE):  train=0.003068323712795973\n",
      "Epoch: 7280/10000 Loss (MSE):  train=0.0030646873638033867\n",
      "Epoch: 7290/10000 Loss (MSE):  train=0.0030610673129558563\n",
      "Epoch: 7300/10000 Loss (MSE):  train=0.00305746728554368\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 7310/10000 Loss (MSE):  train=0.003053886815905571\n",
      "Epoch: 7320/10000 Loss (MSE):  train=0.0030503226444125175\n",
      "Epoch: 7330/10000 Loss (MSE):  train=0.0030467803589999676\n",
      "Epoch: 7340/10000 Loss (MSE):  train=0.003043249947950244\n",
      "Epoch: 7350/10000 Loss (MSE):  train=0.003039740491658449\n",
      "Epoch: 7360/10000 Loss (MSE):  train=0.0030362482648342848\n",
      "Epoch: 7370/10000 Loss (MSE):  train=0.003032776527106762\n",
      "Epoch: 7380/10000 Loss (MSE):  train=0.0030293180607259274\n",
      "Epoch: 7390/10000 Loss (MSE):  train=0.0030258772894740105\n",
      "Epoch: 7400/10000 Loss (MSE):  train=0.003022455610334873\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 7410/10000 Loss (MSE):  train=0.0030190511606633663\n",
      "Epoch: 7420/10000 Loss (MSE):  train=0.003015662543475628\n",
      "Epoch: 7430/10000 Loss (MSE):  train=0.003012292552739382\n",
      "Epoch: 7440/10000 Loss (MSE):  train=0.0030089369975030422\n",
      "Epoch: 7450/10000 Loss (MSE):  train=0.0030055977404117584\n",
      "Epoch: 7460/10000 Loss (MSE):  train=0.003002275014296174\n",
      "Epoch: 7470/10000 Loss (MSE):  train=0.0029989685863256454\n",
      "Epoch: 7480/10000 Loss (MSE):  train=0.0029956784565001726\n",
      "Epoch: 7490/10000 Loss (MSE):  train=0.0029924074187874794\n",
      "Epoch: 7500/10000 Loss (MSE):  train=0.0029891510494053364\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 7510/10000 Loss (MSE):  train=0.0029859114438295364\n",
      "Epoch: 7520/10000 Loss (MSE):  train=0.0029826839454472065\n",
      "Epoch: 7530/10000 Loss (MSE):  train=0.002979476470500231\n",
      "Epoch: 7540/10000 Loss (MSE):  train=0.0029762820340692997\n",
      "Epoch: 7550/10000 Loss (MSE):  train=0.0029731052927672863\n",
      "Epoch: 7560/10000 Loss (MSE):  train=0.002969942521303892\n",
      "Epoch: 7570/10000 Loss (MSE):  train=0.002966793719679117\n",
      "Epoch: 7580/10000 Loss (MSE):  train=0.0029636616818606853\n",
      "Epoch: 7590/10000 Loss (MSE):  train=0.0029605438467115164\n",
      "Epoch: 7600/10000 Loss (MSE):  train=0.002957442309707403\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 7610/10000 Loss (MSE):  train=0.002954354276880622\n",
      "Epoch: 7620/10000 Loss (MSE):  train=0.0029512804467231035\n",
      "Epoch: 7630/10000 Loss (MSE):  train=0.0029482217505574226\n",
      "Epoch: 7640/10000 Loss (MSE):  train=0.002945180982351303\n",
      "Epoch: 7650/10000 Loss (MSE):  train=0.002942151390016079\n",
      "Epoch: 7660/10000 Loss (MSE):  train=0.002939137164503336\n",
      "Epoch: 7670/10000 Loss (MSE):  train=0.0029361366759985685\n",
      "Epoch: 7680/10000 Loss (MSE):  train=0.0029331506229937077\n",
      "Epoch: 7690/10000 Loss (MSE):  train=0.002930177142843604\n",
      "Epoch: 7700/10000 Loss (MSE):  train=0.0029272197280079126\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 7710/10000 Loss (MSE):  train=0.002924275817349553\n",
      "Epoch: 7720/10000 Loss (MSE):  train=0.0029213461093604565\n",
      "Epoch: 7730/10000 Loss (MSE):  train=0.002918427810072899\n",
      "Epoch: 7740/10000 Loss (MSE):  train=0.002915523946285248\n",
      "Epoch: 7750/10000 Loss (MSE):  train=0.0029126370791345835\n",
      "Epoch: 7760/10000 Loss (MSE):  train=0.002909759059548378\n",
      "Epoch: 7770/10000 Loss (MSE):  train=0.0029068957082927227\n",
      "Epoch: 7780/10000 Loss (MSE):  train=0.002904048888012767\n",
      "Epoch: 7790/10000 Loss (MSE):  train=0.00290121091529727\n",
      "Epoch: 7800/10000 Loss (MSE):  train=0.0028983871452510357\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 7810/10000 Loss (MSE):  train=0.0028955775778740644\n",
      "Epoch: 7820/10000 Loss (MSE):  train=0.002892780117690563\n",
      "Epoch: 7830/10000 Loss (MSE):  train=0.0028899989556521177\n",
      "Epoch: 7840/10000 Loss (MSE):  train=0.002887225477024913\n",
      "Epoch: 7850/10000 Loss (MSE):  train=0.0028844675980508327\n",
      "Epoch: 7860/10000 Loss (MSE):  train=0.0028817211277782917\n",
      "Epoch: 7870/10000 Loss (MSE):  train=0.0028789862990379333\n",
      "Epoch: 7880/10000 Loss (MSE):  train=0.002876263577491045\n",
      "Epoch: 7890/10000 Loss (MSE):  train=0.0028735543601214886\n",
      "Epoch: 7900/10000 Loss (MSE):  train=0.0028708581812679768\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 7910/10000 Loss (MSE):  train=0.0028681738767772913\n",
      "Epoch: 7920/10000 Loss (MSE):  train=0.0028655012138187885\n",
      "Epoch: 7930/10000 Loss (MSE):  train=0.002862841123715043\n",
      "Epoch: 7940/10000 Loss (MSE):  train=0.002860194304957986\n",
      "Epoch: 7950/10000 Loss (MSE):  train=0.002857554005458951\n",
      "Epoch: 7960/10000 Loss (MSE):  train=0.002854930004104972\n",
      "Epoch: 7970/10000 Loss (MSE):  train=0.00285231857560575\n",
      "Epoch: 7980/10000 Loss (MSE):  train=0.0028497162275016308\n",
      "Epoch: 7990/10000 Loss (MSE):  train=0.002847126219421625\n",
      "Epoch: 8000/10000 Loss (MSE):  train=0.0028445497155189514\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 8010/10000 Loss (MSE):  train=0.0028419820591807365\n",
      "Epoch: 8020/10000 Loss (MSE):  train=0.0028394272085279226\n",
      "Epoch: 8030/10000 Loss (MSE):  train=0.002836881671100855\n",
      "Epoch: 8040/10000 Loss (MSE):  train=0.0028343487065285444\n",
      "Epoch: 8050/10000 Loss (MSE):  train=0.002831827849149704\n",
      "Epoch: 8060/10000 Loss (MSE):  train=0.002829318167641759\n",
      "Epoch: 8070/10000 Loss (MSE):  train=0.002826819196343422\n",
      "Epoch: 8080/10000 Loss (MSE):  train=0.002824332332238555\n",
      "Epoch: 8090/10000 Loss (MSE):  train=0.0028218538500368595\n",
      "Epoch: 8100/10000 Loss (MSE):  train=0.0028193872421979904\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 8110/10000 Loss (MSE):  train=0.0028169311117380857\n",
      "Epoch: 8120/10000 Loss (MSE):  train=0.002814484992995858\n",
      "Epoch: 8130/10000 Loss (MSE):  train=0.0028120519127696753\n",
      "Epoch: 8140/10000 Loss (MSE):  train=0.002809627680107951\n",
      "Epoch: 8150/10000 Loss (MSE):  train=0.002807213459163904\n",
      "Epoch: 8160/10000 Loss (MSE):  train=0.00280481344088912\n",
      "Epoch: 8170/10000 Loss (MSE):  train=0.0028024192433804274\n",
      "Epoch: 8180/10000 Loss (MSE):  train=0.0028000366874039173\n",
      "Epoch: 8190/10000 Loss (MSE):  train=0.00279766577295959\n",
      "Epoch: 8200/10000 Loss (MSE):  train=0.002795303473249078\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 8210/10000 Loss (MSE):  train=0.0027929528150707483\n",
      "Epoch: 8220/10000 Loss (MSE):  train=0.0027906084433197975\n",
      "Epoch: 8230/10000 Loss (MSE):  train=0.0027882796712219715\n",
      "Epoch: 8240/10000 Loss (MSE):  train=0.002785957418382168\n",
      "Epoch: 8250/10000 Loss (MSE):  train=0.002783645875751972\n",
      "Epoch: 8260/10000 Loss (MSE):  train=0.0027813457418233156\n",
      "Epoch: 8270/10000 Loss (MSE):  train=0.002779054921120405\n",
      "Epoch: 8280/10000 Loss (MSE):  train=0.0027767708525061607\n",
      "Epoch: 8290/10000 Loss (MSE):  train=0.00277449912391603\n",
      "Epoch: 8300/10000 Loss (MSE):  train=0.0027722371742129326\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 8310/10000 Loss (MSE):  train=0.0027699843049049377\n",
      "Epoch: 8320/10000 Loss (MSE):  train=0.0027677419129759073\n",
      "Epoch: 8330/10000 Loss (MSE):  train=0.0027655072044581175\n",
      "Epoch: 8340/10000 Loss (MSE):  train=0.0027632846031337976\n",
      "Epoch: 8350/10000 Loss (MSE):  train=0.002761070616543293\n",
      "Epoch: 8360/10000 Loss (MSE):  train=0.002758862916380167\n",
      "Epoch: 8370/10000 Loss (MSE):  train=0.002756665926426649\n",
      "Epoch: 8380/10000 Loss (MSE):  train=0.0027544789481908083\n",
      "Epoch: 8390/10000 Loss (MSE):  train=0.002752301748842001\n",
      "Epoch: 8400/10000 Loss (MSE):  train=0.0027501315344125032\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 8410/10000 Loss (MSE):  train=0.002747972495853901\n",
      "Epoch: 8420/10000 Loss (MSE):  train=0.0027458216063678265\n",
      "Epoch: 8430/10000 Loss (MSE):  train=0.00274367886595428\n",
      "Epoch: 8440/10000 Loss (MSE):  train=0.0027415468357503414\n",
      "Epoch: 8450/10000 Loss (MSE):  train=0.002739423420280218\n",
      "Epoch: 8460/10000 Loss (MSE):  train=0.0027373088523745537\n",
      "Epoch: 8470/10000 Loss (MSE):  train=0.002735202433541417\n",
      "Epoch: 8480/10000 Loss (MSE):  train=0.002733104396611452\n",
      "Epoch: 8490/10000 Loss (MSE):  train=0.0027310154400765896\n",
      "Epoch: 8500/10000 Loss (MSE):  train=0.0027289355639368296\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 8510/10000 Loss (MSE):  train=0.0027268624398857355\n",
      "Epoch: 8520/10000 Loss (MSE):  train=0.002724801190197468\n",
      "Epoch: 8530/10000 Loss (MSE):  train=0.0027227464597672224\n",
      "Epoch: 8540/10000 Loss (MSE):  train=0.002720703138038516\n",
      "Epoch: 8550/10000 Loss (MSE):  train=0.0027186647057533264\n",
      "Epoch: 8560/10000 Loss (MSE):  train=0.0027166344225406647\n",
      "Epoch: 8570/10000 Loss (MSE):  train=0.00271461415104568\n",
      "Epoch: 8580/10000 Loss (MSE):  train=0.002712602261453867\n",
      "Epoch: 8590/10000 Loss (MSE):  train=0.002710597589612007\n",
      "Epoch: 8600/10000 Loss (MSE):  train=0.00270860199816525\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 8610/10000 Loss (MSE):  train=0.0027066131588071585\n",
      "Epoch: 8620/10000 Loss (MSE):  train=0.0027046361938118935\n",
      "Epoch: 8630/10000 Loss (MSE):  train=0.002702660858631134\n",
      "Epoch: 8640/10000 Loss (MSE):  train=0.0027006997261196375\n",
      "Epoch: 8650/10000 Loss (MSE):  train=0.002698743948712945\n",
      "Epoch: 8660/10000 Loss (MSE):  train=0.0026967967860400677\n",
      "Epoch: 8670/10000 Loss (MSE):  train=0.0026948566082865\n",
      "Epoch: 8680/10000 Loss (MSE):  train=0.0026929243467748165\n",
      "Epoch: 8690/10000 Loss (MSE):  train=0.002691000234335661\n",
      "Epoch: 8700/10000 Loss (MSE):  train=0.002689086366444826\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 8710/10000 Loss (MSE):  train=0.0026871764566749334\n",
      "Epoch: 8720/10000 Loss (MSE):  train=0.0026852760929614305\n",
      "Epoch: 8730/10000 Loss (MSE):  train=0.002683384343981743\n",
      "Epoch: 8740/10000 Loss (MSE):  train=0.0026815009769052267\n",
      "Epoch: 8750/10000 Loss (MSE):  train=0.0026796236634254456\n",
      "Epoch: 8760/10000 Loss (MSE):  train=0.0026777544990181923\n",
      "Epoch: 8770/10000 Loss (MSE):  train=0.0026758904568850994\n",
      "Epoch: 8780/10000 Loss (MSE):  train=0.0026740371249616146\n",
      "Epoch: 8790/10000 Loss (MSE):  train=0.0026721905451267958\n",
      "Epoch: 8800/10000 Loss (MSE):  train=0.0026703523471951485\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 8810/10000 Loss (MSE):  train=0.002668519737198949\n",
      "Epoch: 8820/10000 Loss (MSE):  train=0.0026666936464607716\n",
      "Epoch: 8830/10000 Loss (MSE):  train=0.0026648780331015587\n",
      "Epoch: 8840/10000 Loss (MSE):  train=0.0026630680076777935\n",
      "Epoch: 8850/10000 Loss (MSE):  train=0.002661266829818487\n",
      "Epoch: 8860/10000 Loss (MSE):  train=0.0026594693772494793\n",
      "Epoch: 8870/10000 Loss (MSE):  train=0.0026576844975352287\n",
      "Epoch: 8880/10000 Loss (MSE):  train=0.002655902411788702\n",
      "Epoch: 8890/10000 Loss (MSE):  train=0.0026541301049292088\n",
      "Epoch: 8900/10000 Loss (MSE):  train=0.002652363386005163\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 8910/10000 Loss (MSE):  train=0.002650606445968151\n",
      "Epoch: 8920/10000 Loss (MSE):  train=0.002648853464052081\n",
      "Epoch: 8930/10000 Loss (MSE):  train=0.0026471074670553207\n",
      "Epoch: 8940/10000 Loss (MSE):  train=0.0026453714817762375\n",
      "Epoch: 8950/10000 Loss (MSE):  train=0.00264363968744874\n",
      "Epoch: 8960/10000 Loss (MSE):  train=0.0026419174391776323\n",
      "Epoch: 8970/10000 Loss (MSE):  train=0.0026402021758258343\n",
      "Epoch: 8980/10000 Loss (MSE):  train=0.002638490404933691\n",
      "Epoch: 8990/10000 Loss (MSE):  train=0.002636789809912443\n",
      "Epoch: 9000/10000 Loss (MSE):  train=0.0026350931730121374\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 9010/10000 Loss (MSE):  train=0.0026334072463214397\n",
      "Epoch: 9020/10000 Loss (MSE):  train=0.0026317238807678223\n",
      "Epoch: 9030/10000 Loss (MSE):  train=0.002630049828439951\n",
      "Epoch: 9040/10000 Loss (MSE):  train=0.0026283799670636654\n",
      "Epoch: 9050/10000 Loss (MSE):  train=0.0026267212815582752\n",
      "Epoch: 9060/10000 Loss (MSE):  train=0.002625067252665758\n",
      "Epoch: 9070/10000 Loss (MSE):  train=0.002623417181894183\n",
      "Epoch: 9080/10000 Loss (MSE):  train=0.0026217750273644924\n",
      "Epoch: 9090/10000 Loss (MSE):  train=0.002620144048705697\n",
      "Epoch: 9100/10000 Loss (MSE):  train=0.0026185167953372\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 9110/10000 Loss (MSE):  train=0.0026168960612267256\n",
      "Epoch: 9120/10000 Loss (MSE):  train=0.002615282079204917\n",
      "Epoch: 9130/10000 Loss (MSE):  train=0.0026136732194572687\n",
      "Epoch: 9140/10000 Loss (MSE):  train=0.0026120711117982864\n",
      "Epoch: 9150/10000 Loss (MSE):  train=0.002610478550195694\n",
      "Epoch: 9160/10000 Loss (MSE):  train=0.0026088901795446873\n",
      "Epoch: 9170/10000 Loss (MSE):  train=0.002607309492304921\n",
      "Epoch: 9180/10000 Loss (MSE):  train=0.00260573485866189\n",
      "Epoch: 9190/10000 Loss (MSE):  train=0.002604165580123663\n",
      "Epoch: 9200/10000 Loss (MSE):  train=0.0026026039849966764\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 9210/10000 Loss (MSE):  train=0.002601047046482563\n",
      "Epoch: 9220/10000 Loss (MSE):  train=0.00259949779137969\n",
      "Epoch: 9230/10000 Loss (MSE):  train=0.0025979557540267706\n",
      "Epoch: 9240/10000 Loss (MSE):  train=0.002596417674794793\n",
      "Epoch: 9250/10000 Loss (MSE):  train=0.0025948898401111364\n",
      "Epoch: 9260/10000 Loss (MSE):  train=0.002593365730717778\n",
      "Epoch: 9270/10000 Loss (MSE):  train=0.0025918479077517986\n",
      "Epoch: 9280/10000 Loss (MSE):  train=0.0025903363712131977\n",
      "Epoch: 9290/10000 Loss (MSE):  train=0.0025888336822390556\n",
      "Epoch: 9300/10000 Loss (MSE):  train=0.002587332157418132\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 9310/10000 Loss (MSE):  train=0.002585839945822954\n",
      "Epoch: 9320/10000 Loss (MSE):  train=0.0025843523908406496\n",
      "Epoch: 9330/10000 Loss (MSE):  train=0.002582872984930873\n",
      "Epoch: 9340/10000 Loss (MSE):  train=0.0025813973043113947\n",
      "Epoch: 9350/10000 Loss (MSE):  train=0.0025799295399338007\n",
      "Epoch: 9360/10000 Loss (MSE):  train=0.002578467596322298\n",
      "Epoch: 9370/10000 Loss (MSE):  train=0.0025770128704607487\n",
      "Epoch: 9380/10000 Loss (MSE):  train=0.0025755621027201414\n",
      "Epoch: 9390/10000 Loss (MSE):  train=0.002574116690084338\n",
      "Epoch: 9400/10000 Loss (MSE):  train=0.0025726789608597755\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 9410/10000 Loss (MSE):  train=0.002571245888248086\n",
      "Epoch: 9420/10000 Loss (MSE):  train=0.0025698195677250624\n",
      "Epoch: 9430/10000 Loss (MSE):  train=0.002568397205322981\n",
      "Epoch: 9440/10000 Loss (MSE):  train=0.0025669815950095654\n",
      "Epoch: 9450/10000 Loss (MSE):  train=0.0025655748322606087\n",
      "Epoch: 9460/10000 Loss (MSE):  train=0.002564171561971307\n",
      "Epoch: 9470/10000 Loss (MSE):  train=0.00256277434527874\n",
      "Epoch: 9480/10000 Loss (MSE):  train=0.0025613834150135517\n",
      "Epoch: 9490/10000 Loss (MSE):  train=0.0025599959772080183\n",
      "Epoch: 9500/10000 Loss (MSE):  train=0.00255861459299922\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 9510/10000 Loss (MSE):  train=0.0025572394952178\n",
      "Epoch: 9520/10000 Loss (MSE):  train=0.0025558695197105408\n",
      "Epoch: 9530/10000 Loss (MSE):  train=0.0025545069947838783\n",
      "Epoch: 9540/10000 Loss (MSE):  train=0.002553149126470089\n",
      "Epoch: 9550/10000 Loss (MSE):  train=0.0025517973117530346\n",
      "Epoch: 9560/10000 Loss (MSE):  train=0.0025504494551569223\n",
      "Epoch: 9570/10000 Loss (MSE):  train=0.002549108350649476\n",
      "Epoch: 9580/10000 Loss (MSE):  train=0.002547771204262972\n",
      "Epoch: 9590/10000 Loss (MSE):  train=0.0025464396458119154\n",
      "Epoch: 9600/10000 Loss (MSE):  train=0.002545114140957594\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 9610/10000 Loss (MSE):  train=0.0025437953881919384\n",
      "Epoch: 9620/10000 Loss (MSE):  train=0.0025424796622246504\n",
      "Epoch: 9630/10000 Loss (MSE):  train=0.002541170921176672\n",
      "Epoch: 9640/10000 Loss (MSE):  train=0.0025398670695722103\n",
      "Epoch: 9650/10000 Loss (MSE):  train=0.0025385692715644836\n",
      "Epoch: 9660/10000 Loss (MSE):  train=0.0025372749660164118\n",
      "Epoch: 9670/10000 Loss (MSE):  train=0.002535988111048937\n",
      "Epoch: 9680/10000 Loss (MSE):  train=0.002534702653065324\n",
      "Epoch: 9690/10000 Loss (MSE):  train=0.0025334248784929514\n",
      "Epoch: 9700/10000 Loss (MSE):  train=0.0025321519933640957\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 9710/10000 Loss (MSE):  train=0.0025308839976787567\n",
      "Epoch: 9720/10000 Loss (MSE):  train=0.002529620658606291\n",
      "Epoch: 9730/10000 Loss (MSE):  train=0.002528360579162836\n",
      "Epoch: 9740/10000 Loss (MSE):  train=0.002527108881622553\n",
      "Epoch: 9750/10000 Loss (MSE):  train=0.002525861607864499\n",
      "Epoch: 9760/10000 Loss (MSE):  train=0.0025246189907193184\n",
      "Epoch: 9770/10000 Loss (MSE):  train=0.0025233805645257235\n",
      "Epoch: 9780/10000 Loss (MSE):  train=0.002522145863622427\n",
      "Epoch: 9790/10000 Loss (MSE):  train=0.0025209214072674513\n",
      "Epoch: 9800/10000 Loss (MSE):  train=0.002519697416573763\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 9810/10000 Loss (MSE):  train=0.0025184766855090857\n",
      "Epoch: 9820/10000 Loss (MSE):  train=0.0025172648020088673\n",
      "Epoch: 9830/10000 Loss (MSE):  train=0.0025160545483231544\n",
      "Epoch: 9840/10000 Loss (MSE):  train=0.0025148498825728893\n",
      "Epoch: 9850/10000 Loss (MSE):  train=0.00251364940777421\n",
      "Epoch: 9860/10000 Loss (MSE):  train=0.002512456849217415\n",
      "Epoch: 9870/10000 Loss (MSE):  train=0.002511265454813838\n",
      "Epoch: 9880/10000 Loss (MSE):  train=0.002510080114006996\n",
      "Epoch: 9890/10000 Loss (MSE):  train=0.002508897101506591\n",
      "Epoch: 9900/10000 Loss (MSE):  train=0.002507720375433564\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/loss_array.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "Epoch: 9910/10000 Loss (MSE):  train=0.002506550867110491\n",
      "Epoch: 9920/10000 Loss (MSE):  train=0.0025053820572793484\n",
      "Epoch: 9930/10000 Loss (MSE):  train=0.0025042202323675156\n",
      "Epoch: 9940/10000 Loss (MSE):  train=0.002503061667084694\n",
      "Epoch: 9950/10000 Loss (MSE):  train=0.0025019082240760326\n",
      "Epoch: 9960/10000 Loss (MSE):  train=0.002500757575035095\n",
      "Epoch: 9970/10000 Loss (MSE):  train=0.0024996118154376745\n",
      "Epoch: 9980/10000 Loss (MSE):  train=0.002498473273590207\n",
      "Epoch: 9990/10000 Loss (MSE):  train=0.0024973340332508087\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/training_loss.png ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/05-17-2023_03-29-19/fgnode_trained_model_low.dil ===\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def loss_fn(params, Rs, Rs_1_ac):\n",
    "    Rs_1_pred = v_v_next_step_fn_model(Rs, params)\n",
    "    return MSE(Rs_1_pred, Rs_1_ac)\n",
    "\n",
    "def gloss(*args):\n",
    "    return value_and_grad(loss_fn)(*args)\n",
    "\n",
    "def update(i, opt_state, params, loss__, *data):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads_ = gloss(params, *data)\n",
    "    opt_state = opt_update(i, grads_, opt_state)\n",
    "    return opt_state, get_params(opt_state), value\n",
    "\n",
    "@jit\n",
    "def step(i, ps, *args):\n",
    "    return update(i, *ps, *args)\n",
    "\n",
    "opt_init, opt_update_, get_params = optimizers.adam(lr)\n",
    "\n",
    "@jit\n",
    "def opt_update(i, grads_, opt_state):\n",
    "    grads_ = jax.tree_map(jnp.nan_to_num, grads_)\n",
    "    grads_ = jax.tree_map(partial(jnp.clip, a_min=-1000.0, a_max=1000.0), grads_)\n",
    "    return opt_update_(i, grads_, opt_state)\n",
    "\n",
    "def batching(*args, size=None):\n",
    "    L = len(args[0])\n",
    "    if size != None:\n",
    "        nbatches1 = int((L - 0.5) // size) + 1\n",
    "        nbatches2 = max(1, nbatches1 - 1)\n",
    "        size1 = int(L/nbatches1)\n",
    "        size2 = int(L/nbatches2)\n",
    "        if size1*nbatches1 > size2*nbatches2:\n",
    "            size = size1\n",
    "            nbatches = nbatches1\n",
    "        else:\n",
    "            size = size2\n",
    "            nbatches = nbatches2\n",
    "    else:\n",
    "        nbatches = 1\n",
    "        size = L\n",
    "    \n",
    "    newargs = []\n",
    "    for arg in args:\n",
    "        newargs += [jnp.array([arg[i*size:(i+1)*size]\n",
    "                                for i in range(nbatches)])]\n",
    "    return newargs\n",
    "\n",
    "bRs_in, bRs_out = batching(Rs_in, Rs_out, size=min(len(Rs_in), batch_size))\n",
    "\n",
    "print(f\"training ...\")\n",
    "\n",
    "opt_state = opt_init(params)\n",
    "epoch = 0\n",
    "optimizer_step = -1\n",
    "larray = []\n",
    "ltarray = []\n",
    "last_loss = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    l = 0.0\n",
    "    count = 0\n",
    "    for data in zip(bRs_in, bRs_out):\n",
    "        optimizer_step += 1\n",
    "        opt_state, params, l_ = step(\n",
    "            optimizer_step, (opt_state, params, 0), *data)\n",
    "        l += l_\n",
    "        count+=1\n",
    "    # print(\"epoch,countttttt: \", epoch,count)\n",
    "    # opt_state, params, l_ = step(optimizer_step, (opt_state, params, 0), Rs, Vs, Fs)\n",
    "    l = l/count\n",
    "    larray += [l]\n",
    "    # ltarray += [loss_fn(params, bRs_in, bVs_in, bRs_out)]\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}/{epochs} Loss (MSE):  train={larray[-1]}\")#, test={ltarray[-1]}\")\n",
    "    if epoch % 100 == 0:\n",
    "        metadata = {\n",
    "            \"savedat\": epoch,\n",
    "            # \"mpass\": mpass,\n",
    "            }\n",
    "        savefile(f\"fgnode_trained_model.dil\",\n",
    "                    params, metadata=metadata)\n",
    "        # savefile(f\"loss_array.dil\", (larray, ltarray), metadata=metadata)\n",
    "        savefile(f\"loss_array.dil\", larray, metadata=metadata)\n",
    "        if last_loss > larray[-1]:\n",
    "            last_loss = larray[-1]\n",
    "            savefile(f\"fgnode_trained_model_low.dil\",\n",
    "                        params, metadata=metadata)\n",
    "        fig, axs = panel(1, 1)\n",
    "        # plt.semilogy(larray, label=\"Training\")\n",
    "        plt.plot(larray, label=\"Training\")\n",
    "        # plt.semilogy(ltarray, label=\"Test\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(_filename(f\"training_loss.png\"))\n",
    "\n",
    "fig, axs = panel(1, 1)\n",
    "# plt.semilogy(larray, label=\"Training\")\n",
    "plt.plot(larray, label=\"Training\")\n",
    "# plt.semilogy(ltarray, label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(_filename(f\"training_loss.png\"))\n",
    "\n",
    "params = get_params(opt_state)\n",
    "savefile(f\"fgnode_trained_model.dil\", params, metadata=metadata)\n",
    "# savefile(f\"loss_array.dil\", (larray, ltarray), metadata=metadata)\n",
    "\n",
    "if last_loss > larray[-1]:\n",
    "    last_loss = larray[-1]\n",
    "    savefile(f\"fgnode_trained_model_low.dil\", params, metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params, _ = loadfile(f\"fgnode_trained_model_low.dil\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rname=False\n",
    "\n",
    "# PSYS = f\"a-{N}-Spring-data-brownian_EM\"\n",
    "# TAG = f\"1NN\"\n",
    "# out_dir = f\"../results\"\n",
    "\n",
    "def _filename(name, tag=TAG):\n",
    "    rstring = randfilename if (rname and (tag != \"data\")) else (\n",
    "        \"0\" if (tag == \"data\") or (withdata == None) else f\"0_{withdata}\")\n",
    "    filename_prefix = f\"{out_dir}/{PSYS}-{tag}/{rstring}/\"\n",
    "    file = f\"{filename_prefix}/{name}\"\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    filename = f\"{filename_prefix}/{name}\".replace(\"//\", \"/\")\n",
    "    print(\"===\", filename, \"===\")\n",
    "    return filename\n",
    "\n",
    "def OUT(f):\n",
    "    @wraps(f)\n",
    "    def func(file, *args, tag=TAG, **kwargs):\n",
    "        return f(_filename(file, tag=tag), *args, **kwargs)\n",
    "    return func\n",
    "\n",
    "loadmodel = OUT(src.models.loadmodel)\n",
    "savemodel = OUT(src.models.savemodel)\n",
    "\n",
    "loadfile = OUT(src.io.loadfile)\n",
    "savefile = OUT(src.io.savefile)\n",
    "save_ovito = OUT(src.io.save_ovito)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../results/a-5-Spring-data-brownian_EM-1NN/0/fgnode_trained_model_low.dil ===\n",
      "Loading ../results/a-5-Spring-data-brownian_EM-1NN/0/fgnode_trained_model_low.dil\n"
     ]
    }
   ],
   "source": [
    "params, _ = loadfile(f\"fgnode_trained_model_low.dil\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "spring_constant = 1.0\n",
    "length_constant = 1.0\n",
    "gamma_orig = jnp.ones(jnp.unique(species).shape)\n",
    "stride = 1\n",
    "runs=100\n",
    "\n",
    "def SPRING(x, stiffness=1.0, length=1.0):\n",
    "    x_ = jnp.linalg.norm(x, keepdims=True)\n",
    "    return 0.5*stiffness*(x_ - length)**2\n",
    "\n",
    "def pot_energy_orig(x):\n",
    "    dr = x[senders, :] - x[receivers, :]\n",
    "    return vmap(partial(SPRING, stiffness=spring_constant, length=length_constant))(dr).sum()\n",
    "\n",
    "def force_fn_orig(R, params):\n",
    "    return -grad(pot_energy_orig)(R)\n",
    "\n",
    "def get_forward_sim(params = None, force_fn = None, gamma = None, runs=10):\n",
    "        @jit\n",
    "        def fn(R,key):\n",
    "            return predition_brow(R, params, force_fn, shift, dt, kT, masses, gamma = gamma, stride=stride, runs=runs, key=key)\n",
    "        return fn\n",
    "\n",
    "\n",
    "sim_orig = get_forward_sim(params=None,force_fn=force_fn_orig, gamma=gamma_orig,runs=runs)\n",
    "\n",
    "# model\n",
    "def get_forward_sim_model(params = None, next_step_fn = None, runs=10, stride=1):\n",
    "        next_step_fn = lambda R: next_step_fn_model(R, params)\n",
    "        @jit\n",
    "        def solve_dynamics(R_init):\n",
    "            step = jit(lambda i, R: next_step_fn(R))\n",
    "            def f(R):\n",
    "                y = jax.lax.fori_loop(0, stride, step, R)\n",
    "                return y, y\n",
    "            \n",
    "            def func(R, i): return f(R)\n",
    "            @jit\n",
    "            def scan(R0):\n",
    "                return jax.lax.scan(func, R0, jnp.array(range(runs)))\n",
    "            \n",
    "            final_state, traj = scan(R_init)\n",
    "            return traj\n",
    "        return solve_dynamics\n",
    "\n",
    "sim_model = get_forward_sim_model(params = params, next_step_fn = next_step_fn_model, runs=runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_xyz_traj(Filepath,Name,R):\n",
    "    '''Writes ovito xyz file'''\n",
    "    f=open(Filepath,'w')\n",
    "    f.write(str(R.shape[1])+\"\\n\")\n",
    "    f.write(Name)\n",
    "    for i in range(R.shape[0]): #R.shape[0]\n",
    "        for j in range(R.shape[1]):\n",
    "            f.write(\"\\n\"+str(species[j])+\"\\t\"+str(R[i,j,0])+\"\\t\"+str(R[i,j,1])+\"\\t\"+str(R[i,j,2]))\n",
    "        f.write(\"\\n\"+str(R.shape[1]))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating trajectory 0/100 ...\n",
      "=== ../results/a-5-Spring-data-brownian_EM-1NN/0/actual_0_0.xyz ===\n",
      "Saving ovito file: ../results/a-5-Spring-data-brownian_EM-1NN/0/actual_0_0.xyz\n",
      "=== ../results/a-5-Spring-data-brownian_EM-1NN/0/pred_0_0.xyz ===\n",
      "Simulating trajectory 1/100 ...\n",
      "Simulating trajectory 2/100 ...\n",
      "Simulating trajectory 3/100 ...\n",
      "Simulating trajectory 4/100 ...\n",
      "Simulating trajectory 5/100 ...\n",
      "Simulating trajectory 6/100 ...\n",
      "Simulating trajectory 7/100 ...\n",
      "Simulating trajectory 8/100 ...\n",
      "Simulating trajectory 9/100 ...\n",
      "Simulating trajectory 10/100 ...\n",
      "Simulating trajectory 11/100 ...\n",
      "Simulating trajectory 12/100 ...\n",
      "Simulating trajectory 13/100 ...\n",
      "Simulating trajectory 14/100 ...\n",
      "Simulating trajectory 15/100 ...\n",
      "Simulating trajectory 16/100 ...\n",
      "Simulating trajectory 17/100 ...\n",
      "Simulating trajectory 18/100 ...\n",
      "Simulating trajectory 19/100 ...\n",
      "Simulating trajectory 20/100 ...\n",
      "Simulating trajectory 21/100 ...\n",
      "Simulating trajectory 22/100 ...\n",
      "Simulating trajectory 23/100 ...\n",
      "Simulating trajectory 24/100 ...\n",
      "Simulating trajectory 25/100 ...\n",
      "Simulating trajectory 26/100 ...\n",
      "Simulating trajectory 27/100 ...\n",
      "Simulating trajectory 28/100 ...\n",
      "Simulating trajectory 29/100 ...\n",
      "Simulating trajectory 30/100 ...\n",
      "Simulating trajectory 31/100 ...\n",
      "Simulating trajectory 32/100 ...\n",
      "Simulating trajectory 33/100 ...\n",
      "Simulating trajectory 34/100 ...\n",
      "Simulating trajectory 35/100 ...\n",
      "Simulating trajectory 36/100 ...\n",
      "Simulating trajectory 37/100 ...\n",
      "Simulating trajectory 38/100 ...\n",
      "Simulating trajectory 39/100 ...\n",
      "Simulating trajectory 40/100 ...\n",
      "Simulating trajectory 41/100 ...\n",
      "Simulating trajectory 42/100 ...\n",
      "Simulating trajectory 43/100 ...\n",
      "Simulating trajectory 44/100 ...\n",
      "Simulating trajectory 45/100 ...\n",
      "Simulating trajectory 46/100 ...\n",
      "Simulating trajectory 47/100 ...\n",
      "Simulating trajectory 48/100 ...\n",
      "Simulating trajectory 49/100 ...\n",
      "Simulating trajectory 50/100 ...\n",
      "Simulating trajectory 51/100 ...\n",
      "Simulating trajectory 52/100 ...\n",
      "Simulating trajectory 53/100 ...\n",
      "Simulating trajectory 54/100 ...\n",
      "Simulating trajectory 55/100 ...\n",
      "Simulating trajectory 56/100 ...\n",
      "Simulating trajectory 57/100 ...\n",
      "Simulating trajectory 58/100 ...\n",
      "Simulating trajectory 59/100 ...\n",
      "Simulating trajectory 60/100 ...\n",
      "Simulating trajectory 61/100 ...\n",
      "Simulating trajectory 62/100 ...\n",
      "Simulating trajectory 63/100 ...\n",
      "Simulating trajectory 64/100 ...\n",
      "Simulating trajectory 65/100 ...\n",
      "Simulating trajectory 66/100 ...\n",
      "Simulating trajectory 67/100 ...\n",
      "Simulating trajectory 68/100 ...\n",
      "Simulating trajectory 69/100 ...\n",
      "Simulating trajectory 70/100 ...\n",
      "Simulating trajectory 71/100 ...\n",
      "Simulating trajectory 72/100 ...\n",
      "Simulating trajectory 73/100 ...\n",
      "Simulating trajectory 74/100 ...\n",
      "Simulating trajectory 75/100 ...\n",
      "Simulating trajectory 76/100 ...\n",
      "Simulating trajectory 77/100 ...\n",
      "Simulating trajectory 78/100 ...\n",
      "Simulating trajectory 79/100 ...\n",
      "Simulating trajectory 80/100 ...\n",
      "Simulating trajectory 81/100 ...\n",
      "Simulating trajectory 82/100 ...\n",
      "Simulating trajectory 83/100 ...\n",
      "Simulating trajectory 84/100 ...\n",
      "Simulating trajectory 85/100 ...\n",
      "Simulating trajectory 86/100 ...\n",
      "Simulating trajectory 87/100 ...\n",
      "Simulating trajectory 88/100 ...\n",
      "Simulating trajectory 89/100 ...\n",
      "Simulating trajectory 90/100 ...\n",
      "Simulating trajectory 91/100 ...\n",
      "Simulating trajectory 92/100 ...\n",
      "Simulating trajectory 93/100 ...\n",
      "Simulating trajectory 94/100 ...\n",
      "Simulating trajectory 95/100 ...\n",
      "Simulating trajectory 96/100 ...\n",
      "Simulating trajectory 97/100 ...\n",
      "Simulating trajectory 98/100 ...\n",
      "Simulating trajectory 99/100 ...\n",
      "=== ../results/a-5-Spring-data-brownian_EM-1NN/0/error_paramete_plot_a_b_c.pkl ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-1NN/0/error_parameter.pkl ===\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# plotthings = True\n",
    "rng_key = random.PRNGKey(0)\n",
    "maxtraj = 100\n",
    "np.random.seed(seed)\n",
    "key = random.PRNGKey(seed)\n",
    "\n",
    "nexp = {\n",
    "        \"dz_actual\": [],\n",
    "        \"dz_pred\": [],\n",
    "        \"z_actual\": [],\n",
    "        \"z_pred\": [],\n",
    "        \"_gamma\": [],\n",
    "        \"simulation_time\":[],\n",
    "        }\n",
    "\n",
    "trajectories = []\n",
    "for ind in range(maxtraj):\n",
    "    print(f\"Simulating trajectory {ind}/{maxtraj} ...\")\n",
    "    R, _ = chain(N)[:2]\n",
    "    for rand in range(10):\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        actual_traj = sim_orig(R,(ind+13)*subkey)\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        \n",
    "        start = time.time()\n",
    "        pred_pos = sim_model(R)\n",
    "        end = time.time()\n",
    "        nexp[\"simulation_time\"] += [end-start]\n",
    "        \n",
    "        nexp[\"dz_actual\"] += [actual_traj.position-R]\n",
    "        nexp[\"dz_pred\"] += [pred_pos-R]\n",
    "\n",
    "        nexp[\"z_actual\"] += [actual_traj.position]\n",
    "        nexp[\"z_pred\"] += [pred_pos]\n",
    "        \n",
    "        if save_ovito:\n",
    "            if ind<1 and rand<1:\n",
    "                save_ovito(f\"actual_{ind}_{rand}.xyz\", [state for state in BrownianStates(actual_traj)], lattice=\"\")\n",
    "                write_xyz_traj(_filename(f\"pred_{ind}_{rand}.xyz\"),'spring_ddnn',pred_pos)\n",
    "                \n",
    "        # trajectories += [(actual_traj.position, pred_pos)]\n",
    "        # if ind%10==0:\n",
    "        #     savefile(\"trajectories.pkl\", trajectories)\n",
    "\n",
    "\n",
    "def KL_divergence(sigma0,mu0,sigma1,mu1, eps=1e-8):\n",
    "    return jnp.log(sigma1/sigma0) + (jnp.square(sigma0)+jnp.square(mu0-mu1))/(2*jnp.square(sigma1)) - 0.5\n",
    "\n",
    "def get_kld(d_actual, d_pred):\n",
    "    mu0 = jnp.mean(d_actual, axis=(0,2,3))\n",
    "    std0 = jnp.std(d_actual, axis=(0,2,3))\n",
    "    mu1 = jnp.mean(d_pred, axis=(0,2,3))\n",
    "    std1 = jnp.std(d_pred, axis=(0,2,3))\n",
    "    kld = []\n",
    "    for i in range(len(std0)):\n",
    "        kld.append(KL_divergence(std0[i],mu0[i],std1[i],mu1[i]))\n",
    "    return jnp.array(kld)\n",
    "\n",
    "def get_std_rmse(d_actual, d_pred):\n",
    "    std0 = jnp.std(d_actual, axis=(0,2,3))\n",
    "    std1 = jnp.std(d_pred, axis=(0,2,3))\n",
    "    return jnp.sqrt(jnp.square(std0 - std1))\n",
    "\n",
    "def get_dist_by_var(actual, pred, zeta):\n",
    "    disp = displacement(actual, pred)\n",
    "    dist_matrix = jnp.sqrt(jnp.square(disp).sum(-1))\n",
    "    dist_mean = jnp.mean(dist_matrix, axis=(0,2))\n",
    "    dist_by_zeta = dist_mean/zeta\n",
    "    return dist_by_zeta\n",
    "\n",
    "nexp2 = {\n",
    "        \"kld\": [],\n",
    "        \"std_rmse\": [],\n",
    "        }\n",
    "\n",
    "nexp2[\"kld\"] = jnp.array(get_kld(jnp.array(nexp[\"dz_actual\"]),jnp.array(nexp[\"dz_pred\"])))\n",
    "\n",
    "nexp2[\"std_rmse\"] = jnp.array(get_std_rmse(jnp.array(nexp[\"dz_actual\"]),jnp.array(nexp[\"dz_pred\"])))\n",
    "\n",
    "# nexp2[\"dist_by_var\"] = jnp.array(get_dist_by_var(jnp.array(nexp['z_actual']), jnp.array(nexp['z_pred']),1/(jnp.array(nexp['_gamma'])[0][0])))\n",
    "\n",
    "savefile(f\"error_paramete_plot_a_b_c.pkl\", nexp2)\n",
    "# savefile(\"trajectories.pkl\", trajectories)\n",
    "savefile(f\"error_parameter.pkl\", nexp)\n",
    "# savefile(\"trajectories.pkl\", trajectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../results/a-5-Spring-data-brownian_EM-NN/0/mu_sigma.png ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/0/kld1.png ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-NN/0/kld_x_y.png ===\n"
     ]
    }
   ],
   "source": [
    "def KL_divergence(sigma0,mu0,sigma1,mu1, eps=1e-8):\n",
    "    # q = np.where(q == 0.0, eps, q)\n",
    "    # p = np.where(p == 0, eps, p)\n",
    "    return jnp.log(sigma1/sigma0) + (jnp.square(sigma0)+jnp.square(mu0-mu1))/(2*jnp.square(sigma1)) - 0.5\n",
    "\n",
    "actual = jnp.array(nexp[\"dz_actual\"])\n",
    "pred = jnp.array(nexp[\"dz_pred\"])\n",
    "\n",
    "\n",
    "mu0 = jnp.mean(actual, axis=(0,2,3))\n",
    "std0 = jnp.std(actual, axis=(0,2,3))\n",
    "\n",
    "mu1 = jnp.mean(pred, axis=(0,2,3))\n",
    "std1 = jnp.std(pred, axis=(0,2,3))\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(mu0,label='mu0')\n",
    "plt.plot(mu1,label='mu1')\n",
    "plt.plot(std0,label='std0')\n",
    "plt.plot(std1,label='std1')\n",
    "plt.legend()\n",
    "plt.savefig(_filename('mu_sigma.png'))\n",
    "plt.clf()\n",
    "\n",
    "kld = []\n",
    "for i in range(100):\n",
    "    kld.append(KL_divergence(std0[i],mu0[i],std1[i],mu1[i]))\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(kld)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('$D_{KL}$($\\hat{X}$||X)')\n",
    "plt.savefig(_filename('kld1.png'))\n",
    "plt.clf()\n",
    "\n",
    "mu0 = jnp.mean(actual, axis=(0,2))\n",
    "std0 = jnp.std(actual, axis=(0,2))\n",
    "\n",
    "mu1 = jnp.mean(pred, axis=(0,2))\n",
    "std1 = jnp.std(pred, axis=(0,2))\n",
    "\n",
    "kld_x = []\n",
    "for i in range(100):\n",
    "    kld_x.append(KL_divergence(std0[i,0],mu0[i,0],std1[i,0],mu1[i,0]))\n",
    "\n",
    "kld_y = []\n",
    "for i in range(100):\n",
    "    kld_y.append(KL_divergence(std0[i,1],mu0[i,1],std1[i,1],mu1[i,1]))\n",
    "\n",
    "\n",
    "plt.plot(kld_x, label ='x')\n",
    "plt.plot(kld_y, label ='y')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('$D_{KL}$($\\hat{X}$||X)')\n",
    "plt.legend()\n",
    "plt.savefig(_filename('kld_x_y.png'))\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_jaxbrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
