{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## IMPORT ######################\n",
    "import json\n",
    "from datetime import datetime\n",
    "from functools import partial, wraps\n",
    "\n",
    "import fire\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import jit, random, value_and_grad, vmap\n",
    "# from jax.experimental import optimizers\n",
    "from jax.example_libraries import optimizers\n",
    "from jax_md import space\n",
    "from shadow.plot import *\n",
    "from sklearn.metrics import r2_score\n",
    "from psystems.nsprings import (chain, edge_order, get_connections,\n",
    "                               get_fully_connected_senders_and_receivers,\n",
    "                               get_fully_edge_order)\n",
    "# from statistics import mode\n",
    "# from sympy import LM\n",
    "# from torch import batch_norm_gather_stats_with_counts\n",
    "import sys\n",
    "MAINPATH = \"..\"  # nopep8\n",
    "sys.path.append(MAINPATH)  # nopep8\n",
    "import jraph\n",
    "import src\n",
    "from jax.config import config\n",
    "# from src import fgn, lnn\n",
    "from src.graph import *\n",
    "# from src.lnn import acceleration, accelerationFull, accelerationTV\n",
    "from src.md import *\n",
    "from src.models import MSE, initialize_mlp, GaussianNLL, initialize_mlp_gamma, forward_pass_gamma\n",
    "from src.nve import NVEStates, nve, BrownianStates\n",
    "from src.utils import *\n",
    "\n",
    "# config.update(\"jax_enable_x64\", True)\n",
    "# config.update(\"jax_debug_nans\", True)\n",
    "# jax.config.update('jax_platform_name', 'gpu')\n",
    "\n",
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "\n",
    "def pprint(*args, namespace=globals()):\n",
    "    for arg in args:\n",
    "        print(f\"{namestr(arg, namespace)[0]}: {arg}\")\n",
    "\n",
    "f32 = jnp.float32\n",
    "f64 = jnp.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs: \n",
      "N: 5\n",
      "epochs: 10000\n",
      "seed: 42\n",
      "rname: True\n",
      "dt: 0.001\n",
      "lr: 0.0001\n",
      "batch_size: 20\n"
     ]
    }
   ],
   "source": [
    "N = 5  # number of particles\n",
    "dim = 2  # dimensions\n",
    "runs = 1\n",
    "kT = 1 #1.380649e-23*T  # boltzmann constant*temperature\n",
    "# spring_constant = 1.0\n",
    "# length_constant = 1.0\n",
    "# nconfig=100\n",
    "seed=42\n",
    "dt = 1.0e-3 # time step*stride \n",
    "lr=1e-4\n",
    "batch_size=20\n",
    "epochs = 10000\n",
    "# node_type = jnp.array([0,0,0,0,0])\n",
    "masses = jnp.ones(N)\n",
    "species = jnp.zeros(N, dtype=int).reshape(-1,1)\n",
    "# gamma = jnp.ones(jnp.unique(species).shape)  # damping constant\n",
    "\n",
    "rname=True\n",
    "withdata = None\n",
    "\n",
    "print(\"Configs: \")\n",
    "pprint(N, epochs, seed, rname, dt, lr, batch_size, namespace=locals())\n",
    "\n",
    "randfilename = datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "\n",
    "PSYS = f\"a-{N}-non-linear-Spring-data-brownian_EM\"\n",
    "TAG = f\"1NN\"\n",
    "out_dir = f\"../results\"\n",
    "\n",
    "def _filename(name, tag=TAG):\n",
    "    rstring = randfilename if (rname and (tag != \"data\")) else (\n",
    "        \"0\" if (tag == \"data\") or (withdata == None) else f\"0_{withdata}\")\n",
    "    filename_prefix = f\"{out_dir}/{PSYS}-{tag}/{rstring}/\"\n",
    "    file = f\"{filename_prefix}/{name}\"\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    filename = f\"{filename_prefix}/{name}\".replace(\"//\", \"/\")\n",
    "    print(\"===\", filename, \"===\")\n",
    "    return filename\n",
    "\n",
    "def displacement(a, b):\n",
    "    return a - b\n",
    "\n",
    "def shift(R, dR):\n",
    "    return R+dR\n",
    "\n",
    "def OUT(f):\n",
    "    @wraps(f)\n",
    "    def func(file, *args, tag=TAG, **kwargs):\n",
    "        return f(_filename(file, tag=tag), *args, **kwargs)\n",
    "    return func\n",
    "\n",
    "loadmodel = OUT(src.models.loadmodel)\n",
    "savemodel = OUT(src.models.savemodel)\n",
    "\n",
    "loadfile = OUT(src.io.loadfile)\n",
    "savefile = OUT(src.io.savefile)\n",
    "save_ovito = OUT(src.io.save_ovito)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-data/0/model_states_brownian.pkl ===\n",
      "Total number of data points: 100x100\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "################## CONFIG ######################\n",
    "################################################\n",
    "np.random.seed(seed)\n",
    "key = random.PRNGKey(seed)\n",
    "\n",
    "try:\n",
    "    dataset_states = loadfile(f\"model_states_brownian.pkl\", tag=\"data\")[0]\n",
    "except:\n",
    "    raise Exception(\"Generate dataset first.\")\n",
    "\n",
    "model_states = dataset_states[0]\n",
    "\n",
    "print(f\"Total number of data points: {len(dataset_states)}x{model_states.position.shape[0]}\")\n",
    "\n",
    "Rs = States_Brow().fromlist(dataset_states).get_array()\n",
    "\n",
    "Rs_in = Rs[:,:99,:,:]\n",
    "Rs_out = Rs[:,1:100,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################### ML Model ###################\n",
    "################################################\n",
    "# print(\"Creating Chain\")\n",
    "x, _, senders, receivers = chain(N)\n",
    "\n",
    "hidden = 16\n",
    "nhidden = 2\n",
    "\n",
    "def get_layers(in_, out_):\n",
    "    return [in_] + [hidden]*nhidden + [out_]\n",
    "\n",
    "def mlp(in_, out_, key, **kwargs):\n",
    "    return initialize_mlp(get_layers(in_, out_), key, **kwargs)\n",
    "\n",
    "params = {\"F_pos\": mlp(N*dim, N*dim, key)}\n",
    "\n",
    "def acceleration_node(x, params, **kwargs):\n",
    "    n,dim = x.shape\n",
    "    inp = x.flatten() #jnp.hstack([x.flatten(),v.flatten()])\n",
    "    out = forward_pass(params, inp)\n",
    "    return out.reshape(-1,dim)\n",
    "\n",
    "def _force_fn():    \n",
    "    def apply(R, params):\n",
    "        return acceleration_node(R, params)\n",
    "    return apply\n",
    "\n",
    "apply_fn = _force_fn()\n",
    "\n",
    "def next_step_fn_model(x, params): return apply_fn(x, params['F_pos'])\n",
    "v_next_step_fn_model = vmap(next_step_fn_model, in_axes=(0, None))\n",
    "v_v_next_step_fn_model = vmap(v_next_step_fn_model, in_axes=(0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.3587485 , -5.5219827 ],\n",
       "       [-0.16316819, -2.8957014 ],\n",
       "       [ 2.7990637 , -0.8542066 ],\n",
       "       [ 0.00590687, -0.661735  ],\n",
       "       [-1.1160023 , -2.2723567 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_step_fn_model(x, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "Epoch: 0/10000 Loss (MSE):  train=12.50381851196289\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 10/10000 Loss (MSE):  train=11.287025451660156\n",
      "Epoch: 20/10000 Loss (MSE):  train=10.20813274383545\n",
      "Epoch: 30/10000 Loss (MSE):  train=9.252677917480469\n",
      "Epoch: 40/10000 Loss (MSE):  train=8.402363777160645\n",
      "Epoch: 50/10000 Loss (MSE):  train=7.642260551452637\n",
      "Epoch: 60/10000 Loss (MSE):  train=6.960115432739258\n",
      "Epoch: 70/10000 Loss (MSE):  train=6.345608711242676\n",
      "Epoch: 80/10000 Loss (MSE):  train=5.789948463439941\n",
      "Epoch: 90/10000 Loss (MSE):  train=5.285636901855469\n",
      "Epoch: 100/10000 Loss (MSE):  train=4.826262950897217\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 110/10000 Loss (MSE):  train=4.406373977661133\n",
      "Epoch: 120/10000 Loss (MSE):  train=4.021355628967285\n",
      "Epoch: 130/10000 Loss (MSE):  train=3.6673214435577393\n",
      "Epoch: 140/10000 Loss (MSE):  train=3.341034412384033\n",
      "Epoch: 150/10000 Loss (MSE):  train=3.039844512939453\n",
      "Epoch: 160/10000 Loss (MSE):  train=2.7616078853607178\n",
      "Epoch: 170/10000 Loss (MSE):  train=2.5046608448028564\n",
      "Epoch: 180/10000 Loss (MSE):  train=2.2677419185638428\n",
      "Epoch: 190/10000 Loss (MSE):  train=2.0499372482299805\n",
      "Epoch: 200/10000 Loss (MSE):  train=1.850575566291809\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 210/10000 Loss (MSE):  train=1.6691529750823975\n",
      "Epoch: 220/10000 Loss (MSE):  train=1.505201816558838\n",
      "Epoch: 230/10000 Loss (MSE):  train=1.3582156896591187\n",
      "Epoch: 240/10000 Loss (MSE):  train=1.2275590896606445\n",
      "Epoch: 250/10000 Loss (MSE):  train=1.112442970275879\n",
      "Epoch: 260/10000 Loss (MSE):  train=1.0119035243988037\n",
      "Epoch: 270/10000 Loss (MSE):  train=0.924834668636322\n",
      "Epoch: 280/10000 Loss (MSE):  train=0.8500264883041382\n",
      "Epoch: 290/10000 Loss (MSE):  train=0.7862148284912109\n",
      "Epoch: 300/10000 Loss (MSE):  train=0.7321267127990723\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 310/10000 Loss (MSE):  train=0.6865243911743164\n",
      "Epoch: 320/10000 Loss (MSE):  train=0.6482359170913696\n",
      "Epoch: 330/10000 Loss (MSE):  train=0.6161780953407288\n",
      "Epoch: 340/10000 Loss (MSE):  train=0.5893702507019043\n",
      "Epoch: 350/10000 Loss (MSE):  train=0.5669419169425964\n",
      "Epoch: 360/10000 Loss (MSE):  train=0.5481313467025757\n",
      "Epoch: 370/10000 Loss (MSE):  train=0.5322853922843933\n",
      "Epoch: 380/10000 Loss (MSE):  train=0.5188475251197815\n",
      "Epoch: 390/10000 Loss (MSE):  train=0.5073541402816772\n",
      "Epoch: 400/10000 Loss (MSE):  train=0.4974207580089569\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 410/10000 Loss (MSE):  train=0.4887322187423706\n",
      "Epoch: 420/10000 Loss (MSE):  train=0.4810338318347931\n",
      "Epoch: 430/10000 Loss (MSE):  train=0.4741211533546448\n",
      "Epoch: 440/10000 Loss (MSE):  train=0.46783095598220825\n",
      "Epoch: 450/10000 Loss (MSE):  train=0.4620347023010254\n",
      "Epoch: 460/10000 Loss (MSE):  train=0.4566308856010437\n",
      "Epoch: 470/10000 Loss (MSE):  train=0.45154133439064026\n",
      "Epoch: 480/10000 Loss (MSE):  train=0.4467041492462158\n",
      "Epoch: 490/10000 Loss (MSE):  train=0.44207173585891724\n",
      "Epoch: 500/10000 Loss (MSE):  train=0.4376083314418793\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 510/10000 Loss (MSE):  train=0.43328574299812317\n",
      "Epoch: 520/10000 Loss (MSE):  train=0.4290819764137268\n",
      "Epoch: 530/10000 Loss (MSE):  train=0.4249807596206665\n",
      "Epoch: 540/10000 Loss (MSE):  train=0.4209693670272827\n",
      "Epoch: 550/10000 Loss (MSE):  train=0.41703739762306213\n",
      "Epoch: 560/10000 Loss (MSE):  train=0.4131777584552765\n",
      "Epoch: 570/10000 Loss (MSE):  train=0.40938371419906616\n",
      "Epoch: 580/10000 Loss (MSE):  train=0.40565067529678345\n",
      "Epoch: 590/10000 Loss (MSE):  train=0.4019745886325836\n",
      "Epoch: 600/10000 Loss (MSE):  train=0.39835232496261597\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 610/10000 Loss (MSE):  train=0.39478081464767456\n",
      "Epoch: 620/10000 Loss (MSE):  train=0.39125746488571167\n",
      "Epoch: 630/10000 Loss (MSE):  train=0.3877809941768646\n",
      "Epoch: 640/10000 Loss (MSE):  train=0.38434869050979614\n",
      "Epoch: 650/10000 Loss (MSE):  train=0.38095927238464355\n",
      "Epoch: 660/10000 Loss (MSE):  train=0.37761062383651733\n",
      "Epoch: 670/10000 Loss (MSE):  train=0.37430253624916077\n",
      "Epoch: 680/10000 Loss (MSE):  train=0.3710325062274933\n",
      "Epoch: 690/10000 Loss (MSE):  train=0.36779969930648804\n",
      "Epoch: 700/10000 Loss (MSE):  train=0.3646031618118286\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 710/10000 Loss (MSE):  train=0.3614412844181061\n",
      "Epoch: 720/10000 Loss (MSE):  train=0.3583131730556488\n",
      "Epoch: 730/10000 Loss (MSE):  train=0.3552183508872986\n",
      "Epoch: 740/10000 Loss (MSE):  train=0.35215502977371216\n",
      "Epoch: 750/10000 Loss (MSE):  train=0.34912288188934326\n",
      "Epoch: 760/10000 Loss (MSE):  train=0.3461207151412964\n",
      "Epoch: 770/10000 Loss (MSE):  train=0.34314799308776855\n",
      "Epoch: 780/10000 Loss (MSE):  train=0.34020352363586426\n",
      "Epoch: 790/10000 Loss (MSE):  train=0.3372873067855835\n",
      "Epoch: 800/10000 Loss (MSE):  train=0.33439791202545166\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 810/10000 Loss (MSE):  train=0.33153489232063293\n",
      "Epoch: 820/10000 Loss (MSE):  train=0.3286980390548706\n",
      "Epoch: 830/10000 Loss (MSE):  train=0.3258861303329468\n",
      "Epoch: 840/10000 Loss (MSE):  train=0.3230990171432495\n",
      "Epoch: 850/10000 Loss (MSE):  train=0.32033607363700867\n",
      "Epoch: 860/10000 Loss (MSE):  train=0.3175966143608093\n",
      "Epoch: 870/10000 Loss (MSE):  train=0.3148806393146515\n",
      "Epoch: 880/10000 Loss (MSE):  train=0.3121873438358307\n",
      "Epoch: 890/10000 Loss (MSE):  train=0.30951637029647827\n",
      "Epoch: 900/10000 Loss (MSE):  train=0.30686718225479126\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 910/10000 Loss (MSE):  train=0.3042397201061249\n",
      "Epoch: 920/10000 Loss (MSE):  train=0.30163347721099854\n",
      "Epoch: 930/10000 Loss (MSE):  train=0.2990480661392212\n",
      "Epoch: 940/10000 Loss (MSE):  train=0.2964833974838257\n",
      "Epoch: 950/10000 Loss (MSE):  train=0.29393908381462097\n",
      "Epoch: 960/10000 Loss (MSE):  train=0.291414737701416\n",
      "Epoch: 970/10000 Loss (MSE):  train=0.28891006112098694\n",
      "Epoch: 980/10000 Loss (MSE):  train=0.28642523288726807\n",
      "Epoch: 990/10000 Loss (MSE):  train=0.2839599549770355\n",
      "Epoch: 1000/10000 Loss (MSE):  train=0.2815132141113281\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 1010/10000 Loss (MSE):  train=0.2790861129760742\n",
      "Epoch: 1020/10000 Loss (MSE):  train=0.27667754888534546\n",
      "Epoch: 1030/10000 Loss (MSE):  train=0.274287611246109\n",
      "Epoch: 1040/10000 Loss (MSE):  train=0.2719162106513977\n",
      "Epoch: 1050/10000 Loss (MSE):  train=0.269563227891922\n",
      "Epoch: 1060/10000 Loss (MSE):  train=0.26722848415374756\n",
      "Epoch: 1070/10000 Loss (MSE):  train=0.2649117410182953\n",
      "Epoch: 1080/10000 Loss (MSE):  train=0.2626132071018219\n",
      "Epoch: 1090/10000 Loss (MSE):  train=0.26033246517181396\n",
      "Epoch: 1100/10000 Loss (MSE):  train=0.2580695152282715\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 1110/10000 Loss (MSE):  train=0.25582432746887207\n",
      "Epoch: 1120/10000 Loss (MSE):  train=0.2535969018936157\n",
      "Epoch: 1130/10000 Loss (MSE):  train=0.25138697028160095\n",
      "Epoch: 1140/10000 Loss (MSE):  train=0.24919447302818298\n",
      "Epoch: 1150/10000 Loss (MSE):  train=0.247019425034523\n",
      "Epoch: 1160/10000 Loss (MSE):  train=0.24486152827739716\n",
      "Epoch: 1170/10000 Loss (MSE):  train=0.24272114038467407\n",
      "Epoch: 1180/10000 Loss (MSE):  train=0.2405978888273239\n",
      "Epoch: 1190/10000 Loss (MSE):  train=0.23849163949489594\n",
      "Epoch: 1200/10000 Loss (MSE):  train=0.23640230298042297\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 1210/10000 Loss (MSE):  train=0.23432986438274384\n",
      "Epoch: 1220/10000 Loss (MSE):  train=0.23227429389953613\n",
      "Epoch: 1230/10000 Loss (MSE):  train=0.23023538291454315\n",
      "Epoch: 1240/10000 Loss (MSE):  train=0.22821293771266937\n",
      "Epoch: 1250/10000 Loss (MSE):  train=0.2262069582939148\n",
      "Epoch: 1260/10000 Loss (MSE):  train=0.22421720623970032\n",
      "Epoch: 1270/10000 Loss (MSE):  train=0.22224362194538116\n",
      "Epoch: 1280/10000 Loss (MSE):  train=0.22028614580631256\n",
      "Epoch: 1290/10000 Loss (MSE):  train=0.21834442019462585\n",
      "Epoch: 1300/10000 Loss (MSE):  train=0.21641819179058075\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 1310/10000 Loss (MSE):  train=0.21450743079185486\n",
      "Epoch: 1320/10000 Loss (MSE):  train=0.21261225640773773\n",
      "Epoch: 1330/10000 Loss (MSE):  train=0.21073168516159058\n",
      "Epoch: 1340/10000 Loss (MSE):  train=0.20886598527431488\n",
      "Epoch: 1350/10000 Loss (MSE):  train=0.20701482892036438\n",
      "Epoch: 1360/10000 Loss (MSE):  train=0.20517806708812714\n",
      "Epoch: 1370/10000 Loss (MSE):  train=0.20335537195205688\n",
      "Epoch: 1380/10000 Loss (MSE):  train=0.201546311378479\n",
      "Epoch: 1390/10000 Loss (MSE):  train=0.19975075125694275\n",
      "Epoch: 1400/10000 Loss (MSE):  train=0.19796831905841827\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 1410/10000 Loss (MSE):  train=0.19619888067245483\n",
      "Epoch: 1420/10000 Loss (MSE):  train=0.19444192945957184\n",
      "Epoch: 1430/10000 Loss (MSE):  train=0.1926971971988678\n",
      "Epoch: 1440/10000 Loss (MSE):  train=0.19096426665782928\n",
      "Epoch: 1450/10000 Loss (MSE):  train=0.18924301862716675\n",
      "Epoch: 1460/10000 Loss (MSE):  train=0.18753287196159363\n",
      "Epoch: 1470/10000 Loss (MSE):  train=0.18583375215530396\n",
      "Epoch: 1480/10000 Loss (MSE):  train=0.18414506316184998\n",
      "Epoch: 1490/10000 Loss (MSE):  train=0.18246638774871826\n",
      "Epoch: 1500/10000 Loss (MSE):  train=0.18079774081707\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 1510/10000 Loss (MSE):  train=0.17913834750652313\n",
      "Epoch: 1520/10000 Loss (MSE):  train=0.17748813331127167\n",
      "Epoch: 1530/10000 Loss (MSE):  train=0.1758466362953186\n",
      "Epoch: 1540/10000 Loss (MSE):  train=0.17421354353427887\n",
      "Epoch: 1550/10000 Loss (MSE):  train=0.17258833348751068\n",
      "Epoch: 1560/10000 Loss (MSE):  train=0.17097091674804688\n",
      "Epoch: 1570/10000 Loss (MSE):  train=0.16936074197292328\n",
      "Epoch: 1580/10000 Loss (MSE):  train=0.16775751113891602\n",
      "Epoch: 1590/10000 Loss (MSE):  train=0.16616114974021912\n",
      "Epoch: 1600/10000 Loss (MSE):  train=0.16457104682922363\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 1610/10000 Loss (MSE):  train=0.16298682987689972\n",
      "Epoch: 1620/10000 Loss (MSE):  train=0.1614084541797638\n",
      "Epoch: 1630/10000 Loss (MSE):  train=0.1598355770111084\n",
      "Epoch: 1640/10000 Loss (MSE):  train=0.1582677662372589\n",
      "Epoch: 1650/10000 Loss (MSE):  train=0.15670502185821533\n",
      "Epoch: 1660/10000 Loss (MSE):  train=0.15514691174030304\n",
      "Epoch: 1670/10000 Loss (MSE):  train=0.1535932868719101\n",
      "Epoch: 1680/10000 Loss (MSE):  train=0.1520441621541977\n",
      "Epoch: 1690/10000 Loss (MSE):  train=0.15049897134304047\n",
      "Epoch: 1700/10000 Loss (MSE):  train=0.1489579677581787\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 1710/10000 Loss (MSE):  train=0.14742062985897064\n",
      "Epoch: 1720/10000 Loss (MSE):  train=0.14588724076747894\n",
      "Epoch: 1730/10000 Loss (MSE):  train=0.14435754716396332\n",
      "Epoch: 1740/10000 Loss (MSE):  train=0.142831489443779\n",
      "Epoch: 1750/10000 Loss (MSE):  train=0.14130906760692596\n",
      "Epoch: 1760/10000 Loss (MSE):  train=0.13979049026966095\n",
      "Epoch: 1770/10000 Loss (MSE):  train=0.13827547430992126\n",
      "Epoch: 1780/10000 Loss (MSE):  train=0.1367645114660263\n",
      "Epoch: 1790/10000 Loss (MSE):  train=0.13525734841823578\n",
      "Epoch: 1800/10000 Loss (MSE):  train=0.13375408947467804\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 1810/10000 Loss (MSE):  train=0.13225534558296204\n",
      "Epoch: 1820/10000 Loss (MSE):  train=0.13076095283031464\n",
      "Epoch: 1830/10000 Loss (MSE):  train=0.12927134335041046\n",
      "Epoch: 1840/10000 Loss (MSE):  train=0.12778685986995697\n",
      "Epoch: 1850/10000 Loss (MSE):  train=0.12630753219127655\n",
      "Epoch: 1860/10000 Loss (MSE):  train=0.12483406811952591\n",
      "Epoch: 1870/10000 Loss (MSE):  train=0.1233665868639946\n",
      "Epoch: 1880/10000 Loss (MSE):  train=0.12190555036067963\n",
      "Epoch: 1890/10000 Loss (MSE):  train=0.12045148760080338\n",
      "Epoch: 1900/10000 Loss (MSE):  train=0.11900489777326584\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 1910/10000 Loss (MSE):  train=0.11756604164838791\n",
      "Epoch: 1920/10000 Loss (MSE):  train=0.1161356270313263\n",
      "Epoch: 1930/10000 Loss (MSE):  train=0.11471426486968994\n",
      "Epoch: 1940/10000 Loss (MSE):  train=0.11330245435237885\n",
      "Epoch: 1950/10000 Loss (MSE):  train=0.11190058290958405\n",
      "Epoch: 1960/10000 Loss (MSE):  train=0.11050953716039658\n",
      "Epoch: 1970/10000 Loss (MSE):  train=0.10912957787513733\n",
      "Epoch: 1980/10000 Loss (MSE):  train=0.10776163637638092\n",
      "Epoch: 1990/10000 Loss (MSE):  train=0.10640614479780197\n",
      "Epoch: 2000/10000 Loss (MSE):  train=0.10506368428468704\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sureshjyoti/GitHub/BGNODE_scratch/.venv_jaxbrow/lib/python3.9/site-packages/shadow/plot.py:181: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=figsize, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2010/10000 Loss (MSE):  train=0.1037348061800003\n",
      "Epoch: 2020/10000 Loss (MSE):  train=0.10242026299238205\n",
      "Epoch: 2030/10000 Loss (MSE):  train=0.1011204868555069\n",
      "Epoch: 2040/10000 Loss (MSE):  train=0.09983598440885544\n",
      "Epoch: 2050/10000 Loss (MSE):  train=0.09856736660003662\n",
      "Epoch: 2060/10000 Loss (MSE):  train=0.09731513261795044\n",
      "Epoch: 2070/10000 Loss (MSE):  train=0.09607967734336853\n",
      "Epoch: 2080/10000 Loss (MSE):  train=0.09486141800880432\n",
      "Epoch: 2090/10000 Loss (MSE):  train=0.0936608538031578\n",
      "Epoch: 2100/10000 Loss (MSE):  train=0.09247809648513794\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 2110/10000 Loss (MSE):  train=0.09131372720003128\n",
      "Epoch: 2120/10000 Loss (MSE):  train=0.0901678055524826\n",
      "Epoch: 2130/10000 Loss (MSE):  train=0.08904073387384415\n",
      "Epoch: 2140/10000 Loss (MSE):  train=0.08793244510889053\n",
      "Epoch: 2150/10000 Loss (MSE):  train=0.08684321492910385\n",
      "Epoch: 2160/10000 Loss (MSE):  train=0.08577311038970947\n",
      "Epoch: 2170/10000 Loss (MSE):  train=0.08472194522619247\n",
      "Epoch: 2180/10000 Loss (MSE):  train=0.08368980139493942\n",
      "Epoch: 2190/10000 Loss (MSE):  train=0.0826767086982727\n",
      "Epoch: 2200/10000 Loss (MSE):  train=0.08168225735425949\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 2210/10000 Loss (MSE):  train=0.08070643246173859\n",
      "Epoch: 2220/10000 Loss (MSE):  train=0.07974885404109955\n",
      "Epoch: 2230/10000 Loss (MSE):  train=0.0788094624876976\n",
      "Epoch: 2240/10000 Loss (MSE):  train=0.07788759469985962\n",
      "Epoch: 2250/10000 Loss (MSE):  train=0.07698310166597366\n",
      "Epoch: 2260/10000 Loss (MSE):  train=0.07609544694423676\n",
      "Epoch: 2270/10000 Loss (MSE):  train=0.07522423565387726\n",
      "Epoch: 2280/10000 Loss (MSE):  train=0.07436899095773697\n",
      "Epoch: 2290/10000 Loss (MSE):  train=0.07352912425994873\n",
      "Epoch: 2300/10000 Loss (MSE):  train=0.07270409911870956\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 2310/10000 Loss (MSE):  train=0.07189332693815231\n",
      "Epoch: 2320/10000 Loss (MSE):  train=0.07109630852937698\n",
      "Epoch: 2330/10000 Loss (MSE):  train=0.07031232863664627\n",
      "Epoch: 2340/10000 Loss (MSE):  train=0.06954096257686615\n",
      "Epoch: 2350/10000 Loss (MSE):  train=0.06878131628036499\n",
      "Epoch: 2360/10000 Loss (MSE):  train=0.06803296506404877\n",
      "Epoch: 2370/10000 Loss (MSE):  train=0.06729515641927719\n",
      "Epoch: 2380/10000 Loss (MSE):  train=0.0665673092007637\n",
      "Epoch: 2390/10000 Loss (MSE):  train=0.06584890186786652\n",
      "Epoch: 2400/10000 Loss (MSE):  train=0.06513918191194534\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 2410/10000 Loss (MSE):  train=0.06443757563829422\n",
      "Epoch: 2420/10000 Loss (MSE):  train=0.06374352425336838\n",
      "Epoch: 2430/10000 Loss (MSE):  train=0.06305646896362305\n",
      "Epoch: 2440/10000 Loss (MSE):  train=0.06237577274441719\n",
      "Epoch: 2450/10000 Loss (MSE):  train=0.061701029539108276\n",
      "Epoch: 2460/10000 Loss (MSE):  train=0.061031609773635864\n",
      "Epoch: 2470/10000 Loss (MSE):  train=0.06036706268787384\n",
      "Epoch: 2480/10000 Loss (MSE):  train=0.0597069151699543\n",
      "Epoch: 2490/10000 Loss (MSE):  train=0.05905074626207352\n",
      "Epoch: 2500/10000 Loss (MSE):  train=0.0583980493247509\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 2510/10000 Loss (MSE):  train=0.057748571038246155\n",
      "Epoch: 2520/10000 Loss (MSE):  train=0.057101838290691376\n",
      "Epoch: 2530/10000 Loss (MSE):  train=0.05645754188299179\n",
      "Epoch: 2540/10000 Loss (MSE):  train=0.055815376341342926\n",
      "Epoch: 2550/10000 Loss (MSE):  train=0.0551750548183918\n",
      "Epoch: 2560/10000 Loss (MSE):  train=0.05453626811504364\n",
      "Epoch: 2570/10000 Loss (MSE):  train=0.05389886721968651\n",
      "Epoch: 2580/10000 Loss (MSE):  train=0.0532626137137413\n",
      "Epoch: 2590/10000 Loss (MSE):  train=0.05262727662920952\n",
      "Epoch: 2600/10000 Loss (MSE):  train=0.05199272185564041\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 2610/10000 Loss (MSE):  train=0.051358792930841446\n",
      "Epoch: 2620/10000 Loss (MSE):  train=0.050725482404232025\n",
      "Epoch: 2630/10000 Loss (MSE):  train=0.05009258911013603\n",
      "Epoch: 2640/10000 Loss (MSE):  train=0.04946010559797287\n",
      "Epoch: 2650/10000 Loss (MSE):  train=0.048828013241291046\n",
      "Epoch: 2660/10000 Loss (MSE):  train=0.0481962114572525\n",
      "Epoch: 2670/10000 Loss (MSE):  train=0.04756476730108261\n",
      "Epoch: 2680/10000 Loss (MSE):  train=0.046933695673942566\n",
      "Epoch: 2690/10000 Loss (MSE):  train=0.04630305990576744\n",
      "Epoch: 2700/10000 Loss (MSE):  train=0.04567285627126694\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 2710/10000 Loss (MSE):  train=0.04504319280385971\n",
      "Epoch: 2720/10000 Loss (MSE):  train=0.044414229691028595\n",
      "Epoch: 2730/10000 Loss (MSE):  train=0.04378601536154747\n",
      "Epoch: 2740/10000 Loss (MSE):  train=0.04315876215696335\n",
      "Epoch: 2750/10000 Loss (MSE):  train=0.04253257066011429\n",
      "Epoch: 2760/10000 Loss (MSE):  train=0.04190758988261223\n",
      "Epoch: 2770/10000 Loss (MSE):  train=0.041284069418907166\n",
      "Epoch: 2780/10000 Loss (MSE):  train=0.04066218063235283\n",
      "Epoch: 2790/10000 Loss (MSE):  train=0.04004215449094772\n",
      "Epoch: 2800/10000 Loss (MSE):  train=0.03942422196269035\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 2810/10000 Loss (MSE):  train=0.038808610290288925\n",
      "Epoch: 2820/10000 Loss (MSE):  train=0.038195572793483734\n",
      "Epoch: 2830/10000 Loss (MSE):  train=0.03758540004491806\n",
      "Epoch: 2840/10000 Loss (MSE):  train=0.03697836771607399\n",
      "Epoch: 2850/10000 Loss (MSE):  train=0.036374740302562714\n",
      "Epoch: 2860/10000 Loss (MSE):  train=0.03577478602528572\n",
      "Epoch: 2870/10000 Loss (MSE):  train=0.03517885133624077\n",
      "Epoch: 2880/10000 Loss (MSE):  train=0.03458719700574875\n",
      "Epoch: 2890/10000 Loss (MSE):  train=0.034000083804130554\n",
      "Epoch: 2900/10000 Loss (MSE):  train=0.033417873084545135\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 2910/10000 Loss (MSE):  train=0.03284080699086189\n",
      "Epoch: 2920/10000 Loss (MSE):  train=0.032269228249788284\n",
      "Epoch: 2930/10000 Loss (MSE):  train=0.031703390181064606\n",
      "Epoch: 2940/10000 Loss (MSE):  train=0.031143568456172943\n",
      "Epoch: 2950/10000 Loss (MSE):  train=0.030590035021305084\n",
      "Epoch: 2960/10000 Loss (MSE):  train=0.030043018981814384\n",
      "Epoch: 2970/10000 Loss (MSE):  train=0.029502829536795616\n",
      "Epoch: 2980/10000 Loss (MSE):  train=0.0289696604013443\n",
      "Epoch: 2990/10000 Loss (MSE):  train=0.028443774208426476\n",
      "Epoch: 3000/10000 Loss (MSE):  train=0.027925333008170128\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 3010/10000 Loss (MSE):  train=0.027414586395025253\n",
      "Epoch: 3020/10000 Loss (MSE):  train=0.026911668479442596\n",
      "Epoch: 3030/10000 Loss (MSE):  train=0.026416774839162827\n",
      "Epoch: 3040/10000 Loss (MSE):  train=0.02593003585934639\n",
      "Epoch: 3050/10000 Loss (MSE):  train=0.025451568886637688\n",
      "Epoch: 3060/10000 Loss (MSE):  train=0.024981509894132614\n",
      "Epoch: 3070/10000 Loss (MSE):  train=0.024519966915249825\n",
      "Epoch: 3080/10000 Loss (MSE):  train=0.02406698279082775\n",
      "Epoch: 3090/10000 Loss (MSE):  train=0.023622646927833557\n",
      "Epoch: 3100/10000 Loss (MSE):  train=0.02318699285387993\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 3110/10000 Loss (MSE):  train=0.022760070860385895\n",
      "Epoch: 3120/10000 Loss (MSE):  train=0.022341851145029068\n",
      "Epoch: 3130/10000 Loss (MSE):  train=0.02193235605955124\n",
      "Epoch: 3140/10000 Loss (MSE):  train=0.02153157815337181\n",
      "Epoch: 3150/10000 Loss (MSE):  train=0.021139448508620262\n",
      "Epoch: 3160/10000 Loss (MSE):  train=0.020755935460329056\n",
      "Epoch: 3170/10000 Loss (MSE):  train=0.020380999892950058\n",
      "Epoch: 3180/10000 Loss (MSE):  train=0.02001456916332245\n",
      "Epoch: 3190/10000 Loss (MSE):  train=0.019656533375382423\n",
      "Epoch: 3200/10000 Loss (MSE):  train=0.01930682174861431\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 3210/10000 Loss (MSE):  train=0.01896531507372856\n",
      "Epoch: 3220/10000 Loss (MSE):  train=0.018631942570209503\n",
      "Epoch: 3230/10000 Loss (MSE):  train=0.01830654963850975\n",
      "Epoch: 3240/10000 Loss (MSE):  train=0.017989028245210648\n",
      "Epoch: 3250/10000 Loss (MSE):  train=0.017679261043667793\n",
      "Epoch: 3260/10000 Loss (MSE):  train=0.017377082258462906\n",
      "Epoch: 3270/10000 Loss (MSE):  train=0.017082395032048225\n",
      "Epoch: 3280/10000 Loss (MSE):  train=0.016795018687844276\n",
      "Epoch: 3290/10000 Loss (MSE):  train=0.016514839604496956\n",
      "Epoch: 3300/10000 Loss (MSE):  train=0.01624169945716858\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 3310/10000 Loss (MSE):  train=0.0159754641354084\n",
      "Epoch: 3320/10000 Loss (MSE):  train=0.01571596972644329\n",
      "Epoch: 3330/10000 Loss (MSE):  train=0.015463065356016159\n",
      "Epoch: 3340/10000 Loss (MSE):  train=0.01521662250161171\n",
      "Epoch: 3350/10000 Loss (MSE):  train=0.014976483769714832\n",
      "Epoch: 3360/10000 Loss (MSE):  train=0.014742512255907059\n",
      "Epoch: 3370/10000 Loss (MSE):  train=0.014514550566673279\n",
      "Epoch: 3380/10000 Loss (MSE):  train=0.014292476698756218\n",
      "Epoch: 3390/10000 Loss (MSE):  train=0.014076124876737595\n",
      "Epoch: 3400/10000 Loss (MSE):  train=0.013865383341908455\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 3410/10000 Loss (MSE):  train=0.013660086318850517\n",
      "Epoch: 3420/10000 Loss (MSE):  train=0.013460110872983932\n",
      "Epoch: 3430/10000 Loss (MSE):  train=0.013265334069728851\n",
      "Epoch: 3440/10000 Loss (MSE):  train=0.013075629249215126\n",
      "Epoch: 3450/10000 Loss (MSE):  train=0.012890854850411415\n",
      "Epoch: 3460/10000 Loss (MSE):  train=0.012710902839899063\n",
      "Epoch: 3470/10000 Loss (MSE):  train=0.012535631656646729\n",
      "Epoch: 3480/10000 Loss (MSE):  train=0.012364938855171204\n",
      "Epoch: 3490/10000 Loss (MSE):  train=0.012198714539408684\n",
      "Epoch: 3500/10000 Loss (MSE):  train=0.01203683391213417\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 3510/10000 Loss (MSE):  train=0.011879172176122665\n",
      "Epoch: 3520/10000 Loss (MSE):  train=0.011725657619535923\n",
      "Epoch: 3530/10000 Loss (MSE):  train=0.011576144024729729\n",
      "Epoch: 3540/10000 Loss (MSE):  train=0.011430548503994942\n",
      "Epoch: 3550/10000 Loss (MSE):  train=0.011288769543170929\n",
      "Epoch: 3560/10000 Loss (MSE):  train=0.011150714010000229\n",
      "Epoch: 3570/10000 Loss (MSE):  train=0.011016277596354485\n",
      "Epoch: 3580/10000 Loss (MSE):  train=0.010885350406169891\n",
      "Epoch: 3590/10000 Loss (MSE):  train=0.010757861658930779\n",
      "Epoch: 3600/10000 Loss (MSE):  train=0.010633714497089386\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 3610/10000 Loss (MSE):  train=0.010512817651033401\n",
      "Epoch: 3620/10000 Loss (MSE):  train=0.010395079851150513\n",
      "Epoch: 3630/10000 Loss (MSE):  train=0.010280430316925049\n",
      "Epoch: 3640/10000 Loss (MSE):  train=0.010168757289648056\n",
      "Epoch: 3650/10000 Loss (MSE):  train=0.010060007683932781\n",
      "Epoch: 3660/10000 Loss (MSE):  train=0.009954087436199188\n",
      "Epoch: 3670/10000 Loss (MSE):  train=0.00985090434551239\n",
      "Epoch: 3680/10000 Loss (MSE):  train=0.009750411845743656\n",
      "Epoch: 3690/10000 Loss (MSE):  train=0.009652500972151756\n",
      "Epoch: 3700/10000 Loss (MSE):  train=0.009557124227285385\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 3710/10000 Loss (MSE):  train=0.009464193135499954\n",
      "Epoch: 3720/10000 Loss (MSE):  train=0.009373631328344345\n",
      "Epoch: 3730/10000 Loss (MSE):  train=0.009285377338528633\n",
      "Epoch: 3740/10000 Loss (MSE):  train=0.009199358522891998\n",
      "Epoch: 3750/10000 Loss (MSE):  train=0.009115518070757389\n",
      "Epoch: 3760/10000 Loss (MSE):  train=0.009033766575157642\n",
      "Epoch: 3770/10000 Loss (MSE):  train=0.008954059332609177\n",
      "Epoch: 3780/10000 Loss (MSE):  train=0.008876321837306023\n",
      "Epoch: 3790/10000 Loss (MSE):  train=0.008800499141216278\n",
      "Epoch: 3800/10000 Loss (MSE):  train=0.00872652418911457\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 3810/10000 Loss (MSE):  train=0.008654335513710976\n",
      "Epoch: 3820/10000 Loss (MSE):  train=0.008583882823586464\n",
      "Epoch: 3830/10000 Loss (MSE):  train=0.008515101857483387\n",
      "Epoch: 3840/10000 Loss (MSE):  train=0.008447940461337566\n",
      "Epoch: 3850/10000 Loss (MSE):  train=0.008382339030504227\n",
      "Epoch: 3860/10000 Loss (MSE):  train=0.00831824354827404\n",
      "Epoch: 3870/10000 Loss (MSE):  train=0.00825561210513115\n",
      "Epoch: 3880/10000 Loss (MSE):  train=0.008194392547011375\n",
      "Epoch: 3890/10000 Loss (MSE):  train=0.008134521543979645\n",
      "Epoch: 3900/10000 Loss (MSE):  train=0.008075965568423271\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 3910/10000 Loss (MSE):  train=0.008018668740987778\n",
      "Epoch: 3920/10000 Loss (MSE):  train=0.00796259380877018\n",
      "Epoch: 3930/10000 Loss (MSE):  train=0.00790769699960947\n",
      "Epoch: 3940/10000 Loss (MSE):  train=0.007853932678699493\n",
      "Epoch: 3950/10000 Loss (MSE):  train=0.007801252417266369\n",
      "Epoch: 3960/10000 Loss (MSE):  train=0.007749634329229593\n",
      "Epoch: 3970/10000 Loss (MSE):  train=0.007699029520153999\n",
      "Epoch: 3980/10000 Loss (MSE):  train=0.007649395614862442\n",
      "Epoch: 3990/10000 Loss (MSE):  train=0.007600707001984119\n",
      "Epoch: 4000/10000 Loss (MSE):  train=0.007552928291261196\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 4010/10000 Loss (MSE):  train=0.0075060175731778145\n",
      "Epoch: 4020/10000 Loss (MSE):  train=0.007459952495992184\n",
      "Epoch: 4030/10000 Loss (MSE):  train=0.00741469394415617\n",
      "Epoch: 4040/10000 Loss (MSE):  train=0.00737022003158927\n",
      "Epoch: 4050/10000 Loss (MSE):  train=0.007326500024646521\n",
      "Epoch: 4060/10000 Loss (MSE):  train=0.00728350505232811\n",
      "Epoch: 4070/10000 Loss (MSE):  train=0.007241209503263235\n",
      "Epoch: 4080/10000 Loss (MSE):  train=0.007199588697403669\n",
      "Epoch: 4090/10000 Loss (MSE):  train=0.007158624939620495\n",
      "Epoch: 4100/10000 Loss (MSE):  train=0.007118287496268749\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 4110/10000 Loss (MSE):  train=0.007078555878251791\n",
      "Epoch: 4120/10000 Loss (MSE):  train=0.007039411924779415\n",
      "Epoch: 4130/10000 Loss (MSE):  train=0.007000831887125969\n",
      "Epoch: 4140/10000 Loss (MSE):  train=0.006962802726775408\n",
      "Epoch: 4150/10000 Loss (MSE):  train=0.006925306282937527\n",
      "Epoch: 4160/10000 Loss (MSE):  train=0.006888316944241524\n",
      "Epoch: 4170/10000 Loss (MSE):  train=0.006851822137832642\n",
      "Epoch: 4180/10000 Loss (MSE):  train=0.006815815344452858\n",
      "Epoch: 4190/10000 Loss (MSE):  train=0.006780270487070084\n",
      "Epoch: 4200/10000 Loss (MSE):  train=0.006745185237377882\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 4210/10000 Loss (MSE):  train=0.006710536312311888\n",
      "Epoch: 4220/10000 Loss (MSE):  train=0.006676310673356056\n",
      "Epoch: 4230/10000 Loss (MSE):  train=0.006642501801252365\n",
      "Epoch: 4240/10000 Loss (MSE):  train=0.006609095260500908\n",
      "Epoch: 4250/10000 Loss (MSE):  train=0.006576079875230789\n",
      "Epoch: 4260/10000 Loss (MSE):  train=0.006543443538248539\n",
      "Epoch: 4270/10000 Loss (MSE):  train=0.006511190440505743\n",
      "Epoch: 4280/10000 Loss (MSE):  train=0.006479292176663876\n",
      "Epoch: 4290/10000 Loss (MSE):  train=0.006447747815400362\n",
      "Epoch: 4300/10000 Loss (MSE):  train=0.0064165545627474785\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 4310/10000 Loss (MSE):  train=0.006385700311511755\n",
      "Epoch: 4320/10000 Loss (MSE):  train=0.00635517155751586\n",
      "Epoch: 4330/10000 Loss (MSE):  train=0.006324968300759792\n",
      "Epoch: 4340/10000 Loss (MSE):  train=0.006295084487646818\n",
      "Epoch: 4350/10000 Loss (MSE):  train=0.006265503820031881\n",
      "Epoch: 4360/10000 Loss (MSE):  train=0.006236233748495579\n",
      "Epoch: 4370/10000 Loss (MSE):  train=0.0062072621658444405\n",
      "Epoch: 4380/10000 Loss (MSE):  train=0.00617857463657856\n",
      "Epoch: 4390/10000 Loss (MSE):  train=0.0061501855961978436\n",
      "Epoch: 4400/10000 Loss (MSE):  train=0.00612207455560565\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 4410/10000 Loss (MSE):  train=0.006094243377447128\n",
      "Epoch: 4420/10000 Loss (MSE):  train=0.0060666827484965324\n",
      "Epoch: 4430/10000 Loss (MSE):  train=0.006039390340447426\n",
      "Epoch: 4440/10000 Loss (MSE):  train=0.006012363359332085\n",
      "Epoch: 4450/10000 Loss (MSE):  train=0.005985595285892487\n",
      "Epoch: 4460/10000 Loss (MSE):  train=0.005959082394838333\n",
      "Epoch: 4470/10000 Loss (MSE):  train=0.005932822823524475\n",
      "Epoch: 4480/10000 Loss (MSE):  train=0.005906813777983189\n",
      "Epoch: 4490/10000 Loss (MSE):  train=0.005881050135940313\n",
      "Epoch: 4500/10000 Loss (MSE):  train=0.00585552491247654\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 4510/10000 Loss (MSE):  train=0.005830240435898304\n",
      "Epoch: 4520/10000 Loss (MSE):  train=0.005805191118270159\n",
      "Epoch: 4530/10000 Loss (MSE):  train=0.005780372768640518\n",
      "Epoch: 4540/10000 Loss (MSE):  train=0.005755787715315819\n",
      "Epoch: 4550/10000 Loss (MSE):  train=0.005731421988457441\n",
      "Epoch: 4560/10000 Loss (MSE):  train=0.0057072825729846954\n",
      "Epoch: 4570/10000 Loss (MSE):  train=0.005683370400220156\n",
      "Epoch: 4580/10000 Loss (MSE):  train=0.005659664981067181\n",
      "Epoch: 4590/10000 Loss (MSE):  train=0.005636182613670826\n",
      "Epoch: 4600/10000 Loss (MSE):  train=0.005612911190837622\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 4610/10000 Loss (MSE):  train=0.005589850712567568\n",
      "Epoch: 4620/10000 Loss (MSE):  train=0.00556700024753809\n",
      "Epoch: 4630/10000 Loss (MSE):  train=0.005544353276491165\n",
      "Epoch: 4640/10000 Loss (MSE):  train=0.005521905608475208\n",
      "Epoch: 4650/10000 Loss (MSE):  train=0.005499664694070816\n",
      "Epoch: 4660/10000 Loss (MSE):  train=0.00547761982306838\n",
      "Epoch: 4670/10000 Loss (MSE):  train=0.005455776117742062\n",
      "Epoch: 4680/10000 Loss (MSE):  train=0.005434126127511263\n",
      "Epoch: 4690/10000 Loss (MSE):  train=0.005412662867456675\n",
      "Epoch: 4700/10000 Loss (MSE):  train=0.005391393788158894\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 4710/10000 Loss (MSE):  train=0.005370316095650196\n",
      "Epoch: 4720/10000 Loss (MSE):  train=0.005349419079720974\n",
      "Epoch: 4730/10000 Loss (MSE):  train=0.005328708328306675\n",
      "Epoch: 4740/10000 Loss (MSE):  train=0.005308183841407299\n",
      "Epoch: 4750/10000 Loss (MSE):  train=0.005287839099764824\n",
      "Epoch: 4760/10000 Loss (MSE):  train=0.005267670378088951\n",
      "Epoch: 4770/10000 Loss (MSE):  train=0.005247673951089382\n",
      "Epoch: 4780/10000 Loss (MSE):  train=0.005227860528975725\n",
      "Epoch: 4790/10000 Loss (MSE):  train=0.005208218470215797\n",
      "Epoch: 4800/10000 Loss (MSE):  train=0.005188746377825737\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 4810/10000 Loss (MSE):  train=0.005169447977095842\n",
      "Epoch: 4820/10000 Loss (MSE):  train=0.005150309763848782\n",
      "Epoch: 4830/10000 Loss (MSE):  train=0.005131338257342577\n",
      "Epoch: 4840/10000 Loss (MSE):  train=0.005112536251544952\n",
      "Epoch: 4850/10000 Loss (MSE):  train=0.0050938925705850124\n",
      "Epoch: 4860/10000 Loss (MSE):  train=0.005075416062027216\n",
      "Epoch: 4870/10000 Loss (MSE):  train=0.0050570908933877945\n",
      "Epoch: 4880/10000 Loss (MSE):  train=0.005038929637521505\n",
      "Epoch: 4890/10000 Loss (MSE):  train=0.005020922049880028\n",
      "Epoch: 4900/10000 Loss (MSE):  train=0.005003065336495638\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 4910/10000 Loss (MSE):  train=0.004985365085303783\n",
      "Epoch: 4920/10000 Loss (MSE):  train=0.0049678185023367405\n",
      "Epoch: 4930/10000 Loss (MSE):  train=0.004950419533997774\n",
      "Epoch: 4940/10000 Loss (MSE):  train=0.004933165851980448\n",
      "Epoch: 4950/10000 Loss (MSE):  train=0.0049160681664943695\n",
      "Epoch: 4960/10000 Loss (MSE):  train=0.004899108782410622\n",
      "Epoch: 4970/10000 Loss (MSE):  train=0.004882293753325939\n",
      "Epoch: 4980/10000 Loss (MSE):  train=0.004865617956966162\n",
      "Epoch: 4990/10000 Loss (MSE):  train=0.004849086049944162\n",
      "Epoch: 5000/10000 Loss (MSE):  train=0.004832698963582516\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 5010/10000 Loss (MSE):  train=0.004816440399736166\n",
      "Epoch: 5020/10000 Loss (MSE):  train=0.004800321999937296\n",
      "Epoch: 5030/10000 Loss (MSE):  train=0.0047843437641859055\n",
      "Epoch: 5040/10000 Loss (MSE):  train=0.00476849777624011\n",
      "Epoch: 5050/10000 Loss (MSE):  train=0.0047527807764709\n",
      "Epoch: 5060/10000 Loss (MSE):  train=0.004737197421491146\n",
      "Epoch: 5070/10000 Loss (MSE):  train=0.004721741192042828\n",
      "Epoch: 5080/10000 Loss (MSE):  train=0.004706417676061392\n",
      "Epoch: 5090/10000 Loss (MSE):  train=0.004691216628998518\n",
      "Epoch: 5100/10000 Loss (MSE):  train=0.004676146898418665\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 5110/10000 Loss (MSE):  train=0.004661201033741236\n",
      "Epoch: 5120/10000 Loss (MSE):  train=0.004646379500627518\n",
      "Epoch: 5130/10000 Loss (MSE):  train=0.0046316771768033504\n",
      "Epoch: 5140/10000 Loss (MSE):  train=0.004617095924913883\n",
      "Epoch: 5150/10000 Loss (MSE):  train=0.004602634813636541\n",
      "Epoch: 5160/10000 Loss (MSE):  train=0.004588292445987463\n",
      "Epoch: 5170/10000 Loss (MSE):  train=0.004574068821966648\n",
      "Epoch: 5180/10000 Loss (MSE):  train=0.0045599564909935\n",
      "Epoch: 5190/10000 Loss (MSE):  train=0.004545961506664753\n",
      "Epoch: 5200/10000 Loss (MSE):  train=0.00453208526596427\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 5210/10000 Loss (MSE):  train=0.004518319386988878\n",
      "Epoch: 5220/10000 Loss (MSE):  train=0.004504663869738579\n",
      "Epoch: 5230/10000 Loss (MSE):  train=0.004491118714213371\n",
      "Epoch: 5240/10000 Loss (MSE):  train=0.004477685783058405\n",
      "Epoch: 5250/10000 Loss (MSE):  train=0.004464355763047934\n",
      "Epoch: 5260/10000 Loss (MSE):  train=0.004451137036085129\n",
      "Epoch: 5270/10000 Loss (MSE):  train=0.00443802447989583\n",
      "Epoch: 5280/10000 Loss (MSE):  train=0.004425015300512314\n",
      "Epoch: 5290/10000 Loss (MSE):  train=0.004412110894918442\n",
      "Epoch: 5300/10000 Loss (MSE):  train=0.004399309400469065\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 5310/10000 Loss (MSE):  train=0.004386614076793194\n",
      "Epoch: 5320/10000 Loss (MSE):  train=0.004374015145003796\n",
      "Epoch: 5330/10000 Loss (MSE):  train=0.0043615177273750305\n",
      "Epoch: 5340/10000 Loss (MSE):  train=0.004349117167294025\n",
      "Epoch: 5350/10000 Loss (MSE):  train=0.004336816258728504\n",
      "Epoch: 5360/10000 Loss (MSE):  train=0.004324611276388168\n",
      "Epoch: 5370/10000 Loss (MSE):  train=0.00431250361725688\n",
      "Epoch: 5380/10000 Loss (MSE):  train=0.00430048955604434\n",
      "Epoch: 5390/10000 Loss (MSE):  train=0.004288574680685997\n",
      "Epoch: 5400/10000 Loss (MSE):  train=0.004276746418327093\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 5410/10000 Loss (MSE):  train=0.004265014082193375\n",
      "Epoch: 5420/10000 Loss (MSE):  train=0.004253374878317118\n",
      "Epoch: 5430/10000 Loss (MSE):  train=0.004241823218762875\n",
      "Epoch: 5440/10000 Loss (MSE):  train=0.004230362828820944\n",
      "Epoch: 5450/10000 Loss (MSE):  train=0.004218989051878452\n",
      "Epoch: 5460/10000 Loss (MSE):  train=0.004207709338515997\n",
      "Epoch: 5470/10000 Loss (MSE):  train=0.00419651111587882\n",
      "Epoch: 5480/10000 Loss (MSE):  train=0.004185399040579796\n",
      "Epoch: 5490/10000 Loss (MSE):  train=0.004174374043941498\n",
      "Epoch: 5500/10000 Loss (MSE):  train=0.004163432400673628\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 5510/10000 Loss (MSE):  train=0.004152572713792324\n",
      "Epoch: 5520/10000 Loss (MSE):  train=0.004141801968216896\n",
      "Epoch: 5530/10000 Loss (MSE):  train=0.0041311089880764484\n",
      "Epoch: 5540/10000 Loss (MSE):  train=0.00412049749866128\n",
      "Epoch: 5550/10000 Loss (MSE):  train=0.00410996749997139\n",
      "Epoch: 5560/10000 Loss (MSE):  train=0.0040995171293616295\n",
      "Epoch: 5570/10000 Loss (MSE):  train=0.004089145455509424\n",
      "Epoch: 5580/10000 Loss (MSE):  train=0.004078853875398636\n",
      "Epoch: 5590/10000 Loss (MSE):  train=0.004068635869771242\n",
      "Epoch: 5600/10000 Loss (MSE):  train=0.004058497492223978\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 5610/10000 Loss (MSE):  train=0.004048432223498821\n",
      "Epoch: 5620/10000 Loss (MSE):  train=0.004038444720208645\n",
      "Epoch: 5630/10000 Loss (MSE):  train=0.004028529394418001\n",
      "Epoch: 5640/10000 Loss (MSE):  train=0.004018690437078476\n",
      "Epoch: 5650/10000 Loss (MSE):  train=0.0040089222602546215\n",
      "Epoch: 5660/10000 Loss (MSE):  train=0.0039992257952690125\n",
      "Epoch: 5670/10000 Loss (MSE):  train=0.003989602439105511\n",
      "Epoch: 5680/10000 Loss (MSE):  train=0.003980048932135105\n",
      "Epoch: 5690/10000 Loss (MSE):  train=0.003970564343035221\n",
      "Epoch: 5700/10000 Loss (MSE):  train=0.003961151000112295\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 5710/10000 Loss (MSE):  train=0.003951807506382465\n",
      "Epoch: 5720/10000 Loss (MSE):  train=0.003942530136555433\n",
      "Epoch: 5730/10000 Loss (MSE):  train=0.003933318424969912\n",
      "Epoch: 5740/10000 Loss (MSE):  train=0.003924173768609762\n",
      "Epoch: 5750/10000 Loss (MSE):  train=0.003915098961442709\n",
      "Epoch: 5760/10000 Loss (MSE):  train=0.0039060870185494423\n",
      "Epoch: 5770/10000 Loss (MSE):  train=0.0038971402682363987\n",
      "Epoch: 5780/10000 Loss (MSE):  train=0.0038882556837052107\n",
      "Epoch: 5790/10000 Loss (MSE):  train=0.0038794362917542458\n",
      "Epoch: 5800/10000 Loss (MSE):  train=0.0038706797640770674\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 5810/10000 Loss (MSE):  train=0.0038619840051978827\n",
      "Epoch: 5820/10000 Loss (MSE):  train=0.003853351343423128\n",
      "Epoch: 5830/10000 Loss (MSE):  train=0.003844781778752804\n",
      "Epoch: 5840/10000 Loss (MSE):  train=0.0038362708874046803\n",
      "Epoch: 5850/10000 Loss (MSE):  train=0.003827816341072321\n",
      "Epoch: 5860/10000 Loss (MSE):  train=0.0038194269873201847\n",
      "Epoch: 5870/10000 Loss (MSE):  train=0.003811091650277376\n",
      "Epoch: 5880/10000 Loss (MSE):  train=0.0038028182461857796\n",
      "Epoch: 5890/10000 Loss (MSE):  train=0.003794600022956729\n",
      "Epoch: 5900/10000 Loss (MSE):  train=0.003786439076066017\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 5910/10000 Loss (MSE):  train=0.003778336336836219\n",
      "Epoch: 5920/10000 Loss (MSE):  train=0.0037702862173318863\n",
      "Epoch: 5930/10000 Loss (MSE):  train=0.0037622894160449505\n",
      "Epoch: 5940/10000 Loss (MSE):  train=0.0037543524522334337\n",
      "Epoch: 5950/10000 Loss (MSE):  train=0.0037464702036231756\n",
      "Epoch: 5960/10000 Loss (MSE):  train=0.003738638013601303\n",
      "Epoch: 5970/10000 Loss (MSE):  train=0.0037308610044419765\n",
      "Epoch: 5980/10000 Loss (MSE):  train=0.0037231375463306904\n",
      "Epoch: 5990/10000 Loss (MSE):  train=0.0037154648452997208\n",
      "Epoch: 6000/10000 Loss (MSE):  train=0.0037078422028571367\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 6010/10000 Loss (MSE):  train=0.0037002740427851677\n",
      "Epoch: 6020/10000 Loss (MSE):  train=0.0036927550099790096\n",
      "Epoch: 6030/10000 Loss (MSE):  train=0.0036852871999144554\n",
      "Epoch: 6040/10000 Loss (MSE):  train=0.0036778650246560574\n",
      "Epoch: 6050/10000 Loss (MSE):  train=0.0036704977974295616\n",
      "Epoch: 6060/10000 Loss (MSE):  train=0.0036631759721785784\n",
      "Epoch: 6070/10000 Loss (MSE):  train=0.0036559058353304863\n",
      "Epoch: 6080/10000 Loss (MSE):  train=0.003648681566119194\n",
      "Epoch: 6090/10000 Loss (MSE):  train=0.0036415059585124254\n",
      "Epoch: 6100/10000 Loss (MSE):  train=0.0036343750543892384\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 6110/10000 Loss (MSE):  train=0.0036272951401770115\n",
      "Epoch: 6120/10000 Loss (MSE):  train=0.0036202576011419296\n",
      "Epoch: 6130/10000 Loss (MSE):  train=0.0036132652312517166\n",
      "Epoch: 6140/10000 Loss (MSE):  train=0.0036063201259821653\n",
      "Epoch: 6150/10000 Loss (MSE):  train=0.0035994199570268393\n",
      "Epoch: 6160/10000 Loss (MSE):  train=0.0035925633274018764\n",
      "Epoch: 6170/10000 Loss (MSE):  train=0.0035857504699379206\n",
      "Epoch: 6180/10000 Loss (MSE):  train=0.003578983712941408\n",
      "Epoch: 6190/10000 Loss (MSE):  train=0.003572256537154317\n",
      "Epoch: 6200/10000 Loss (MSE):  train=0.003565576858818531\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 6210/10000 Loss (MSE):  train=0.0035589360632002354\n",
      "Epoch: 6220/10000 Loss (MSE):  train=0.0035523392725735903\n",
      "Epoch: 6230/10000 Loss (MSE):  train=0.003545785788446665\n",
      "Epoch: 6240/10000 Loss (MSE):  train=0.003539272118359804\n",
      "Epoch: 6250/10000 Loss (MSE):  train=0.0035327989608049393\n",
      "Epoch: 6260/10000 Loss (MSE):  train=0.0035263672471046448\n",
      "Epoch: 6270/10000 Loss (MSE):  train=0.0035199762787669897\n",
      "Epoch: 6280/10000 Loss (MSE):  train=0.0035136258229613304\n",
      "Epoch: 6290/10000 Loss (MSE):  train=0.00350731099024415\n",
      "Epoch: 6300/10000 Loss (MSE):  train=0.003501039231196046\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 6310/10000 Loss (MSE):  train=0.0034948079846799374\n",
      "Epoch: 6320/10000 Loss (MSE):  train=0.0034886132925748825\n",
      "Epoch: 6330/10000 Loss (MSE):  train=0.003482455387711525\n",
      "Epoch: 6340/10000 Loss (MSE):  train=0.003476338228210807\n",
      "Epoch: 6350/10000 Loss (MSE):  train=0.003470258554443717\n",
      "Epoch: 6360/10000 Loss (MSE):  train=0.0034642149694263935\n",
      "Epoch: 6370/10000 Loss (MSE):  train=0.003458209801465273\n",
      "Epoch: 6380/10000 Loss (MSE):  train=0.0034522388596087694\n",
      "Epoch: 6390/10000 Loss (MSE):  train=0.0034463093616068363\n",
      "Epoch: 6400/10000 Loss (MSE):  train=0.003440410364419222\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 6410/10000 Loss (MSE):  train=0.003434552578255534\n",
      "Epoch: 6420/10000 Loss (MSE):  train=0.003428726689890027\n",
      "Epoch: 6430/10000 Loss (MSE):  train=0.0034229345619678497\n",
      "Epoch: 6440/10000 Loss (MSE):  train=0.0034171815495938063\n",
      "Epoch: 6450/10000 Loss (MSE):  train=0.0034114629961550236\n",
      "Epoch: 6460/10000 Loss (MSE):  train=0.003405775409191847\n",
      "Epoch: 6470/10000 Loss (MSE):  train=0.0034001253079622984\n",
      "Epoch: 6480/10000 Loss (MSE):  train=0.003394506871700287\n",
      "Epoch: 6490/10000 Loss (MSE):  train=0.0033889233600348234\n",
      "Epoch: 6500/10000 Loss (MSE):  train=0.0033833717461675406\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 6510/10000 Loss (MSE):  train=0.003377852961421013\n",
      "Epoch: 6520/10000 Loss (MSE):  train=0.0033723688684403896\n",
      "Epoch: 6530/10000 Loss (MSE):  train=0.0033669143449515104\n",
      "Epoch: 6540/10000 Loss (MSE):  train=0.0033614926505833864\n",
      "Epoch: 6550/10000 Loss (MSE):  train=0.0033561086747795343\n",
      "Epoch: 6560/10000 Loss (MSE):  train=0.0033507496118545532\n",
      "Epoch: 6570/10000 Loss (MSE):  train=0.0033454217482358217\n",
      "Epoch: 6580/10000 Loss (MSE):  train=0.0033401299733668566\n",
      "Epoch: 6590/10000 Loss (MSE):  train=0.003334867302328348\n",
      "Epoch: 6600/10000 Loss (MSE):  train=0.003329632803797722\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 6610/10000 Loss (MSE):  train=0.003324433695524931\n",
      "Epoch: 6620/10000 Loss (MSE):  train=0.003319260198622942\n",
      "Epoch: 6630/10000 Loss (MSE):  train=0.003314117668196559\n",
      "Epoch: 6640/10000 Loss (MSE):  train=0.003309007268399\n",
      "Epoch: 6650/10000 Loss (MSE):  train=0.003303924109786749\n",
      "Epoch: 6660/10000 Loss (MSE):  train=0.00329887168481946\n",
      "Epoch: 6670/10000 Loss (MSE):  train=0.0032938518561422825\n",
      "Epoch: 6680/10000 Loss (MSE):  train=0.003288854146376252\n",
      "Epoch: 6690/10000 Loss (MSE):  train=0.003283887403085828\n",
      "Epoch: 6700/10000 Loss (MSE):  train=0.0032789483666419983\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 6710/10000 Loss (MSE):  train=0.0032740402966737747\n",
      "Epoch: 6720/10000 Loss (MSE):  train=0.003269156673923135\n",
      "Epoch: 6730/10000 Loss (MSE):  train=0.0032643030863255262\n",
      "Epoch: 6740/10000 Loss (MSE):  train=0.003259476274251938\n",
      "Epoch: 6750/10000 Loss (MSE):  train=0.0032546790316700935\n",
      "Epoch: 6760/10000 Loss (MSE):  train=0.0032499064691364765\n",
      "Epoch: 6770/10000 Loss (MSE):  train=0.0032451613806188107\n",
      "Epoch: 6780/10000 Loss (MSE):  train=0.003240444464609027\n",
      "Epoch: 6790/10000 Loss (MSE):  train=0.0032357526943087578\n",
      "Epoch: 6800/10000 Loss (MSE):  train=0.0032310853712260723\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 6810/10000 Loss (MSE):  train=0.0032264478504657745\n",
      "Epoch: 6820/10000 Loss (MSE):  train=0.0032218347769230604\n",
      "Epoch: 6830/10000 Loss (MSE):  train=0.0032172470819205046\n",
      "Epoch: 6840/10000 Loss (MSE):  train=0.0032126866281032562\n",
      "Epoch: 6850/10000 Loss (MSE):  train=0.0032081487588584423\n",
      "Epoch: 6860/10000 Loss (MSE):  train=0.003203637432307005\n",
      "Epoch: 6870/10000 Loss (MSE):  train=0.003199152648448944\n",
      "Epoch: 6880/10000 Loss (MSE):  train=0.0031946904491633177\n",
      "Epoch: 6890/10000 Loss (MSE):  train=0.003190254559740424\n",
      "Epoch: 6900/10000 Loss (MSE):  train=0.003185841254889965\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 6910/10000 Loss (MSE):  train=0.0031814533285796642\n",
      "Epoch: 6920/10000 Loss (MSE):  train=0.0031770910136401653\n",
      "Epoch: 6930/10000 Loss (MSE):  train=0.0031727487221360207\n",
      "Epoch: 6940/10000 Loss (MSE):  train=0.003168434603139758\n",
      "Epoch: 6950/10000 Loss (MSE):  train=0.0031641428358852863\n",
      "Epoch: 6960/10000 Loss (MSE):  train=0.0031598734203726053\n",
      "Epoch: 6970/10000 Loss (MSE):  train=0.0031556265894323587\n",
      "Epoch: 6980/10000 Loss (MSE):  train=0.0031514058355242014\n",
      "Epoch: 6990/10000 Loss (MSE):  train=0.003147205337882042\n",
      "Epoch: 7000/10000 Loss (MSE):  train=0.003143028821796179\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 7010/10000 Loss (MSE):  train=0.0031388772185891867\n",
      "Epoch: 7020/10000 Loss (MSE):  train=0.003134742146357894\n",
      "Epoch: 7030/10000 Loss (MSE):  train=0.0031306343153119087\n",
      "Epoch: 7040/10000 Loss (MSE):  train=0.0031265446450561285\n",
      "Epoch: 7050/10000 Loss (MSE):  train=0.003122478723526001\n",
      "Epoch: 7060/10000 Loss (MSE):  train=0.003118434688076377\n",
      "Epoch: 7070/10000 Loss (MSE):  train=0.003114414168521762\n",
      "Epoch: 7080/10000 Loss (MSE):  train=0.0031104146037250757\n",
      "Epoch: 7090/10000 Loss (MSE):  train=0.0031064345967024565\n",
      "Epoch: 7100/10000 Loss (MSE):  train=0.003102473448961973\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 7110/10000 Loss (MSE):  train=0.00309853651560843\n",
      "Epoch: 7120/10000 Loss (MSE):  train=0.003094621002674103\n",
      "Epoch: 7130/10000 Loss (MSE):  train=0.0030907264444977045\n",
      "Epoch: 7140/10000 Loss (MSE):  train=0.003086851676926017\n",
      "Epoch: 7150/10000 Loss (MSE):  train=0.003082995768636465\n",
      "Epoch: 7160/10000 Loss (MSE):  train=0.003079161746427417\n",
      "Epoch: 7170/10000 Loss (MSE):  train=0.003075347049161792\n",
      "Epoch: 7180/10000 Loss (MSE):  train=0.0030715526081621647\n",
      "Epoch: 7190/10000 Loss (MSE):  train=0.003067777492105961\n",
      "Epoch: 7200/10000 Loss (MSE):  train=0.0030640256591141224\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 7210/10000 Loss (MSE):  train=0.0030602882616221905\n",
      "Epoch: 7220/10000 Loss (MSE):  train=0.0030565732158720493\n",
      "Epoch: 7230/10000 Loss (MSE):  train=0.003052876330912113\n",
      "Epoch: 7240/10000 Loss (MSE):  train=0.0030491987708956003\n",
      "Epoch: 7250/10000 Loss (MSE):  train=0.003045541699975729\n",
      "Epoch: 7260/10000 Loss (MSE):  train=0.0030418995302170515\n",
      "Epoch: 7270/10000 Loss (MSE):  train=0.0030382811091840267\n",
      "Epoch: 7280/10000 Loss (MSE):  train=0.0030346778221428394\n",
      "Epoch: 7290/10000 Loss (MSE):  train=0.0030310950241982937\n",
      "Epoch: 7300/10000 Loss (MSE):  train=0.0030275301542133093\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 7310/10000 Loss (MSE):  train=0.0030239818152040243\n",
      "Epoch: 7320/10000 Loss (MSE):  train=0.003020451171323657\n",
      "Epoch: 7330/10000 Loss (MSE):  train=0.0030169442761689425\n",
      "Epoch: 7340/10000 Loss (MSE):  train=0.003013450652360916\n",
      "Epoch: 7350/10000 Loss (MSE):  train=0.003009974490851164\n",
      "Epoch: 7360/10000 Loss (MSE):  train=0.0030065185856074095\n",
      "Epoch: 7370/10000 Loss (MSE):  train=0.003003077581524849\n",
      "Epoch: 7380/10000 Loss (MSE):  train=0.0029996545054018497\n",
      "Epoch: 7390/10000 Loss (MSE):  train=0.002996250055730343\n",
      "Epoch: 7400/10000 Loss (MSE):  train=0.00299286050722003\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 7410/10000 Loss (MSE):  train=0.002989489119499922\n",
      "Epoch: 7420/10000 Loss (MSE):  train=0.002986136358231306\n",
      "Epoch: 7430/10000 Loss (MSE):  train=0.0029827968683093786\n",
      "Epoch: 7440/10000 Loss (MSE):  train=0.0029794757720083\n",
      "Epoch: 7450/10000 Loss (MSE):  train=0.0029761712066829205\n",
      "Epoch: 7460/10000 Loss (MSE):  train=0.0029728817753493786\n",
      "Epoch: 7470/10000 Loss (MSE):  train=0.0029696100391447544\n",
      "Epoch: 7480/10000 Loss (MSE):  train=0.0029663562308996916\n",
      "Epoch: 7490/10000 Loss (MSE):  train=0.0029631159268319607\n",
      "Epoch: 7500/10000 Loss (MSE):  train=0.0029598926194012165\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 7510/10000 Loss (MSE):  train=0.0029566846787929535\n",
      "Epoch: 7520/10000 Loss (MSE):  train=0.002953492570668459\n",
      "Epoch: 7530/10000 Loss (MSE):  train=0.00295031676068902\n",
      "Epoch: 7540/10000 Loss (MSE):  train=0.0029471556190401316\n",
      "Epoch: 7550/10000 Loss (MSE):  train=0.0029440103098750114\n",
      "Epoch: 7560/10000 Loss (MSE):  train=0.0029408808331936598\n",
      "Epoch: 7570/10000 Loss (MSE):  train=0.0029377671889960766\n",
      "Epoch: 7580/10000 Loss (MSE):  train=0.0029346668161451817\n",
      "Epoch: 7590/10000 Loss (MSE):  train=0.002931584371253848\n",
      "Epoch: 7600/10000 Loss (MSE):  train=0.002928514964878559\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 7610/10000 Loss (MSE):  train=0.0029254595283418894\n",
      "Epoch: 7620/10000 Loss (MSE):  train=0.002922419458627701\n",
      "Epoch: 7630/10000 Loss (MSE):  train=0.002919395687058568\n",
      "Epoch: 7640/10000 Loss (MSE):  train=0.0029163837898522615\n",
      "Epoch: 7650/10000 Loss (MSE):  train=0.0029133902862668037\n",
      "Epoch: 7660/10000 Loss (MSE):  train=0.002910405630245805\n",
      "Epoch: 7670/10000 Loss (MSE):  train=0.002907439135015011\n",
      "Epoch: 7680/10000 Loss (MSE):  train=0.0029044856783002615\n",
      "Epoch: 7690/10000 Loss (MSE):  train=0.0029015468899160624\n",
      "Epoch: 7700/10000 Loss (MSE):  train=0.002898622304201126\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 7710/10000 Loss (MSE):  train=0.00289571238681674\n",
      "Epoch: 7720/10000 Loss (MSE):  train=0.002892813878133893\n",
      "Epoch: 7730/10000 Loss (MSE):  train=0.002889927476644516\n",
      "Epoch: 7740/10000 Loss (MSE):  train=0.002887061098590493\n",
      "Epoch: 7750/10000 Loss (MSE):  train=0.0028842042665928602\n",
      "Epoch: 7760/10000 Loss (MSE):  train=0.0028813614044338465\n",
      "Epoch: 7770/10000 Loss (MSE):  train=0.0028785308822989464\n",
      "Epoch: 7780/10000 Loss (MSE):  train=0.0028757168911397457\n",
      "Epoch: 7790/10000 Loss (MSE):  train=0.002872912911698222\n",
      "Epoch: 7800/10000 Loss (MSE):  train=0.002870122669264674\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 7810/10000 Loss (MSE):  train=0.002867345931008458\n",
      "Epoch: 7820/10000 Loss (MSE):  train=0.0028645815327763557\n",
      "Epoch: 7830/10000 Loss (MSE):  train=0.002861828776076436\n",
      "Epoch: 7840/10000 Loss (MSE):  train=0.0028590913861989975\n",
      "Epoch: 7850/10000 Loss (MSE):  train=0.002856365405023098\n",
      "Epoch: 7860/10000 Loss (MSE):  train=0.002853653859347105\n",
      "Epoch: 7870/10000 Loss (MSE):  train=0.0028509534895420074\n",
      "Epoch: 7880/10000 Loss (MSE):  train=0.0028482647612690926\n",
      "Epoch: 7890/10000 Loss (MSE):  train=0.002845589304342866\n",
      "Epoch: 7900/10000 Loss (MSE):  train=0.0028429257217794657\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 7910/10000 Loss (MSE):  train=0.0028402735479176044\n",
      "Epoch: 7920/10000 Loss (MSE):  train=0.0028376360423862934\n",
      "Epoch: 7930/10000 Loss (MSE):  train=0.0028350099455565214\n",
      "Epoch: 7940/10000 Loss (MSE):  train=0.0028323952574282885\n",
      "Epoch: 7950/10000 Loss (MSE):  train=0.0028297940734773874\n",
      "Epoch: 7960/10000 Loss (MSE):  train=0.0028272029012441635\n",
      "Epoch: 7970/10000 Loss (MSE):  train=0.002824620343744755\n",
      "Epoch: 7980/10000 Loss (MSE):  train=0.0028220578096807003\n",
      "Epoch: 7990/10000 Loss (MSE):  train=0.0028195020277053118\n",
      "Epoch: 8000/10000 Loss (MSE):  train=0.0028169567231088877\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 8010/10000 Loss (MSE):  train=0.00281442329287529\n",
      "Epoch: 8020/10000 Loss (MSE):  train=0.002811902202665806\n",
      "Epoch: 8030/10000 Loss (MSE):  train=0.0028093913570046425\n",
      "Epoch: 8040/10000 Loss (MSE):  train=0.002806892851367593\n",
      "Epoch: 8050/10000 Loss (MSE):  train=0.0028044069185853004\n",
      "Epoch: 8060/10000 Loss (MSE):  train=0.002801929833367467\n",
      "Epoch: 8070/10000 Loss (MSE):  train=0.0027994667179882526\n",
      "Epoch: 8080/10000 Loss (MSE):  train=0.0027970103546977043\n",
      "Epoch: 8090/10000 Loss (MSE):  train=0.002794566797092557\n",
      "Epoch: 8100/10000 Loss (MSE):  train=0.002792134415358305\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 8110/10000 Loss (MSE):  train=0.002789716236293316\n",
      "Epoch: 8120/10000 Loss (MSE):  train=0.002787303877994418\n",
      "Epoch: 8130/10000 Loss (MSE):  train=0.0027849047910422087\n",
      "Epoch: 8140/10000 Loss (MSE):  train=0.0027825147844851017\n",
      "Epoch: 8150/10000 Loss (MSE):  train=0.002780135488137603\n",
      "Epoch: 8160/10000 Loss (MSE):  train=0.0027777657378464937\n",
      "Epoch: 8170/10000 Loss (MSE):  train=0.0027754090260714293\n",
      "Epoch: 8180/10000 Loss (MSE):  train=0.002773062326014042\n",
      "Epoch: 8190/10000 Loss (MSE):  train=0.0027707237750291824\n",
      "Epoch: 8200/10000 Loss (MSE):  train=0.002768399193882942\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 8210/10000 Loss (MSE):  train=0.002766080666333437\n",
      "Epoch: 8220/10000 Loss (MSE):  train=0.0027637756429612637\n",
      "Epoch: 8230/10000 Loss (MSE):  train=0.002761479467153549\n",
      "Epoch: 8240/10000 Loss (MSE):  train=0.0027591935358941555\n",
      "Epoch: 8250/10000 Loss (MSE):  train=0.00275691831484437\n",
      "Epoch: 8260/10000 Loss (MSE):  train=0.0027546521741896868\n",
      "Epoch: 8270/10000 Loss (MSE):  train=0.002752395113930106\n",
      "Epoch: 8280/10000 Loss (MSE):  train=0.0027501487638801336\n",
      "Epoch: 8290/10000 Loss (MSE):  train=0.0027479110285639763\n",
      "Epoch: 8300/10000 Loss (MSE):  train=0.0027456842362880707\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 8310/10000 Loss (MSE):  train=0.0027434686198830605\n",
      "Epoch: 8320/10000 Loss (MSE):  train=0.0027412590570747852\n",
      "Epoch: 8330/10000 Loss (MSE):  train=0.00273906160145998\n",
      "Epoch: 8340/10000 Loss (MSE):  train=0.0027368725277483463\n",
      "Epoch: 8350/10000 Loss (MSE):  train=0.002734693232923746\n",
      "Epoch: 8360/10000 Loss (MSE):  train=0.0027325220871716738\n",
      "Epoch: 8370/10000 Loss (MSE):  train=0.002730362582951784\n",
      "Epoch: 8380/10000 Loss (MSE):  train=0.002728211460635066\n",
      "Epoch: 8390/10000 Loss (MSE):  train=0.002726067090407014\n",
      "Epoch: 8400/10000 Loss (MSE):  train=0.0027239378541707993\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 8410/10000 Loss (MSE):  train=0.0027218156028538942\n",
      "Epoch: 8420/10000 Loss (MSE):  train=0.0027196987066417933\n",
      "Epoch: 8430/10000 Loss (MSE):  train=0.0027175918221473694\n",
      "Epoch: 8440/10000 Loss (MSE):  train=0.0027154963463544846\n",
      "Epoch: 8450/10000 Loss (MSE):  train=0.0027134092524647713\n",
      "Epoch: 8460/10000 Loss (MSE):  train=0.002711329609155655\n",
      "Epoch: 8470/10000 Loss (MSE):  train=0.0027092606760561466\n",
      "Epoch: 8480/10000 Loss (MSE):  train=0.0027071982622146606\n",
      "Epoch: 8490/10000 Loss (MSE):  train=0.002705145860090852\n",
      "Epoch: 8500/10000 Loss (MSE):  train=0.0027031039353460073\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 8510/10000 Loss (MSE):  train=0.0027010696940124035\n",
      "Epoch: 8520/10000 Loss (MSE):  train=0.0026990424375981092\n",
      "Epoch: 8530/10000 Loss (MSE):  train=0.002697025192901492\n",
      "Epoch: 8540/10000 Loss (MSE):  train=0.00269501656293869\n",
      "Epoch: 8550/10000 Loss (MSE):  train=0.0026930151507258415\n",
      "Epoch: 8560/10000 Loss (MSE):  train=0.0026910242158919573\n",
      "Epoch: 8570/10000 Loss (MSE):  train=0.0026890395674854517\n",
      "Epoch: 8580/10000 Loss (MSE):  train=0.0026870642323046923\n",
      "Epoch: 8590/10000 Loss (MSE):  train=0.0026850951835513115\n",
      "Epoch: 8600/10000 Loss (MSE):  train=0.0026831382419914007\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 8610/10000 Loss (MSE):  train=0.0026811868883669376\n",
      "Epoch: 8620/10000 Loss (MSE):  train=0.00267924671061337\n",
      "Epoch: 8630/10000 Loss (MSE):  train=0.002677311422303319\n",
      "Epoch: 8640/10000 Loss (MSE):  train=0.0026753859128803015\n",
      "Epoch: 8650/10000 Loss (MSE):  train=0.0026734680868685246\n",
      "Epoch: 8660/10000 Loss (MSE):  train=0.002671557944267988\n",
      "Epoch: 8670/10000 Loss (MSE):  train=0.0026696575805544853\n",
      "Epoch: 8680/10000 Loss (MSE):  train=0.0026677646674215794\n",
      "Epoch: 8690/10000 Loss (MSE):  train=0.002665877342224121\n",
      "Epoch: 8700/10000 Loss (MSE):  train=0.002664000727236271\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 8710/10000 Loss (MSE):  train=0.002662132028490305\n",
      "Epoch: 8720/10000 Loss (MSE):  train=0.0026602698490023613\n",
      "Epoch: 8730/10000 Loss (MSE):  train=0.002658414887264371\n",
      "Epoch: 8740/10000 Loss (MSE):  train=0.0026565666776150465\n",
      "Epoch: 8750/10000 Loss (MSE):  train=0.002654728479683399\n",
      "Epoch: 8760/10000 Loss (MSE):  train=0.0026528965681791306\n",
      "Epoch: 8770/10000 Loss (MSE):  train=0.0026510758325457573\n",
      "Epoch: 8780/10000 Loss (MSE):  train=0.0026492616161704063\n",
      "Epoch: 8790/10000 Loss (MSE):  train=0.0026474506594240665\n",
      "Epoch: 8800/10000 Loss (MSE):  train=0.0026456518098711967\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 8810/10000 Loss (MSE):  train=0.002643859013915062\n",
      "Epoch: 8820/10000 Loss (MSE):  train=0.002642074367031455\n",
      "Epoch: 8830/10000 Loss (MSE):  train=0.002640294609591365\n",
      "Epoch: 8840/10000 Loss (MSE):  train=0.002638525329530239\n",
      "Epoch: 8850/10000 Loss (MSE):  train=0.0026367618702352047\n",
      "Epoch: 8860/10000 Loss (MSE):  train=0.0026350063271820545\n",
      "Epoch: 8870/10000 Loss (MSE):  train=0.0026332582347095013\n",
      "Epoch: 8880/10000 Loss (MSE):  train=0.002631517592817545\n",
      "Epoch: 8890/10000 Loss (MSE):  train=0.002629784168675542\n",
      "Epoch: 8900/10000 Loss (MSE):  train=0.002628055866807699\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 8910/10000 Loss (MSE):  train=0.0026263364125043154\n",
      "Epoch: 8920/10000 Loss (MSE):  train=0.0026246251072734594\n",
      "Epoch: 8930/10000 Loss (MSE):  train=0.002622919622808695\n",
      "Epoch: 8940/10000 Loss (MSE):  train=0.0026212232187390327\n",
      "Epoch: 8950/10000 Loss (MSE):  train=0.0026195349637418985\n",
      "Epoch: 8960/10000 Loss (MSE):  train=0.002617849502712488\n",
      "Epoch: 8970/10000 Loss (MSE):  train=0.0026161728892475367\n",
      "Epoch: 8980/10000 Loss (MSE):  train=0.0026145039591938257\n",
      "Epoch: 8990/10000 Loss (MSE):  train=0.0026128413155674934\n",
      "Epoch: 9000/10000 Loss (MSE):  train=0.0026111872866749763\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 9010/10000 Loss (MSE):  train=0.0026095376815646887\n",
      "Epoch: 9020/10000 Loss (MSE):  train=0.002607895527034998\n",
      "Epoch: 9030/10000 Loss (MSE):  train=0.0026062619872391224\n",
      "Epoch: 9040/10000 Loss (MSE):  train=0.0026046328712254763\n",
      "Epoch: 9050/10000 Loss (MSE):  train=0.0026030135340988636\n",
      "Epoch: 9060/10000 Loss (MSE):  train=0.0026013986207544804\n",
      "Epoch: 9070/10000 Loss (MSE):  train=0.0025997930206358433\n",
      "Epoch: 9080/10000 Loss (MSE):  train=0.002598193008452654\n",
      "Epoch: 9090/10000 Loss (MSE):  train=0.0025965983513742685\n",
      "Epoch: 9100/10000 Loss (MSE):  train=0.002595011843368411\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 9110/10000 Loss (MSE):  train=0.002593433018773794\n",
      "Epoch: 9120/10000 Loss (MSE):  train=0.0025918574538081884\n",
      "Epoch: 9130/10000 Loss (MSE):  train=0.00259029190056026\n",
      "Epoch: 9140/10000 Loss (MSE):  train=0.0025887317024171352\n",
      "Epoch: 9150/10000 Loss (MSE):  train=0.002587176626548171\n",
      "Epoch: 9160/10000 Loss (MSE):  train=0.0025856324937194586\n",
      "Epoch: 9170/10000 Loss (MSE):  train=0.002584091853350401\n",
      "Epoch: 9180/10000 Loss (MSE):  train=0.002582555403932929\n",
      "Epoch: 9190/10000 Loss (MSE):  train=0.00258103059604764\n",
      "Epoch: 9200/10000 Loss (MSE):  train=0.0025795085821300745\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 9210/10000 Loss (MSE):  train=0.0025779951829463243\n",
      "Epoch: 9220/10000 Loss (MSE):  train=0.0025764850433915854\n",
      "Epoch: 9230/10000 Loss (MSE):  train=0.0025749863125383854\n",
      "Epoch: 9240/10000 Loss (MSE):  train=0.002573491772636771\n",
      "Epoch: 9250/10000 Loss (MSE):  train=0.0025720021221786737\n",
      "Epoch: 9260/10000 Loss (MSE):  train=0.0025705196894705296\n",
      "Epoch: 9270/10000 Loss (MSE):  train=0.0025690430775284767\n",
      "Epoch: 9280/10000 Loss (MSE):  train=0.002567573916167021\n",
      "Epoch: 9290/10000 Loss (MSE):  train=0.002566111274063587\n",
      "Epoch: 9300/10000 Loss (MSE):  train=0.0025646542198956013\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 9310/10000 Loss (MSE):  train=0.0025632036849856377\n",
      "Epoch: 9320/10000 Loss (MSE):  train=0.0025617601349949837\n",
      "Epoch: 9330/10000 Loss (MSE):  train=0.002560323104262352\n",
      "Epoch: 9340/10000 Loss (MSE):  train=0.0025588872376829386\n",
      "Epoch: 9350/10000 Loss (MSE):  train=0.002557462779805064\n",
      "Epoch: 9360/10000 Loss (MSE):  train=0.00255604088306427\n",
      "Epoch: 9370/10000 Loss (MSE):  train=0.0025546266697347164\n",
      "Epoch: 9380/10000 Loss (MSE):  train=0.002553219674155116\n",
      "Epoch: 9390/10000 Loss (MSE):  train=0.0025518182665109634\n",
      "Epoch: 9400/10000 Loss (MSE):  train=0.0025504238437861204\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 9410/10000 Loss (MSE):  train=0.0025490345433354378\n",
      "Epoch: 9420/10000 Loss (MSE):  train=0.002547651994973421\n",
      "Epoch: 9430/10000 Loss (MSE):  train=0.002546274568885565\n",
      "Epoch: 9440/10000 Loss (MSE):  train=0.002544903429225087\n",
      "Epoch: 9450/10000 Loss (MSE):  train=0.00254353741183877\n",
      "Epoch: 9460/10000 Loss (MSE):  train=0.002542178612202406\n",
      "Epoch: 9470/10000 Loss (MSE):  train=0.0025408263318240643\n",
      "Epoch: 9480/10000 Loss (MSE):  train=0.0025394796393811703\n",
      "Epoch: 9490/10000 Loss (MSE):  train=0.002538134576752782\n",
      "Epoch: 9500/10000 Loss (MSE):  train=0.0025367997586727142\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 9510/10000 Loss (MSE):  train=0.002535467501729727\n",
      "Epoch: 9520/10000 Loss (MSE):  train=0.002534142229706049\n",
      "Epoch: 9530/10000 Loss (MSE):  train=0.0025328241754323244\n",
      "Epoch: 9540/10000 Loss (MSE):  train=0.002531512174755335\n",
      "Epoch: 9550/10000 Loss (MSE):  train=0.002530205063521862\n",
      "Epoch: 9560/10000 Loss (MSE):  train=0.0025289026089012623\n",
      "Epoch: 9570/10000 Loss (MSE):  train=0.0025276090018451214\n",
      "Epoch: 9580/10000 Loss (MSE):  train=0.002526317024603486\n",
      "Epoch: 9590/10000 Loss (MSE):  train=0.0025250313337892294\n",
      "Epoch: 9600/10000 Loss (MSE):  train=0.0025237516965717077\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 9610/10000 Loss (MSE):  train=0.0025224797427654266\n",
      "Epoch: 9620/10000 Loss (MSE):  train=0.002521210815757513\n",
      "Epoch: 9630/10000 Loss (MSE):  train=0.0025199484080076218\n",
      "Epoch: 9640/10000 Loss (MSE):  train=0.0025186906568706036\n",
      "Epoch: 9650/10000 Loss (MSE):  train=0.002517439890652895\n",
      "Epoch: 9660/10000 Loss (MSE):  train=0.0025161919184029102\n",
      "Epoch: 9670/10000 Loss (MSE):  train=0.002514951629564166\n",
      "Epoch: 9680/10000 Loss (MSE):  train=0.002513717859983444\n",
      "Epoch: 9690/10000 Loss (MSE):  train=0.0025124861858785152\n",
      "Epoch: 9700/10000 Loss (MSE):  train=0.0025112603325396776\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 9710/10000 Loss (MSE):  train=0.0025100414641201496\n",
      "Epoch: 9720/10000 Loss (MSE):  train=0.002508827717974782\n",
      "Epoch: 9730/10000 Loss (MSE):  train=0.002507620258256793\n",
      "Epoch: 9740/10000 Loss (MSE):  train=0.0025064153596758842\n",
      "Epoch: 9750/10000 Loss (MSE):  train=0.0025052158161997795\n",
      "Epoch: 9760/10000 Loss (MSE):  train=0.002504021627828479\n",
      "Epoch: 9770/10000 Loss (MSE):  train=0.0025028339587152004\n",
      "Epoch: 9780/10000 Loss (MSE):  train=0.0025016488507390022\n",
      "Epoch: 9790/10000 Loss (MSE):  train=0.0025004707276821136\n",
      "Epoch: 9800/10000 Loss (MSE):  train=0.0024992988910526037\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 9810/10000 Loss (MSE):  train=0.0024981298483908176\n",
      "Epoch: 9820/10000 Loss (MSE):  train=0.0024969670921564102\n",
      "Epoch: 9830/10000 Loss (MSE):  train=0.002495808759704232\n",
      "Epoch: 9840/10000 Loss (MSE):  train=0.0024946541525423527\n",
      "Epoch: 9850/10000 Loss (MSE):  train=0.002493504900485277\n",
      "Epoch: 9860/10000 Loss (MSE):  train=0.002492361469194293\n",
      "Epoch: 9870/10000 Loss (MSE):  train=0.0024912236258387566\n",
      "Epoch: 9880/10000 Loss (MSE):  train=0.002490089274942875\n",
      "Epoch: 9890/10000 Loss (MSE):  train=0.0024889593478292227\n",
      "Epoch: 9900/10000 Loss (MSE):  train=0.0024878359399735928\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/loss_array.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "Epoch: 9910/10000 Loss (MSE):  train=0.0024867148604243994\n",
      "Epoch: 9920/10000 Loss (MSE):  train=0.002485600532963872\n",
      "Epoch: 9930/10000 Loss (MSE):  train=0.0024844910949468613\n",
      "Epoch: 9940/10000 Loss (MSE):  train=0.002483383286744356\n",
      "Epoch: 9950/10000 Loss (MSE):  train=0.002482281532138586\n",
      "Epoch: 9960/10000 Loss (MSE):  train=0.0024811860639601946\n",
      "Epoch: 9970/10000 Loss (MSE):  train=0.002480093389749527\n",
      "Epoch: 9980/10000 Loss (MSE):  train=0.0024790065363049507\n",
      "Epoch: 9990/10000 Loss (MSE):  train=0.002477922709658742\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/training_loss.png ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model.dil ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/fgnode_trained_model_low.dil ===\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def loss_fn(params, Rs, Rs_1_ac):\n",
    "    Rs_1_pred = v_v_next_step_fn_model(Rs, params)\n",
    "    return MSE(Rs_1_pred, Rs_1_ac)\n",
    "\n",
    "def gloss(*args):\n",
    "    return value_and_grad(loss_fn)(*args)\n",
    "\n",
    "def update(i, opt_state, params, loss__, *data):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads_ = gloss(params, *data)\n",
    "    opt_state = opt_update(i, grads_, opt_state)\n",
    "    return opt_state, get_params(opt_state), value\n",
    "\n",
    "@jit\n",
    "def step(i, ps, *args):\n",
    "    return update(i, *ps, *args)\n",
    "\n",
    "opt_init, opt_update_, get_params = optimizers.adam(lr)\n",
    "\n",
    "@jit\n",
    "def opt_update(i, grads_, opt_state):\n",
    "    grads_ = jax.tree_map(jnp.nan_to_num, grads_)\n",
    "    grads_ = jax.tree_map(partial(jnp.clip, a_min=-1000.0, a_max=1000.0), grads_)\n",
    "    return opt_update_(i, grads_, opt_state)\n",
    "\n",
    "def batching(*args, size=None):\n",
    "    L = len(args[0])\n",
    "    if size != None:\n",
    "        nbatches1 = int((L - 0.5) // size) + 1\n",
    "        nbatches2 = max(1, nbatches1 - 1)\n",
    "        size1 = int(L/nbatches1)\n",
    "        size2 = int(L/nbatches2)\n",
    "        if size1*nbatches1 > size2*nbatches2:\n",
    "            size = size1\n",
    "            nbatches = nbatches1\n",
    "        else:\n",
    "            size = size2\n",
    "            nbatches = nbatches2\n",
    "    else:\n",
    "        nbatches = 1\n",
    "        size = L\n",
    "    \n",
    "    newargs = []\n",
    "    for arg in args:\n",
    "        newargs += [jnp.array([arg[i*size:(i+1)*size]\n",
    "                                for i in range(nbatches)])]\n",
    "    return newargs\n",
    "\n",
    "bRs_in, bRs_out = batching(Rs_in, Rs_out, size=min(len(Rs_in), batch_size))\n",
    "\n",
    "print(f\"training ...\")\n",
    "\n",
    "opt_state = opt_init(params)\n",
    "epoch = 0\n",
    "optimizer_step = -1\n",
    "larray = []\n",
    "ltarray = []\n",
    "last_loss = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    l = 0.0\n",
    "    count = 0\n",
    "    for data in zip(bRs_in, bRs_out):\n",
    "        optimizer_step += 1\n",
    "        opt_state, params, l_ = step(\n",
    "            optimizer_step, (opt_state, params, 0), *data)\n",
    "        l += l_\n",
    "        count+=1\n",
    "    # print(\"epoch,countttttt: \", epoch,count)\n",
    "    # opt_state, params, l_ = step(optimizer_step, (opt_state, params, 0), Rs, Vs, Fs)\n",
    "    l = l/count\n",
    "    larray += [l]\n",
    "    # ltarray += [loss_fn(params, bRs_in, bVs_in, bRs_out)]\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}/{epochs} Loss (MSE):  train={larray[-1]}\")#, test={ltarray[-1]}\")\n",
    "    if epoch % 100 == 0:\n",
    "        metadata = {\n",
    "            \"savedat\": epoch,\n",
    "            # \"mpass\": mpass,\n",
    "            }\n",
    "        savefile(f\"fgnode_trained_model.dil\",\n",
    "                    params, metadata=metadata)\n",
    "        # savefile(f\"loss_array.dil\", (larray, ltarray), metadata=metadata)\n",
    "        savefile(f\"loss_array.dil\", larray, metadata=metadata)\n",
    "        if last_loss > larray[-1]:\n",
    "            last_loss = larray[-1]\n",
    "            savefile(f\"fgnode_trained_model_low.dil\",\n",
    "                        params, metadata=metadata)\n",
    "        fig, axs = panel(1, 1)\n",
    "        # plt.semilogy(larray, label=\"Training\")\n",
    "        plt.plot(larray, label=\"Training\")\n",
    "        # plt.semilogy(ltarray, label=\"Test\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(_filename(f\"training_loss.png\"))\n",
    "\n",
    "fig, axs = panel(1, 1)\n",
    "# plt.semilogy(larray, label=\"Training\")\n",
    "plt.plot(larray, label=\"Training\")\n",
    "# plt.semilogy(ltarray, label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(_filename(f\"training_loss.png\"))\n",
    "\n",
    "params = get_params(opt_state)\n",
    "savefile(f\"fgnode_trained_model.dil\", params, metadata=metadata)\n",
    "# savefile(f\"loss_array.dil\", (larray, ltarray), metadata=metadata)\n",
    "\n",
    "if last_loss > larray[-1]:\n",
    "    last_loss = larray[-1]\n",
    "    savefile(f\"fgnode_trained_model_low.dil\", params, metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params, _ = loadfile(f\"fgnode_trained_model_low.dil\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rname=False\n",
    "\n",
    "# PSYS = f\"a-{N}-Spring-data-brownian_EM\"\n",
    "# TAG = f\"1NN\"\n",
    "# out_dir = f\"../results\"\n",
    "\n",
    "def _filename(name, tag=TAG):\n",
    "    rstring = randfilename if (rname and (tag != \"data\")) else (\n",
    "        \"0\" if (tag == \"data\") or (withdata == None) else f\"0_{withdata}\")\n",
    "    filename_prefix = f\"{out_dir}/{PSYS}-{tag}/{rstring}/\"\n",
    "    file = f\"{filename_prefix}/{name}\"\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    filename = f\"{filename_prefix}/{name}\".replace(\"//\", \"/\")\n",
    "    print(\"===\", filename, \"===\")\n",
    "    return filename\n",
    "\n",
    "def OUT(f):\n",
    "    @wraps(f)\n",
    "    def func(file, *args, tag=TAG, **kwargs):\n",
    "        return f(_filename(file, tag=tag), *args, **kwargs)\n",
    "    return func\n",
    "\n",
    "loadmodel = OUT(src.models.loadmodel)\n",
    "savemodel = OUT(src.models.savemodel)\n",
    "\n",
    "loadfile = OUT(src.io.loadfile)\n",
    "savefile = OUT(src.io.savefile)\n",
    "save_ovito = OUT(src.io.save_ovito)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../results/a-5-Spring-data-brownian_EM-1NN/0/fgnode_trained_model_low.dil ===\n",
      "Loading ../results/a-5-Spring-data-brownian_EM-1NN/0/fgnode_trained_model_low.dil\n"
     ]
    }
   ],
   "source": [
    "params, _ = loadfile(f\"fgnode_trained_model_low.dil\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "spring_constant = 1.0\n",
    "length_constant = 1.0\n",
    "gamma_orig = jnp.ones(jnp.unique(species).shape)\n",
    "stride = 1\n",
    "runs=100\n",
    "\n",
    "def SPRING(x, stiffness=1.0, length=1.0):\n",
    "    x_ = jnp.linalg.norm(x, keepdims=True)\n",
    "    return 0.5*stiffness*(x_ - length)**4\n",
    "\n",
    "def pot_energy_orig(x):\n",
    "    dr = x[senders, :] - x[receivers, :]\n",
    "    return vmap(partial(SPRING, stiffness=spring_constant, length=length_constant))(dr).sum()\n",
    "\n",
    "def force_fn_orig(R, params):\n",
    "    return -grad(pot_energy_orig)(R)\n",
    "\n",
    "def get_forward_sim(params = None, force_fn = None, gamma = None, runs=10):\n",
    "        @jit\n",
    "        def fn(R,key):\n",
    "            return predition_brow(R, params, force_fn, shift, dt, kT, masses, gamma = gamma, stride=stride, runs=runs, key=key)\n",
    "        return fn\n",
    "\n",
    "\n",
    "sim_orig = get_forward_sim(params=None,force_fn=force_fn_orig, gamma=gamma_orig,runs=runs)\n",
    "\n",
    "# model\n",
    "def get_forward_sim_model(params = None, next_step_fn = None, runs=10, stride=1):\n",
    "        next_step_fn = lambda R: next_step_fn_model(R, params)\n",
    "        @jit\n",
    "        def solve_dynamics(R_init):\n",
    "            step = jit(lambda i, R: next_step_fn(R))\n",
    "            def f(R):\n",
    "                y = jax.lax.fori_loop(0, stride, step, R)\n",
    "                return y, y\n",
    "            \n",
    "            def func(R, i): return f(R)\n",
    "            @jit\n",
    "            def scan(R0):\n",
    "                return jax.lax.scan(func, R0, jnp.array(range(runs)))\n",
    "            \n",
    "            final_state, traj = scan(R_init)\n",
    "            return traj\n",
    "        return solve_dynamics\n",
    "\n",
    "sim_model = get_forward_sim_model(params = params, next_step_fn = next_step_fn_model, runs=runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_xyz_traj(Filepath,Name,R):\n",
    "    '''Writes ovito xyz file'''\n",
    "    f=open(Filepath,'w')\n",
    "    f.write(str(R.shape[1])+\"\\n\")\n",
    "    f.write(Name)\n",
    "    for i in range(R.shape[0]): #R.shape[0]\n",
    "        for j in range(R.shape[1]):\n",
    "            f.write(\"\\n\"+str(species[j])+\"\\t\"+str(R[i,j,0])+\"\\t\"+str(R[i,j,1])+\"\\t\"+str(R[i,j,2]))\n",
    "        f.write(\"\\n\"+str(R.shape[1]))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating trajectory 0/100 ...\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/actual_0_0.xyz ===\n",
      "Saving ovito file: ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/actual_0_0.xyz\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/pred_0_0.xyz ===\n",
      "Simulating trajectory 1/100 ...\n",
      "Simulating trajectory 2/100 ...\n",
      "Simulating trajectory 3/100 ...\n",
      "Simulating trajectory 4/100 ...\n",
      "Simulating trajectory 5/100 ...\n",
      "Simulating trajectory 6/100 ...\n",
      "Simulating trajectory 7/100 ...\n",
      "Simulating trajectory 8/100 ...\n",
      "Simulating trajectory 9/100 ...\n",
      "Simulating trajectory 10/100 ...\n",
      "Simulating trajectory 11/100 ...\n",
      "Simulating trajectory 12/100 ...\n",
      "Simulating trajectory 13/100 ...\n",
      "Simulating trajectory 14/100 ...\n",
      "Simulating trajectory 15/100 ...\n",
      "Simulating trajectory 16/100 ...\n",
      "Simulating trajectory 17/100 ...\n",
      "Simulating trajectory 18/100 ...\n",
      "Simulating trajectory 19/100 ...\n",
      "Simulating trajectory 20/100 ...\n",
      "Simulating trajectory 21/100 ...\n",
      "Simulating trajectory 22/100 ...\n",
      "Simulating trajectory 23/100 ...\n",
      "Simulating trajectory 24/100 ...\n",
      "Simulating trajectory 25/100 ...\n",
      "Simulating trajectory 26/100 ...\n",
      "Simulating trajectory 27/100 ...\n",
      "Simulating trajectory 28/100 ...\n",
      "Simulating trajectory 29/100 ...\n",
      "Simulating trajectory 30/100 ...\n",
      "Simulating trajectory 31/100 ...\n",
      "Simulating trajectory 32/100 ...\n",
      "Simulating trajectory 33/100 ...\n",
      "Simulating trajectory 34/100 ...\n",
      "Simulating trajectory 35/100 ...\n",
      "Simulating trajectory 36/100 ...\n",
      "Simulating trajectory 37/100 ...\n",
      "Simulating trajectory 38/100 ...\n",
      "Simulating trajectory 39/100 ...\n",
      "Simulating trajectory 40/100 ...\n",
      "Simulating trajectory 41/100 ...\n",
      "Simulating trajectory 42/100 ...\n",
      "Simulating trajectory 43/100 ...\n",
      "Simulating trajectory 44/100 ...\n",
      "Simulating trajectory 45/100 ...\n",
      "Simulating trajectory 46/100 ...\n",
      "Simulating trajectory 47/100 ...\n",
      "Simulating trajectory 48/100 ...\n",
      "Simulating trajectory 49/100 ...\n",
      "Simulating trajectory 50/100 ...\n",
      "Simulating trajectory 51/100 ...\n",
      "Simulating trajectory 52/100 ...\n",
      "Simulating trajectory 53/100 ...\n",
      "Simulating trajectory 54/100 ...\n",
      "Simulating trajectory 55/100 ...\n",
      "Simulating trajectory 56/100 ...\n",
      "Simulating trajectory 57/100 ...\n",
      "Simulating trajectory 58/100 ...\n",
      "Simulating trajectory 59/100 ...\n",
      "Simulating trajectory 60/100 ...\n",
      "Simulating trajectory 61/100 ...\n",
      "Simulating trajectory 62/100 ...\n",
      "Simulating trajectory 63/100 ...\n",
      "Simulating trajectory 64/100 ...\n",
      "Simulating trajectory 65/100 ...\n",
      "Simulating trajectory 66/100 ...\n",
      "Simulating trajectory 67/100 ...\n",
      "Simulating trajectory 68/100 ...\n",
      "Simulating trajectory 69/100 ...\n",
      "Simulating trajectory 70/100 ...\n",
      "Simulating trajectory 71/100 ...\n",
      "Simulating trajectory 72/100 ...\n",
      "Simulating trajectory 73/100 ...\n",
      "Simulating trajectory 74/100 ...\n",
      "Simulating trajectory 75/100 ...\n",
      "Simulating trajectory 76/100 ...\n",
      "Simulating trajectory 77/100 ...\n",
      "Simulating trajectory 78/100 ...\n",
      "Simulating trajectory 79/100 ...\n",
      "Simulating trajectory 80/100 ...\n",
      "Simulating trajectory 81/100 ...\n",
      "Simulating trajectory 82/100 ...\n",
      "Simulating trajectory 83/100 ...\n",
      "Simulating trajectory 84/100 ...\n",
      "Simulating trajectory 85/100 ...\n",
      "Simulating trajectory 86/100 ...\n",
      "Simulating trajectory 87/100 ...\n",
      "Simulating trajectory 88/100 ...\n",
      "Simulating trajectory 89/100 ...\n",
      "Simulating trajectory 90/100 ...\n",
      "Simulating trajectory 91/100 ...\n",
      "Simulating trajectory 92/100 ...\n",
      "Simulating trajectory 93/100 ...\n",
      "Simulating trajectory 94/100 ...\n",
      "Simulating trajectory 95/100 ...\n",
      "Simulating trajectory 96/100 ...\n",
      "Simulating trajectory 97/100 ...\n",
      "Simulating trajectory 98/100 ...\n",
      "Simulating trajectory 99/100 ...\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/error_paramete_plot_a_b_c.pkl ===\n",
      "=== ../results/a-5-non-linear-Spring-data-brownian_EM-1NN/05-24-2023_22-09-39/error_parameter.pkl ===\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# plotthings = True\n",
    "rng_key = random.PRNGKey(0)\n",
    "maxtraj = 100\n",
    "np.random.seed(seed)\n",
    "key = random.PRNGKey(seed)\n",
    "\n",
    "nexp = {\n",
    "        \"dz_actual\": [],\n",
    "        \"dz_pred\": [],\n",
    "        \"z_actual\": [],\n",
    "        \"z_pred\": [],\n",
    "        \"_gamma\": [],\n",
    "        \"simulation_time\":[],\n",
    "        }\n",
    "\n",
    "trajectories = []\n",
    "for ind in range(maxtraj):\n",
    "    print(f\"Simulating trajectory {ind}/{maxtraj} ...\")\n",
    "    R, _ = chain(N)[:2]\n",
    "    for rand in range(10):\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        actual_traj = sim_orig(R,(ind+13)*subkey)\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        \n",
    "        start = time.time()\n",
    "        pred_pos = sim_model(R)\n",
    "        end = time.time()\n",
    "        nexp[\"simulation_time\"] += [end-start]\n",
    "        \n",
    "        nexp[\"dz_actual\"] += [actual_traj.position-R]\n",
    "        nexp[\"dz_pred\"] += [pred_pos-R]\n",
    "\n",
    "        nexp[\"z_actual\"] += [actual_traj.position]\n",
    "        nexp[\"z_pred\"] += [pred_pos]\n",
    "        \n",
    "        if save_ovito:\n",
    "            if ind<1 and rand<1:\n",
    "                save_ovito(f\"actual_{ind}_{rand}.xyz\", [state for state in BrownianStates(actual_traj)], lattice=\"\")\n",
    "                write_xyz_traj(_filename(f\"pred_{ind}_{rand}.xyz\"),'spring_ddnn',pred_pos)\n",
    "                \n",
    "        # trajectories += [(actual_traj.position, pred_pos)]\n",
    "        # if ind%10==0:\n",
    "        #     savefile(\"trajectories.pkl\", trajectories)\n",
    "\n",
    "\n",
    "def KL_divergence(sigma0,mu0,sigma1,mu1, eps=1e-8):\n",
    "    return jnp.log(sigma1/sigma0) + (jnp.square(sigma0)+jnp.square(mu0-mu1))/(2*jnp.square(sigma1)) - 0.5\n",
    "\n",
    "def get_kld(d_actual, d_pred):\n",
    "    mu0 = jnp.mean(d_actual, axis=(0,2,3))\n",
    "    std0 = jnp.std(d_actual, axis=(0,2,3))\n",
    "    mu1 = jnp.mean(d_pred, axis=(0,2,3))\n",
    "    std1 = jnp.std(d_pred, axis=(0,2,3))\n",
    "    kld = []\n",
    "    for i in range(len(std0)):\n",
    "        kld.append(KL_divergence(std0[i],mu0[i],std1[i],mu1[i]))\n",
    "    return jnp.array(kld)\n",
    "\n",
    "def get_std_rmse(d_actual, d_pred):\n",
    "    std0 = jnp.std(d_actual, axis=(0,2,3))\n",
    "    std1 = jnp.std(d_pred, axis=(0,2,3))\n",
    "    return jnp.sqrt(jnp.square(std0 - std1))\n",
    "\n",
    "def get_dist_by_var(actual, pred, zeta):\n",
    "    disp = displacement(actual, pred)\n",
    "    dist_matrix = jnp.sqrt(jnp.square(disp).sum(-1))\n",
    "    dist_mean = jnp.mean(dist_matrix, axis=(0,2))\n",
    "    dist_by_zeta = dist_mean/zeta\n",
    "    return dist_by_zeta\n",
    "\n",
    "nexp2 = {\n",
    "        \"kld\": [],\n",
    "        \"std_rmse\": [],\n",
    "        }\n",
    "\n",
    "nexp2[\"kld\"] = jnp.array(get_kld(jnp.array(nexp[\"dz_actual\"]),jnp.array(nexp[\"dz_pred\"])))\n",
    "\n",
    "nexp2[\"std_rmse\"] = jnp.array(get_std_rmse(jnp.array(nexp[\"dz_actual\"]),jnp.array(nexp[\"dz_pred\"])))\n",
    "\n",
    "# nexp2[\"dist_by_var\"] = jnp.array(get_dist_by_var(jnp.array(nexp['z_actual']), jnp.array(nexp['z_pred']),1/(jnp.array(nexp['_gamma'])[0][0])))\n",
    "\n",
    "savefile(f\"error_paramete_plot_a_b_c.pkl\", nexp2)\n",
    "# savefile(\"trajectories.pkl\", trajectories)\n",
    "savefile(f\"error_parameter.pkl\", nexp)\n",
    "# savefile(\"trajectories.pkl\", trajectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_jaxbrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
