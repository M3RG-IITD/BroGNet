{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## IMPORT ######################\n",
    "import json\n",
    "from datetime import datetime\n",
    "from functools import partial, wraps\n",
    "\n",
    "import fire\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import jit, random, value_and_grad, vmap\n",
    "# from jax.experimental import optimizers\n",
    "from jax.example_libraries import optimizers\n",
    "from jax_md import space\n",
    "from shadow.plot import *\n",
    "from sklearn.metrics import r2_score\n",
    "from psystems.nsprings import (chain, edge_order, get_connections,\n",
    "                               get_fully_connected_senders_and_receivers,\n",
    "                               get_fully_edge_order)\n",
    "# from statistics import mode\n",
    "# from sympy import LM\n",
    "# from torch import batch_norm_gather_stats_with_counts\n",
    "import sys\n",
    "MAINPATH = \"..\"  # nopep8\n",
    "sys.path.append(MAINPATH)  # nopep8\n",
    "import jraph\n",
    "import src\n",
    "from jax.config import config\n",
    "# from src import fgn, lnn\n",
    "from src.graph import *\n",
    "# from src.lnn import acceleration, accelerationFull, accelerationTV\n",
    "from src.md import *\n",
    "from src.models import MSE, initialize_mlp, GaussianNLL, initialize_mlp_gamma, forward_pass_gamma\n",
    "from src.nve import NVEStates, nve, BrownianStates\n",
    "from src.utils import *\n",
    "\n",
    "# config.update(\"jax_enable_x64\", True)\n",
    "# config.update(\"jax_debug_nans\", True)\n",
    "# jax.config.update('jax_platform_name', 'gpu')\n",
    "\n",
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "\n",
    "def pprint(*args, namespace=globals()):\n",
    "    for arg in args:\n",
    "        print(f\"{namestr(arg, namespace)[0]}: {arg}\")\n",
    "\n",
    "f32 = jnp.float32\n",
    "f64 = jnp.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs: \n",
      "N: 10\n",
      "epochs: 10000\n",
      "seed: 42\n",
      "rname: True\n",
      "dt: 0.001\n",
      "lr: 0.0001\n",
      "batch_size: 20\n"
     ]
    }
   ],
   "source": [
    "N = 10  # number of particles\n",
    "dim = 2  # dimensions\n",
    "runs = 1\n",
    "kT = 1 #1.380649e-23*T  # boltzmann constant*temperature\n",
    "# spring_constant = 1.0\n",
    "# length_constant = 1.0\n",
    "# nconfig=100\n",
    "seed=42\n",
    "dt = 1.0e-3 # time step*stride \n",
    "lr=1e-4\n",
    "batch_size=20\n",
    "epochs = 10000\n",
    "# node_type = jnp.array([0,0,0,0,0])\n",
    "masses = jnp.ones(N)\n",
    "# masses = 1.0#jnp.where(jnp.arange(N) <3, 1.0, 1.0)\n",
    "species = np.where(np.arange(N) < 3, 0, 1) #jnp.zeros(N, dtype=int)\n",
    "# gamma = jnp.ones(jnp.unique(species).shape)  # damping constant\n",
    "gamma = jnp.where(jnp.arange(N) <3, 1.0, 2.0).reshape(-1,1)\n",
    "\n",
    "rname=True\n",
    "withdata = None\n",
    "\n",
    "print(\"Configs: \")\n",
    "pprint(N, epochs, seed, rname, dt, lr, batch_size, namespace=locals())\n",
    "\n",
    "randfilename = datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "\n",
    "PSYS = f\"a-{N}-AB-Spring-data-brownian_EM\"\n",
    "TAG = f\"2BNN\"\n",
    "out_dir = f\"../results\"\n",
    "\n",
    "def _filename(name, tag=TAG):\n",
    "    rstring = randfilename if (rname and (tag != \"data\")) else (\n",
    "        \"0\" if (tag == \"data\") or (withdata == None) else f\"0_{withdata}\")\n",
    "    filename_prefix = f\"{out_dir}/{PSYS}-{tag}/{rstring}/\"\n",
    "    file = f\"{filename_prefix}/{name}\"\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    filename = f\"{filename_prefix}/{name}\".replace(\"//\", \"/\")\n",
    "    print(\"===\", filename, \"===\")\n",
    "    return filename\n",
    "\n",
    "def displacement(a, b):\n",
    "    return a - b\n",
    "\n",
    "def shift(R, dR):\n",
    "    return R+dR\n",
    "\n",
    "def OUT(f):\n",
    "    @wraps(f)\n",
    "    def func(file, *args, tag=TAG, **kwargs):\n",
    "        return f(_filename(file, tag=tag), *args, **kwargs)\n",
    "    return func\n",
    "\n",
    "loadmodel = OUT(src.models.loadmodel)\n",
    "savemodel = OUT(src.models.savemodel)\n",
    "\n",
    "loadfile = OUT(src.io.loadfile)\n",
    "savefile = OUT(src.io.savefile)\n",
    "save_ovito = OUT(src.io.save_ovito)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../results/a-10-AB-Spring-data-brownian_EM-data/0/model_states_brownian.pkl ===\n",
      "Total number of data points: 100x100\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "################## CONFIG ######################\n",
    "################################################\n",
    "np.random.seed(seed)\n",
    "key = random.PRNGKey(seed)\n",
    "\n",
    "try:\n",
    "    dataset_states = loadfile(f\"model_states_brownian.pkl\", tag=\"data\")[0]\n",
    "except:\n",
    "    raise Exception(\"Generate dataset first.\")\n",
    "\n",
    "model_states = dataset_states[0]\n",
    "\n",
    "print(f\"Total number of data points: {len(dataset_states)}x{model_states.position.shape[0]}\")\n",
    "\n",
    "Rs = States_Brow().fromlist(dataset_states).get_array()\n",
    "\n",
    "Rs_in = Rs[:,:99,:,:]\n",
    "Rs_out = Rs[:,1:100,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################### ML Model ###################\n",
    "################################################\n",
    "# print(\"Creating Chain\")\n",
    "x, _, senders, receivers = chain(N)\n",
    "\n",
    "hidden = 16\n",
    "nhidden = 2\n",
    "\n",
    "def get_layers(in_, out_):\n",
    "    return [in_] + [hidden]*nhidden + [out_]\n",
    "\n",
    "def mlp(in_, out_, key, **kwargs):\n",
    "    return initialize_mlp(get_layers(in_, out_), key, **kwargs)\n",
    "\n",
    "params = {\"F_pos\": mlp(N*dim, N*dim, key)}\n",
    "\n",
    "params[\"gamma\"] = initialize_mlp_gamma([1,10,5,1], key)\n",
    "\n",
    "def nngamma(type, params):\n",
    "    return forward_pass_gamma(params, type, activation_fn=models.SquarePlus)\n",
    "\n",
    "def gamma(type, params):\n",
    "    return vmap(nngamma, in_axes=(0, None))(type.reshape(-1), params).reshape(-1, 1)\n",
    "    # return nngamma(type.reshape(-1), params[\"gamma\"])#.reshape(-1, 1)\n",
    "\n",
    "# ss = gamma(jax.nn.one_hot(species, 1),params[\"gamma\"])\n",
    "\n",
    "\n",
    "def acceleration_node(x, params, **kwargs):\n",
    "    n,dim = x.shape\n",
    "    inp = x.flatten() #jnp.hstack([x.flatten(),v.flatten()])\n",
    "    out = forward_pass(params, inp)\n",
    "    return out.reshape(-1,dim)\n",
    "\n",
    "def _force_fn():    \n",
    "    def apply(R, params):\n",
    "        return acceleration_node(R, params)\n",
    "    return apply\n",
    "\n",
    "def gamma_fn(species):    \n",
    "    def fn(params):\n",
    "        return gamma(jax.nn.one_hot(species, 1),params)    \n",
    "    return fn\n",
    "\n",
    "apply_fn = _force_fn()\n",
    "gamma_fn = gamma_fn(species)\n",
    "\n",
    "def force_fn_model(x, params): return apply_fn(x, params['F_pos'])\n",
    "def gamma_fn_model(params): return gamma_fn(params[\"gamma\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_step_pos_gamma(force_fn_model, gamma_fn_model, shift, dt, kT, mass, runs, key):\n",
    "    key, split = random.split(key)\n",
    "    def fn(x, params):\n",
    "        for i in range(runs):\n",
    "            # calculate the force\n",
    "            force = force_fn_model(x, params)\n",
    "            _gamma = gamma_fn_model(params)\n",
    "            xi = random.normal(split, x.shape, x.dtype)\n",
    "            nu = f32(1) / lax.mul(mass.reshape(-1,1) , _gamma)\n",
    "            x = x+ force * dt * nu + jnp.sqrt(f32(2) * kT * dt * nu) * xi\n",
    "        return x, _gamma\n",
    "    return fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = random.PRNGKey(0)\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "\n",
    "next_step_pos_gamma_fn = next_step_pos_gamma(force_fn_model, gamma_fn_model, shift, dt, kT, masses, runs, subkey)\n",
    "v_next_step_pos_gamma_fn = vmap(next_step_pos_gamma_fn, in_axes=(0, None))\n",
    "v_v_next_step_pos_gamma_fn = vmap(v_next_step_pos_gamma_fn, in_axes=(0, None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "Epoch: 0/10000 Loss (MSE):  train=2.8908004760742188\n",
      "gammaaaaa:  [[5.2292576]\n",
      " [5.2292576]\n",
      " [5.2292576]\n",
      " [4.1524763]\n",
      " [4.1524763]\n",
      " [4.1524763]\n",
      " [4.1524763]\n",
      " [4.1524763]\n",
      " [4.1524763]\n",
      " [4.1524763]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 10/10000 Loss (MSE):  train=2.8309552669525146\n",
      "Epoch: 20/10000 Loss (MSE):  train=2.772874355316162\n",
      "Epoch: 30/10000 Loss (MSE):  train=2.7165098190307617\n",
      "Epoch: 40/10000 Loss (MSE):  train=2.6617350578308105\n",
      "Epoch: 50/10000 Loss (MSE):  train=2.6084020137786865\n",
      "Epoch: 60/10000 Loss (MSE):  train=2.556358814239502\n",
      "Epoch: 70/10000 Loss (MSE):  train=2.5054497718811035\n",
      "Epoch: 80/10000 Loss (MSE):  train=2.4555044174194336\n",
      "Epoch: 90/10000 Loss (MSE):  train=2.4063591957092285\n",
      "Epoch: 100/10000 Loss (MSE):  train=2.3578360080718994\n",
      "gammaaaaa:  [[3.9189782]\n",
      " [3.9189782]\n",
      " [3.9189782]\n",
      " [3.161879 ]\n",
      " [3.161879 ]\n",
      " [3.161879 ]\n",
      " [3.161879 ]\n",
      " [3.161879 ]\n",
      " [3.161879 ]\n",
      " [3.161879 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 110/10000 Loss (MSE):  train=2.3097548484802246\n",
      "Epoch: 120/10000 Loss (MSE):  train=2.2619128227233887\n",
      "Epoch: 130/10000 Loss (MSE):  train=2.2141008377075195\n",
      "Epoch: 140/10000 Loss (MSE):  train=2.166109085083008\n",
      "Epoch: 150/10000 Loss (MSE):  train=2.1177117824554443\n",
      "Epoch: 160/10000 Loss (MSE):  train=2.0686850547790527\n",
      "Epoch: 170/10000 Loss (MSE):  train=2.0188000202178955\n",
      "Epoch: 180/10000 Loss (MSE):  train=1.9678349494934082\n",
      "Epoch: 190/10000 Loss (MSE):  train=1.9155690670013428\n",
      "Epoch: 200/10000 Loss (MSE):  train=1.861803650856018\n",
      "gammaaaaa:  [[2.9006438]\n",
      " [2.9006438]\n",
      " [2.9006438]\n",
      " [2.3793106]\n",
      " [2.3793106]\n",
      " [2.3793106]\n",
      " [2.3793106]\n",
      " [2.3793106]\n",
      " [2.3793106]\n",
      " [2.3793106]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 210/10000 Loss (MSE):  train=1.8063745498657227\n",
      "Epoch: 220/10000 Loss (MSE):  train=1.7491590976715088\n",
      "Epoch: 230/10000 Loss (MSE):  train=1.6900975704193115\n",
      "Epoch: 240/10000 Loss (MSE):  train=1.629188060760498\n",
      "Epoch: 250/10000 Loss (MSE):  train=1.5665141344070435\n",
      "Epoch: 260/10000 Loss (MSE):  train=1.5022324323654175\n",
      "Epoch: 270/10000 Loss (MSE):  train=1.4365969896316528\n",
      "Epoch: 280/10000 Loss (MSE):  train=1.3700251579284668\n",
      "Epoch: 290/10000 Loss (MSE):  train=1.3031178712844849\n",
      "Epoch: 300/10000 Loss (MSE):  train=1.2366528511047363\n",
      "gammaaaaa:  [[2.0713212]\n",
      " [2.0713212]\n",
      " [2.0713212]\n",
      " [1.7308964]\n",
      " [1.7308964]\n",
      " [1.7308964]\n",
      " [1.7308964]\n",
      " [1.7308964]\n",
      " [1.7308964]\n",
      " [1.7308964]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 310/10000 Loss (MSE):  train=1.171494960784912\n",
      "Epoch: 320/10000 Loss (MSE):  train=1.108553171157837\n",
      "Epoch: 330/10000 Loss (MSE):  train=1.04872727394104\n",
      "Epoch: 340/10000 Loss (MSE):  train=0.9928462505340576\n",
      "Epoch: 350/10000 Loss (MSE):  train=0.9416028261184692\n",
      "Epoch: 360/10000 Loss (MSE):  train=0.8955052495002747\n",
      "Epoch: 370/10000 Loss (MSE):  train=0.8548276424407959\n",
      "Epoch: 380/10000 Loss (MSE):  train=0.8195796608924866\n",
      "Epoch: 390/10000 Loss (MSE):  train=0.7895159125328064\n",
      "Epoch: 400/10000 Loss (MSE):  train=0.76416015625\n",
      "gammaaaaa:  [[1.5299796]\n",
      " [1.5299796]\n",
      " [1.5299796]\n",
      " [1.3235452]\n",
      " [1.3235452]\n",
      " [1.3235452]\n",
      " [1.3235452]\n",
      " [1.3235452]\n",
      " [1.3235452]\n",
      " [1.3235452]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 410/10000 Loss (MSE):  train=0.7428835034370422\n",
      "Epoch: 420/10000 Loss (MSE):  train=0.7249987721443176\n",
      "Epoch: 430/10000 Loss (MSE):  train=0.709843099117279\n",
      "Epoch: 440/10000 Loss (MSE):  train=0.6968398094177246\n",
      "Epoch: 450/10000 Loss (MSE):  train=0.6855283975601196\n",
      "Epoch: 460/10000 Loss (MSE):  train=0.6755539178848267\n",
      "Epoch: 470/10000 Loss (MSE):  train=0.6666593551635742\n",
      "Epoch: 480/10000 Loss (MSE):  train=0.6586527228355408\n",
      "Epoch: 490/10000 Loss (MSE):  train=0.651391327381134\n",
      "Epoch: 500/10000 Loss (MSE):  train=0.6447722315788269\n",
      "gammaaaaa:  [[1.4256501]\n",
      " [1.4256501]\n",
      " [1.4256501]\n",
      " [1.3215525]\n",
      " [1.3215525]\n",
      " [1.3215525]\n",
      " [1.3215525]\n",
      " [1.3215525]\n",
      " [1.3215525]\n",
      " [1.3215525]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 510/10000 Loss (MSE):  train=0.6387094259262085\n",
      "Epoch: 520/10000 Loss (MSE):  train=0.6331403255462646\n",
      "Epoch: 530/10000 Loss (MSE):  train=0.6280087828636169\n",
      "Epoch: 540/10000 Loss (MSE):  train=0.6232703328132629\n",
      "Epoch: 550/10000 Loss (MSE):  train=0.6188850402832031\n",
      "Epoch: 560/10000 Loss (MSE):  train=0.6148180961608887\n",
      "Epoch: 570/10000 Loss (MSE):  train=0.6110391616821289\n",
      "Epoch: 580/10000 Loss (MSE):  train=0.6075199842453003\n",
      "Epoch: 590/10000 Loss (MSE):  train=0.6042355298995972\n",
      "Epoch: 600/10000 Loss (MSE):  train=0.6011626720428467\n",
      "gammaaaaa:  [[1.4188696]\n",
      " [1.4188696]\n",
      " [1.4188696]\n",
      " [1.431444 ]\n",
      " [1.431444 ]\n",
      " [1.431444 ]\n",
      " [1.431444 ]\n",
      " [1.431444 ]\n",
      " [1.4314443]\n",
      " [1.4314443]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sureshjyoti/GitHub/BGNODE_scratch/.venv_jaxbrow/lib/python3.9/site-packages/shadow/plot.py:181: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=figsize, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 610/10000 Loss (MSE):  train=0.5982812643051147\n",
      "Epoch: 620/10000 Loss (MSE):  train=0.5955730676651001\n",
      "Epoch: 630/10000 Loss (MSE):  train=0.5930196642875671\n",
      "Epoch: 640/10000 Loss (MSE):  train=0.5906051397323608\n",
      "Epoch: 650/10000 Loss (MSE):  train=0.5883181691169739\n",
      "Epoch: 660/10000 Loss (MSE):  train=0.5861432552337646\n",
      "Epoch: 670/10000 Loss (MSE):  train=0.5840705633163452\n",
      "Epoch: 680/10000 Loss (MSE):  train=0.5820896029472351\n",
      "Epoch: 690/10000 Loss (MSE):  train=0.5801909565925598\n",
      "Epoch: 700/10000 Loss (MSE):  train=0.578366756439209\n",
      "gammaaaaa:  [[1.3822011]\n",
      " [1.3822011]\n",
      " [1.3822011]\n",
      " [1.5324584]\n",
      " [1.5324584]\n",
      " [1.5324584]\n",
      " [1.5324584]\n",
      " [1.5324584]\n",
      " [1.5324583]\n",
      " [1.5324583]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 710/10000 Loss (MSE):  train=0.5766109228134155\n",
      "Epoch: 720/10000 Loss (MSE):  train=0.5749167799949646\n",
      "Epoch: 730/10000 Loss (MSE):  train=0.5732788443565369\n",
      "Epoch: 740/10000 Loss (MSE):  train=0.5716933608055115\n",
      "Epoch: 750/10000 Loss (MSE):  train=0.5701557397842407\n",
      "Epoch: 760/10000 Loss (MSE):  train=0.5686633586883545\n",
      "Epoch: 770/10000 Loss (MSE):  train=0.5672132968902588\n",
      "Epoch: 780/10000 Loss (MSE):  train=0.5658026933670044\n",
      "Epoch: 790/10000 Loss (MSE):  train=0.5644302368164062\n",
      "Epoch: 800/10000 Loss (MSE):  train=0.5630947947502136\n",
      "gammaaaaa:  [[1.3179514]\n",
      " [1.3179514]\n",
      " [1.3179514]\n",
      " [1.6198889]\n",
      " [1.6198889]\n",
      " [1.6198889]\n",
      " [1.6198889]\n",
      " [1.6198889]\n",
      " [1.6198889]\n",
      " [1.6198889]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 810/10000 Loss (MSE):  train=0.5617942810058594\n",
      "Epoch: 820/10000 Loss (MSE):  train=0.5605290532112122\n",
      "Epoch: 830/10000 Loss (MSE):  train=0.5592970848083496\n",
      "Epoch: 840/10000 Loss (MSE):  train=0.5580980777740479\n",
      "Epoch: 850/10000 Loss (MSE):  train=0.556931734085083\n",
      "Epoch: 860/10000 Loss (MSE):  train=0.5557980537414551\n",
      "Epoch: 870/10000 Loss (MSE):  train=0.5546973943710327\n",
      "Epoch: 880/10000 Loss (MSE):  train=0.5536271929740906\n",
      "Epoch: 890/10000 Loss (MSE):  train=0.5525901913642883\n",
      "Epoch: 900/10000 Loss (MSE):  train=0.5515843629837036\n",
      "gammaaaaa:  [[1.2435623]\n",
      " [1.2435623]\n",
      " [1.2435623]\n",
      " [1.7015554]\n",
      " [1.7015554]\n",
      " [1.7015554]\n",
      " [1.7015554]\n",
      " [1.7015554]\n",
      " [1.7015555]\n",
      " [1.7015555]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 910/10000 Loss (MSE):  train=0.5506106019020081\n",
      "Epoch: 920/10000 Loss (MSE):  train=0.5496691465377808\n",
      "Epoch: 930/10000 Loss (MSE):  train=0.5487591028213501\n",
      "Epoch: 940/10000 Loss (MSE):  train=0.5478811860084534\n",
      "Epoch: 950/10000 Loss (MSE):  train=0.5470340847969055\n",
      "Epoch: 960/10000 Loss (MSE):  train=0.5462189316749573\n",
      "Epoch: 970/10000 Loss (MSE):  train=0.5454354882240295\n",
      "Epoch: 980/10000 Loss (MSE):  train=0.5446832180023193\n",
      "Epoch: 990/10000 Loss (MSE):  train=0.543961226940155\n",
      "Epoch: 1000/10000 Loss (MSE):  train=0.5432703495025635\n",
      "gammaaaaa:  [[1.1722182]\n",
      " [1.1722182]\n",
      " [1.1722182]\n",
      " [1.7803125]\n",
      " [1.7803125]\n",
      " [1.7803125]\n",
      " [1.7803125]\n",
      " [1.7803125]\n",
      " [1.7803125]\n",
      " [1.7803125]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 1010/10000 Loss (MSE):  train=0.5426092147827148\n",
      "Epoch: 1020/10000 Loss (MSE):  train=0.5419787764549255\n",
      "Epoch: 1030/10000 Loss (MSE):  train=0.5413776636123657\n",
      "Epoch: 1040/10000 Loss (MSE):  train=0.5408058762550354\n",
      "Epoch: 1050/10000 Loss (MSE):  train=0.5402616262435913\n",
      "Epoch: 1060/10000 Loss (MSE):  train=0.539745569229126\n",
      "Epoch: 1070/10000 Loss (MSE):  train=0.5392568707466125\n",
      "Epoch: 1080/10000 Loss (MSE):  train=0.5387939214706421\n",
      "Epoch: 1090/10000 Loss (MSE):  train=0.5383566617965698\n",
      "Epoch: 1100/10000 Loss (MSE):  train=0.537944495677948\n",
      "gammaaaaa:  [[1.1114163]\n",
      " [1.1114163]\n",
      " [1.1114163]\n",
      " [1.8524493]\n",
      " [1.8524493]\n",
      " [1.8524493]\n",
      " [1.8524493]\n",
      " [1.8524493]\n",
      " [1.8524494]\n",
      " [1.8524494]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 1110/10000 Loss (MSE):  train=0.5375558733940125\n",
      "Epoch: 1120/10000 Loss (MSE):  train=0.5371904373168945\n",
      "Epoch: 1130/10000 Loss (MSE):  train=0.5368468165397644\n",
      "Epoch: 1140/10000 Loss (MSE):  train=0.5365248918533325\n",
      "Epoch: 1150/10000 Loss (MSE):  train=0.5362222790718079\n",
      "Epoch: 1160/10000 Loss (MSE):  train=0.5359398126602173\n",
      "Epoch: 1170/10000 Loss (MSE):  train=0.5356756448745728\n",
      "Epoch: 1180/10000 Loss (MSE):  train=0.5354284048080444\n",
      "Epoch: 1190/10000 Loss (MSE):  train=0.5351969003677368\n",
      "Epoch: 1200/10000 Loss (MSE):  train=0.5349811315536499\n",
      "gammaaaaa:  [[1.0650129]\n",
      " [1.0650129]\n",
      " [1.0650129]\n",
      " [1.9116558]\n",
      " [1.9116558]\n",
      " [1.9116558]\n",
      " [1.9116558]\n",
      " [1.9116558]\n",
      " [1.9116558]\n",
      " [1.9116558]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 1210/10000 Loss (MSE):  train=0.53477942943573\n",
      "Epoch: 1220/10000 Loss (MSE):  train=0.5345906615257263\n",
      "Epoch: 1230/10000 Loss (MSE):  train=0.5344151258468628\n",
      "Epoch: 1240/10000 Loss (MSE):  train=0.5342503190040588\n",
      "Epoch: 1250/10000 Loss (MSE):  train=0.534096360206604\n",
      "Epoch: 1260/10000 Loss (MSE):  train=0.5339518189430237\n",
      "Epoch: 1270/10000 Loss (MSE):  train=0.5338160991668701\n",
      "Epoch: 1280/10000 Loss (MSE):  train=0.5336893200874329\n",
      "Epoch: 1290/10000 Loss (MSE):  train=0.5335691571235657\n",
      "Epoch: 1300/10000 Loss (MSE):  train=0.5334559082984924\n",
      "gammaaaaa:  [[1.0338868]\n",
      " [1.0338868]\n",
      " [1.0338868]\n",
      " [1.9536188]\n",
      " [1.9536188]\n",
      " [1.9536188]\n",
      " [1.9536188]\n",
      " [1.9536188]\n",
      " [1.9536188]\n",
      " [1.9536188]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 1310/10000 Loss (MSE):  train=0.5333477854728699\n",
      "Epoch: 1320/10000 Loss (MSE):  train=0.5332459211349487\n",
      "Epoch: 1330/10000 Loss (MSE):  train=0.533147931098938\n",
      "Epoch: 1340/10000 Loss (MSE):  train=0.5330533981323242\n",
      "Epoch: 1350/10000 Loss (MSE):  train=0.5329629182815552\n",
      "Epoch: 1360/10000 Loss (MSE):  train=0.532874584197998\n",
      "Epoch: 1370/10000 Loss (MSE):  train=0.5327875018119812\n",
      "Epoch: 1380/10000 Loss (MSE):  train=0.5327020883560181\n",
      "Epoch: 1390/10000 Loss (MSE):  train=0.5326156616210938\n",
      "Epoch: 1400/10000 Loss (MSE):  train=0.5325295925140381\n",
      "gammaaaaa:  [[1.0161198]\n",
      " [1.0161198]\n",
      " [1.0161198]\n",
      " [1.9786485]\n",
      " [1.9786485]\n",
      " [1.9786485]\n",
      " [1.9786485]\n",
      " [1.9786485]\n",
      " [1.9786485]\n",
      " [1.9786485]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 1410/10000 Loss (MSE):  train=0.5324448943138123\n",
      "Epoch: 1420/10000 Loss (MSE):  train=0.5323633551597595\n",
      "Epoch: 1430/10000 Loss (MSE):  train=0.532284140586853\n",
      "Epoch: 1440/10000 Loss (MSE):  train=0.5322065353393555\n",
      "Epoch: 1450/10000 Loss (MSE):  train=0.5321305990219116\n",
      "Epoch: 1460/10000 Loss (MSE):  train=0.5320560932159424\n",
      "Epoch: 1470/10000 Loss (MSE):  train=0.5319831371307373\n",
      "Epoch: 1480/10000 Loss (MSE):  train=0.5319098830223083\n",
      "Epoch: 1490/10000 Loss (MSE):  train=0.5318373441696167\n",
      "Epoch: 1500/10000 Loss (MSE):  train=0.5317651629447937\n",
      "gammaaaaa:  [[1.0075675]\n",
      " [1.0075675]\n",
      " [1.0075675]\n",
      " [1.9906862]\n",
      " [1.9906862]\n",
      " [1.9906862]\n",
      " [1.9906862]\n",
      " [1.9906862]\n",
      " [1.9906862]\n",
      " [1.9906862]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 1510/10000 Loss (MSE):  train=0.5316940546035767\n",
      "Epoch: 1520/10000 Loss (MSE):  train=0.5316228270530701\n",
      "Epoch: 1530/10000 Loss (MSE):  train=0.5315516591072083\n",
      "Epoch: 1540/10000 Loss (MSE):  train=0.5314809679985046\n",
      "Epoch: 1550/10000 Loss (MSE):  train=0.5314100980758667\n",
      "Epoch: 1560/10000 Loss (MSE):  train=0.5313395261764526\n",
      "Epoch: 1570/10000 Loss (MSE):  train=0.5312684178352356\n",
      "Epoch: 1580/10000 Loss (MSE):  train=0.5311989784240723\n",
      "Epoch: 1590/10000 Loss (MSE):  train=0.5311275720596313\n",
      "Epoch: 1600/10000 Loss (MSE):  train=0.531057596206665\n",
      "gammaaaaa:  [[1.0040828]\n",
      " [1.0040828]\n",
      " [1.0040828]\n",
      " [1.9955523]\n",
      " [1.9955523]\n",
      " [1.9955523]\n",
      " [1.9955523]\n",
      " [1.9955523]\n",
      " [1.9955523]\n",
      " [1.9955523]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 1610/10000 Loss (MSE):  train=0.5309873819351196\n",
      "Epoch: 1620/10000 Loss (MSE):  train=0.5309169888496399\n",
      "Epoch: 1630/10000 Loss (MSE):  train=0.5308464765548706\n",
      "Epoch: 1640/10000 Loss (MSE):  train=0.5307762026786804\n",
      "Epoch: 1650/10000 Loss (MSE):  train=0.5307055711746216\n",
      "Epoch: 1660/10000 Loss (MSE):  train=0.5306355357170105\n",
      "Epoch: 1670/10000 Loss (MSE):  train=0.5305655002593994\n",
      "Epoch: 1680/10000 Loss (MSE):  train=0.530495285987854\n",
      "Epoch: 1690/10000 Loss (MSE):  train=0.5304247140884399\n",
      "Epoch: 1700/10000 Loss (MSE):  train=0.5303544998168945\n",
      "gammaaaaa:  [[1.0029286]\n",
      " [1.0029286]\n",
      " [1.0029286]\n",
      " [1.9970014]\n",
      " [1.9970014]\n",
      " [1.9970014]\n",
      " [1.9970014]\n",
      " [1.9970014]\n",
      " [1.9970014]\n",
      " [1.9970014]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 1710/10000 Loss (MSE):  train=0.5302843451499939\n",
      "Epoch: 1720/10000 Loss (MSE):  train=0.5302137136459351\n",
      "Epoch: 1730/10000 Loss (MSE):  train=0.5301429629325867\n",
      "Epoch: 1740/10000 Loss (MSE):  train=0.5300732254981995\n",
      "Epoch: 1750/10000 Loss (MSE):  train=0.5300024747848511\n",
      "Epoch: 1760/10000 Loss (MSE):  train=0.5299316048622131\n",
      "Epoch: 1770/10000 Loss (MSE):  train=0.5298615097999573\n",
      "Epoch: 1780/10000 Loss (MSE):  train=0.5297912359237671\n",
      "Epoch: 1790/10000 Loss (MSE):  train=0.5297206044197083\n",
      "Epoch: 1800/10000 Loss (MSE):  train=0.5296500325202942\n",
      "gammaaaaa:  [[1.002603 ]\n",
      " [1.002603 ]\n",
      " [1.002603 ]\n",
      " [1.9972076]\n",
      " [1.9972076]\n",
      " [1.9972076]\n",
      " [1.9972076]\n",
      " [1.9972076]\n",
      " [1.9972076]\n",
      " [1.9972076]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 1810/10000 Loss (MSE):  train=0.5295796990394592\n",
      "Epoch: 1820/10000 Loss (MSE):  train=0.5295085310935974\n",
      "Epoch: 1830/10000 Loss (MSE):  train=0.5294380187988281\n",
      "Epoch: 1840/10000 Loss (MSE):  train=0.5293674468994141\n",
      "Epoch: 1850/10000 Loss (MSE):  train=0.5292965769767761\n",
      "Epoch: 1860/10000 Loss (MSE):  train=0.5292259454727173\n",
      "Epoch: 1870/10000 Loss (MSE):  train=0.5291553735733032\n",
      "Epoch: 1880/10000 Loss (MSE):  train=0.5290844440460205\n",
      "Epoch: 1890/10000 Loss (MSE):  train=0.5290133953094482\n",
      "Epoch: 1900/10000 Loss (MSE):  train=0.5289427042007446\n",
      "gammaaaaa:  [[1.0025082]\n",
      " [1.0025082]\n",
      " [1.0025082]\n",
      " [1.9970605]\n",
      " [1.9970605]\n",
      " [1.9970605]\n",
      " [1.9970605]\n",
      " [1.9970605]\n",
      " [1.9970605]\n",
      " [1.9970605]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 1910/10000 Loss (MSE):  train=0.5288715362548828\n",
      "Epoch: 1920/10000 Loss (MSE):  train=0.5288001298904419\n",
      "Epoch: 1930/10000 Loss (MSE):  train=0.528728723526001\n",
      "Epoch: 1940/10000 Loss (MSE):  train=0.5286581516265869\n",
      "Epoch: 1950/10000 Loss (MSE):  train=0.5285866260528564\n",
      "Epoch: 1960/10000 Loss (MSE):  train=0.5285155773162842\n",
      "Epoch: 1970/10000 Loss (MSE):  train=0.5284443497657776\n",
      "Epoch: 1980/10000 Loss (MSE):  train=0.5283728241920471\n",
      "Epoch: 1990/10000 Loss (MSE):  train=0.5283011198043823\n",
      "Epoch: 2000/10000 Loss (MSE):  train=0.5282295942306519\n",
      "gammaaaaa:  [[1.0024638]\n",
      " [1.0024638]\n",
      " [1.0024638]\n",
      " [1.9968259]\n",
      " [1.9968259]\n",
      " [1.9968259]\n",
      " [1.9968259]\n",
      " [1.9968259]\n",
      " [1.9968259]\n",
      " [1.9968259]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 2010/10000 Loss (MSE):  train=0.5281581282615662\n",
      "Epoch: 2020/10000 Loss (MSE):  train=0.5280863046646118\n",
      "Epoch: 2030/10000 Loss (MSE):  train=0.528014063835144\n",
      "Epoch: 2040/10000 Loss (MSE):  train=0.527942419052124\n",
      "Epoch: 2050/10000 Loss (MSE):  train=0.5278704762458801\n",
      "Epoch: 2060/10000 Loss (MSE):  train=0.5277979373931885\n",
      "Epoch: 2070/10000 Loss (MSE):  train=0.5277262926101685\n",
      "Epoch: 2080/10000 Loss (MSE):  train=0.527654230594635\n",
      "Epoch: 2090/10000 Loss (MSE):  train=0.5275811553001404\n",
      "Epoch: 2100/10000 Loss (MSE):  train=0.5275090336799622\n",
      "gammaaaaa:  [[1.0024287]\n",
      " [1.0024287]\n",
      " [1.0024287]\n",
      " [1.9965653]\n",
      " [1.9965653]\n",
      " [1.9965653]\n",
      " [1.9965653]\n",
      " [1.9965653]\n",
      " [1.9965653]\n",
      " [1.9965653]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 2110/10000 Loss (MSE):  train=0.527436375617981\n",
      "Epoch: 2120/10000 Loss (MSE):  train=0.5273641347885132\n",
      "Epoch: 2130/10000 Loss (MSE):  train=0.5272911787033081\n",
      "Epoch: 2140/10000 Loss (MSE):  train=0.5272184014320374\n",
      "Epoch: 2150/10000 Loss (MSE):  train=0.527145266532898\n",
      "Epoch: 2160/10000 Loss (MSE):  train=0.5270718932151794\n",
      "Epoch: 2170/10000 Loss (MSE):  train=0.5269992351531982\n",
      "Epoch: 2180/10000 Loss (MSE):  train=0.5269251465797424\n",
      "Epoch: 2190/10000 Loss (MSE):  train=0.5268523693084717\n",
      "Epoch: 2200/10000 Loss (MSE):  train=0.5267784595489502\n",
      "gammaaaaa:  [[1.0023973]\n",
      " [1.0023973]\n",
      " [1.0023973]\n",
      " [1.9962916]\n",
      " [1.9962916]\n",
      " [1.9962916]\n",
      " [1.9962916]\n",
      " [1.9962916]\n",
      " [1.9962916]\n",
      " [1.9962916]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 2210/10000 Loss (MSE):  train=0.5267046689987183\n",
      "Epoch: 2220/10000 Loss (MSE):  train=0.5266308784484863\n",
      "Epoch: 2230/10000 Loss (MSE):  train=0.5265564322471619\n",
      "Epoch: 2240/10000 Loss (MSE):  train=0.5264818668365479\n",
      "Epoch: 2250/10000 Loss (MSE):  train=0.5264067649841309\n",
      "Epoch: 2260/10000 Loss (MSE):  train=0.5263316631317139\n",
      "Epoch: 2270/10000 Loss (MSE):  train=0.5262554883956909\n",
      "Epoch: 2280/10000 Loss (MSE):  train=0.5261790752410889\n",
      "Epoch: 2290/10000 Loss (MSE):  train=0.5261015892028809\n",
      "Epoch: 2300/10000 Loss (MSE):  train=0.5260239839553833\n",
      "gammaaaaa:  [[1.0023861]\n",
      " [1.0023861]\n",
      " [1.0023861]\n",
      " [1.9960568]\n",
      " [1.9960568]\n",
      " [1.9960568]\n",
      " [1.9960568]\n",
      " [1.9960568]\n",
      " [1.9960568]\n",
      " [1.9960568]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 2310/10000 Loss (MSE):  train=0.5259456634521484\n",
      "Epoch: 2320/10000 Loss (MSE):  train=0.5258672833442688\n",
      "Epoch: 2330/10000 Loss (MSE):  train=0.5257892608642578\n",
      "Epoch: 2340/10000 Loss (MSE):  train=0.5257118940353394\n",
      "Epoch: 2350/10000 Loss (MSE):  train=0.5256345868110657\n",
      "Epoch: 2360/10000 Loss (MSE):  train=0.5255563259124756\n",
      "Epoch: 2370/10000 Loss (MSE):  train=0.5254788994789124\n",
      "Epoch: 2380/10000 Loss (MSE):  train=0.5254014730453491\n",
      "Epoch: 2390/10000 Loss (MSE):  train=0.5253230929374695\n",
      "Epoch: 2400/10000 Loss (MSE):  train=0.5252454876899719\n",
      "gammaaaaa:  [[1.0023223]\n",
      " [1.0023223]\n",
      " [1.0023223]\n",
      " [1.9957691]\n",
      " [1.9957691]\n",
      " [1.9957691]\n",
      " [1.9957691]\n",
      " [1.9957691]\n",
      " [1.9957693]\n",
      " [1.9957693]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 2410/10000 Loss (MSE):  train=0.5251672267913818\n",
      "Epoch: 2420/10000 Loss (MSE):  train=0.5250895023345947\n",
      "Epoch: 2430/10000 Loss (MSE):  train=0.5250110030174255\n",
      "Epoch: 2440/10000 Loss (MSE):  train=0.5249324440956116\n",
      "Epoch: 2450/10000 Loss (MSE):  train=0.5248538851737976\n",
      "Epoch: 2460/10000 Loss (MSE):  train=0.524775505065918\n",
      "Epoch: 2470/10000 Loss (MSE):  train=0.5246965885162354\n",
      "Epoch: 2480/10000 Loss (MSE):  train=0.5246174335479736\n",
      "Epoch: 2490/10000 Loss (MSE):  train=0.5245381593704224\n",
      "Epoch: 2500/10000 Loss (MSE):  train=0.5244594216346741\n",
      "gammaaaaa:  [[1.0022873]\n",
      " [1.0022873]\n",
      " [1.0022873]\n",
      " [1.9954643]\n",
      " [1.9954643]\n",
      " [1.9954643]\n",
      " [1.9954643]\n",
      " [1.9954643]\n",
      " [1.9954643]\n",
      " [1.9954643]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 2510/10000 Loss (MSE):  train=0.524380087852478\n",
      "Epoch: 2520/10000 Loss (MSE):  train=0.524300754070282\n",
      "Epoch: 2530/10000 Loss (MSE):  train=0.5242208242416382\n",
      "Epoch: 2540/10000 Loss (MSE):  train=0.5241409540176392\n",
      "Epoch: 2550/10000 Loss (MSE):  train=0.5240607261657715\n",
      "Epoch: 2560/10000 Loss (MSE):  train=0.5239804983139038\n",
      "Epoch: 2570/10000 Loss (MSE):  train=0.5238999128341675\n",
      "Epoch: 2580/10000 Loss (MSE):  train=0.5238193273544312\n",
      "Epoch: 2590/10000 Loss (MSE):  train=0.5237388610839844\n",
      "Epoch: 2600/10000 Loss (MSE):  train=0.5236579775810242\n",
      "gammaaaaa:  [[1.0022664]\n",
      " [1.0022664]\n",
      " [1.0022664]\n",
      " [1.9951876]\n",
      " [1.9951876]\n",
      " [1.9951876]\n",
      " [1.9951876]\n",
      " [1.9951876]\n",
      " [1.9951876]\n",
      " [1.9951876]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 2610/10000 Loss (MSE):  train=0.5235762596130371\n",
      "Epoch: 2620/10000 Loss (MSE):  train=0.5234947800636292\n",
      "Epoch: 2630/10000 Loss (MSE):  train=0.5234120488166809\n",
      "Epoch: 2640/10000 Loss (MSE):  train=0.523329496383667\n",
      "Epoch: 2650/10000 Loss (MSE):  train=0.5232464075088501\n",
      "Epoch: 2660/10000 Loss (MSE):  train=0.5231616497039795\n",
      "Epoch: 2670/10000 Loss (MSE):  train=0.523075520992279\n",
      "Epoch: 2680/10000 Loss (MSE):  train=0.5229881405830383\n",
      "Epoch: 2690/10000 Loss (MSE):  train=0.5228983759880066\n",
      "Epoch: 2700/10000 Loss (MSE):  train=0.522807240486145\n",
      "gammaaaaa:  [[1.0023257]\n",
      " [1.0023257]\n",
      " [1.0023257]\n",
      " [1.995022 ]\n",
      " [1.995022 ]\n",
      " [1.995022 ]\n",
      " [1.995022 ]\n",
      " [1.995022 ]\n",
      " [1.995022 ]\n",
      " [1.995022 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 2710/10000 Loss (MSE):  train=0.5227141380310059\n",
      "Epoch: 2720/10000 Loss (MSE):  train=0.522619903087616\n",
      "Epoch: 2730/10000 Loss (MSE):  train=0.5225266218185425\n",
      "Epoch: 2740/10000 Loss (MSE):  train=0.5224357843399048\n",
      "Epoch: 2750/10000 Loss (MSE):  train=0.5223456621170044\n",
      "Epoch: 2760/10000 Loss (MSE):  train=0.5222578048706055\n",
      "Epoch: 2770/10000 Loss (MSE):  train=0.5221697688102722\n",
      "Epoch: 2780/10000 Loss (MSE):  train=0.5220836400985718\n",
      "Epoch: 2790/10000 Loss (MSE):  train=0.5219964385032654\n",
      "Epoch: 2800/10000 Loss (MSE):  train=0.5219099521636963\n",
      "gammaaaaa:  [[1.002272 ]\n",
      " [1.002272 ]\n",
      " [1.002272 ]\n",
      " [1.9949167]\n",
      " [1.9949167]\n",
      " [1.9949167]\n",
      " [1.9949167]\n",
      " [1.9949167]\n",
      " [1.9949167]\n",
      " [1.9949167]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 2810/10000 Loss (MSE):  train=0.5218237638473511\n",
      "Epoch: 2820/10000 Loss (MSE):  train=0.521737813949585\n",
      "Epoch: 2830/10000 Loss (MSE):  train=0.5216522216796875\n",
      "Epoch: 2840/10000 Loss (MSE):  train=0.5215661525726318\n",
      "Epoch: 2850/10000 Loss (MSE):  train=0.5214806199073792\n",
      "Epoch: 2860/10000 Loss (MSE):  train=0.5213948488235474\n",
      "Epoch: 2870/10000 Loss (MSE):  train=0.5213097333908081\n",
      "Epoch: 2880/10000 Loss (MSE):  train=0.5212242007255554\n",
      "Epoch: 2890/10000 Loss (MSE):  train=0.5211386680603027\n",
      "Epoch: 2900/10000 Loss (MSE):  train=0.5210534334182739\n",
      "gammaaaaa:  [[1.0022229]\n",
      " [1.0022229]\n",
      " [1.0022229]\n",
      " [1.9947544]\n",
      " [1.9947544]\n",
      " [1.9947544]\n",
      " [1.9947544]\n",
      " [1.9947544]\n",
      " [1.9947546]\n",
      " [1.9947546]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 2910/10000 Loss (MSE):  train=0.5209681987762451\n",
      "Epoch: 2920/10000 Loss (MSE):  train=0.5208832025527954\n",
      "Epoch: 2930/10000 Loss (MSE):  train=0.5207983255386353\n",
      "Epoch: 2940/10000 Loss (MSE):  train=0.5207130908966064\n",
      "Epoch: 2950/10000 Loss (MSE):  train=0.5206285119056702\n",
      "Epoch: 2960/10000 Loss (MSE):  train=0.5205440521240234\n",
      "Epoch: 2970/10000 Loss (MSE):  train=0.5204595327377319\n",
      "Epoch: 2980/10000 Loss (MSE):  train=0.5203753709793091\n",
      "Epoch: 2990/10000 Loss (MSE):  train=0.5202909111976624\n",
      "Epoch: 3000/10000 Loss (MSE):  train=0.5202070474624634\n",
      "gammaaaaa:  [[1.0022055]\n",
      " [1.0022055]\n",
      " [1.0022055]\n",
      " [1.994659 ]\n",
      " [1.994659 ]\n",
      " [1.994659 ]\n",
      " [1.994659 ]\n",
      " [1.994659 ]\n",
      " [1.994659 ]\n",
      " [1.994659 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 3010/10000 Loss (MSE):  train=0.520122766494751\n",
      "Epoch: 3020/10000 Loss (MSE):  train=0.5200390219688416\n",
      "Epoch: 3030/10000 Loss (MSE):  train=0.5199552774429321\n",
      "Epoch: 3040/10000 Loss (MSE):  train=0.5198719501495361\n",
      "Epoch: 3050/10000 Loss (MSE):  train=0.5197889804840088\n",
      "Epoch: 3060/10000 Loss (MSE):  train=0.5197060704231262\n",
      "Epoch: 3070/10000 Loss (MSE):  train=0.5196227431297302\n",
      "Epoch: 3080/10000 Loss (MSE):  train=0.5195406079292297\n",
      "Epoch: 3090/10000 Loss (MSE):  train=0.5194578766822815\n",
      "Epoch: 3100/10000 Loss (MSE):  train=0.5193756818771362\n",
      "gammaaaaa:  [[1.0021931]\n",
      " [1.0021931]\n",
      " [1.0021931]\n",
      " [1.9946384]\n",
      " [1.9946384]\n",
      " [1.9946384]\n",
      " [1.9946384]\n",
      " [1.9946384]\n",
      " [1.9946381]\n",
      " [1.9946381]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 3110/10000 Loss (MSE):  train=0.5192937850952148\n",
      "Epoch: 3120/10000 Loss (MSE):  train=0.5192116498947144\n",
      "Epoch: 3130/10000 Loss (MSE):  train=0.5191304087638855\n",
      "Epoch: 3140/10000 Loss (MSE):  train=0.5190489888191223\n",
      "Epoch: 3150/10000 Loss (MSE):  train=0.5189679861068726\n",
      "Epoch: 3160/10000 Loss (MSE):  train=0.5188872218132019\n",
      "Epoch: 3170/10000 Loss (MSE):  train=0.5188068151473999\n",
      "Epoch: 3180/10000 Loss (MSE):  train=0.5187268853187561\n",
      "Epoch: 3190/10000 Loss (MSE):  train=0.5186470150947571\n",
      "Epoch: 3200/10000 Loss (MSE):  train=0.5185672044754028\n",
      "gammaaaaa:  [[1.0021844]\n",
      " [1.0021844]\n",
      " [1.0021844]\n",
      " [1.9947   ]\n",
      " [1.9947   ]\n",
      " [1.9947   ]\n",
      " [1.9947   ]\n",
      " [1.9947   ]\n",
      " [1.9947   ]\n",
      " [1.9947   ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 3210/10000 Loss (MSE):  train=0.5184876322746277\n",
      "Epoch: 3220/10000 Loss (MSE):  train=0.5184090733528137\n",
      "Epoch: 3230/10000 Loss (MSE):  train=0.5183309316635132\n",
      "Epoch: 3240/10000 Loss (MSE):  train=0.5182526111602783\n",
      "Epoch: 3250/10000 Loss (MSE):  train=0.5181747674942017\n",
      "Epoch: 3260/10000 Loss (MSE):  train=0.5180972218513489\n",
      "Epoch: 3270/10000 Loss (MSE):  train=0.5180200934410095\n",
      "Epoch: 3280/10000 Loss (MSE):  train=0.517943263053894\n",
      "Epoch: 3290/10000 Loss (MSE):  train=0.5178670287132263\n",
      "Epoch: 3300/10000 Loss (MSE):  train=0.5177912712097168\n",
      "gammaaaaa:  [[1.0021772]\n",
      " [1.0021772]\n",
      " [1.0021772]\n",
      " [1.9948521]\n",
      " [1.9948521]\n",
      " [1.9948521]\n",
      " [1.9948521]\n",
      " [1.9948521]\n",
      " [1.9948521]\n",
      " [1.9948521]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 3310/10000 Loss (MSE):  train=0.5177155137062073\n",
      "Epoch: 3320/10000 Loss (MSE):  train=0.5176406502723694\n",
      "Epoch: 3330/10000 Loss (MSE):  train=0.5175658464431763\n",
      "Epoch: 3340/10000 Loss (MSE):  train=0.5174918174743652\n",
      "Epoch: 3350/10000 Loss (MSE):  train=0.5174179077148438\n",
      "Epoch: 3360/10000 Loss (MSE):  train=0.5173447132110596\n",
      "Epoch: 3370/10000 Loss (MSE):  train=0.5172711610794067\n",
      "Epoch: 3380/10000 Loss (MSE):  train=0.5171992778778076\n",
      "Epoch: 3390/10000 Loss (MSE):  train=0.5171275734901428\n",
      "Epoch: 3400/10000 Loss (MSE):  train=0.5170556306838989\n",
      "gammaaaaa:  [[1.002172 ]\n",
      " [1.002172 ]\n",
      " [1.002172 ]\n",
      " [1.9951038]\n",
      " [1.9951038]\n",
      " [1.9951038]\n",
      " [1.9951038]\n",
      " [1.9951038]\n",
      " [1.9951037]\n",
      " [1.9951037]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 3410/10000 Loss (MSE):  train=0.5169845819473267\n",
      "Epoch: 3420/10000 Loss (MSE):  train=0.516913890838623\n",
      "Epoch: 3430/10000 Loss (MSE):  train=0.5168439149856567\n",
      "Epoch: 3440/10000 Loss (MSE):  train=0.5167742967605591\n",
      "Epoch: 3450/10000 Loss (MSE):  train=0.5167055130004883\n",
      "Epoch: 3460/10000 Loss (MSE):  train=0.5166370868682861\n",
      "Epoch: 3470/10000 Loss (MSE):  train=0.5165694952011108\n",
      "Epoch: 3480/10000 Loss (MSE):  train=0.5165020823478699\n",
      "Epoch: 3490/10000 Loss (MSE):  train=0.516435980796814\n",
      "Epoch: 3500/10000 Loss (MSE):  train=0.5163697600364685\n",
      "gammaaaaa:  [[1.002167]\n",
      " [1.002167]\n",
      " [1.002167]\n",
      " [1.995466]\n",
      " [1.995466]\n",
      " [1.995466]\n",
      " [1.995466]\n",
      " [1.995466]\n",
      " [1.995466]\n",
      " [1.995466]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 3510/10000 Loss (MSE):  train=0.5163038969039917\n",
      "Epoch: 3520/10000 Loss (MSE):  train=0.5162387490272522\n",
      "Epoch: 3530/10000 Loss (MSE):  train=0.516173779964447\n",
      "Epoch: 3540/10000 Loss (MSE):  train=0.5161104202270508\n",
      "Epoch: 3550/10000 Loss (MSE):  train=0.5160475373268127\n",
      "Epoch: 3560/10000 Loss (MSE):  train=0.5159850120544434\n",
      "Epoch: 3570/10000 Loss (MSE):  train=0.5159229636192322\n",
      "Epoch: 3580/10000 Loss (MSE):  train=0.515861988067627\n",
      "Epoch: 3590/10000 Loss (MSE):  train=0.5158011317253113\n",
      "Epoch: 3600/10000 Loss (MSE):  train=0.5157411694526672\n",
      "gammaaaaa:  [[1.0021632]\n",
      " [1.0021632]\n",
      " [1.0021632]\n",
      " [1.9959438]\n",
      " [1.9959438]\n",
      " [1.9959438]\n",
      " [1.9959438]\n",
      " [1.9959438]\n",
      " [1.9959438]\n",
      " [1.9959438]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 3610/10000 Loss (MSE):  train=0.5156819820404053\n",
      "Epoch: 3620/10000 Loss (MSE):  train=0.5156229138374329\n",
      "Epoch: 3630/10000 Loss (MSE):  train=0.5155647397041321\n",
      "Epoch: 3640/10000 Loss (MSE):  train=0.515507161617279\n",
      "Epoch: 3650/10000 Loss (MSE):  train=0.5154507160186768\n",
      "Epoch: 3660/10000 Loss (MSE):  train=0.5153945684432983\n",
      "Epoch: 3670/10000 Loss (MSE):  train=0.5153392553329468\n",
      "Epoch: 3680/10000 Loss (MSE):  train=0.5152844786643982\n",
      "Epoch: 3690/10000 Loss (MSE):  train=0.5152310132980347\n",
      "Epoch: 3700/10000 Loss (MSE):  train=0.5151776075363159\n",
      "gammaaaaa:  [[1.0021622]\n",
      " [1.0021622]\n",
      " [1.0021622]\n",
      " [1.9965432]\n",
      " [1.9965432]\n",
      " [1.9965432]\n",
      " [1.9965432]\n",
      " [1.9965432]\n",
      " [1.9965432]\n",
      " [1.9965432]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 3710/10000 Loss (MSE):  train=0.5151249766349792\n",
      "Epoch: 3720/10000 Loss (MSE):  train=0.5150735974311829\n",
      "Epoch: 3730/10000 Loss (MSE):  train=0.5150220394134521\n",
      "Epoch: 3740/10000 Loss (MSE):  train=0.5149722099304199\n",
      "Epoch: 3750/10000 Loss (MSE):  train=0.5149227380752563\n",
      "Epoch: 3760/10000 Loss (MSE):  train=0.5148740410804749\n",
      "Epoch: 3770/10000 Loss (MSE):  train=0.514825701713562\n",
      "Epoch: 3780/10000 Loss (MSE):  train=0.5147779583930969\n",
      "Epoch: 3790/10000 Loss (MSE):  train=0.5147308707237244\n",
      "Epoch: 3800/10000 Loss (MSE):  train=0.5146850347518921\n",
      "gammaaaaa:  [[1.0021636]\n",
      " [1.0021636]\n",
      " [1.0021636]\n",
      " [1.9972582]\n",
      " [1.9972582]\n",
      " [1.9972582]\n",
      " [1.9972582]\n",
      " [1.9972582]\n",
      " [1.9972582]\n",
      " [1.9972582]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 3810/10000 Loss (MSE):  train=0.5146397948265076\n",
      "Epoch: 3820/10000 Loss (MSE):  train=0.5145953893661499\n",
      "Epoch: 3830/10000 Loss (MSE):  train=0.514552116394043\n",
      "Epoch: 3840/10000 Loss (MSE):  train=0.514508843421936\n",
      "Epoch: 3850/10000 Loss (MSE):  train=0.5144670009613037\n",
      "Epoch: 3860/10000 Loss (MSE):  train=0.5144254565238953\n",
      "Epoch: 3870/10000 Loss (MSE):  train=0.5143851637840271\n",
      "Epoch: 3880/10000 Loss (MSE):  train=0.5143451690673828\n",
      "Epoch: 3890/10000 Loss (MSE):  train=0.5143060088157654\n",
      "Epoch: 3900/10000 Loss (MSE):  train=0.5142672657966614\n",
      "gammaaaaa:  [[1.0021675]\n",
      " [1.0021675]\n",
      " [1.0021675]\n",
      " [1.9980693]\n",
      " [1.9980693]\n",
      " [1.9980693]\n",
      " [1.9980693]\n",
      " [1.9980693]\n",
      " [1.9980693]\n",
      " [1.9980693]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 3910/10000 Loss (MSE):  train=0.5142294764518738\n",
      "Epoch: 3920/10000 Loss (MSE):  train=0.5141922235488892\n",
      "Epoch: 3930/10000 Loss (MSE):  train=0.514155924320221\n",
      "Epoch: 3940/10000 Loss (MSE):  train=0.5141201615333557\n",
      "Epoch: 3950/10000 Loss (MSE):  train=0.5140857100486755\n",
      "Epoch: 3960/10000 Loss (MSE):  train=0.5140515565872192\n",
      "Epoch: 3970/10000 Loss (MSE):  train=0.514018714427948\n",
      "Epoch: 3980/10000 Loss (MSE):  train=0.5139857530593872\n",
      "Epoch: 3990/10000 Loss (MSE):  train=0.5139538049697876\n",
      "Epoch: 4000/10000 Loss (MSE):  train=0.5139226913452148\n",
      "gammaaaaa:  [[1.0021719]\n",
      " [1.0021719]\n",
      " [1.0021719]\n",
      " [1.9989436]\n",
      " [1.9989436]\n",
      " [1.9989436]\n",
      " [1.9989436]\n",
      " [1.9989436]\n",
      " [1.9989434]\n",
      " [1.9989434]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 4010/10000 Loss (MSE):  train=0.5138916969299316\n",
      "Epoch: 4020/10000 Loss (MSE):  train=0.513861894607544\n",
      "Epoch: 4030/10000 Loss (MSE):  train=0.5138328075408936\n",
      "Epoch: 4040/10000 Loss (MSE):  train=0.5138040781021118\n",
      "Epoch: 4050/10000 Loss (MSE):  train=0.5137760639190674\n",
      "Epoch: 4060/10000 Loss (MSE):  train=0.5137491226196289\n",
      "Epoch: 4070/10000 Loss (MSE):  train=0.513722836971283\n",
      "Epoch: 4080/10000 Loss (MSE):  train=0.513696551322937\n",
      "Epoch: 4090/10000 Loss (MSE):  train=0.5136713981628418\n",
      "Epoch: 4100/10000 Loss (MSE):  train=0.5136467814445496\n",
      "gammaaaaa:  [[1.0021763]\n",
      " [1.0021763]\n",
      " [1.0021763]\n",
      " [1.999836 ]\n",
      " [1.999836 ]\n",
      " [1.999836 ]\n",
      " [1.999836 ]\n",
      " [1.999836 ]\n",
      " [1.999836 ]\n",
      " [1.999836 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 4110/10000 Loss (MSE):  train=0.5136224031448364\n",
      "Epoch: 4120/10000 Loss (MSE):  train=0.5135986804962158\n",
      "Epoch: 4130/10000 Loss (MSE):  train=0.5135757923126221\n",
      "Epoch: 4140/10000 Loss (MSE):  train=0.5135530829429626\n",
      "Epoch: 4150/10000 Loss (MSE):  train=0.5135313272476196\n",
      "Epoch: 4160/10000 Loss (MSE):  train=0.5135104656219482\n",
      "Epoch: 4170/10000 Loss (MSE):  train=0.5134894847869873\n",
      "Epoch: 4180/10000 Loss (MSE):  train=0.5134692788124084\n",
      "Epoch: 4190/10000 Loss (MSE):  train=0.5134499073028564\n",
      "Epoch: 4200/10000 Loss (MSE):  train=0.5134305953979492\n",
      "gammaaaaa:  [[1.0021777]\n",
      " [1.0021777]\n",
      " [1.0021777]\n",
      " [2.0006962]\n",
      " [2.0006962]\n",
      " [2.0006962]\n",
      " [2.0006962]\n",
      " [2.0006962]\n",
      " [2.0006962]\n",
      " [2.0006962]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 4210/10000 Loss (MSE):  train=0.5134118795394897\n",
      "Epoch: 4220/10000 Loss (MSE):  train=0.5133931040763855\n",
      "Epoch: 4230/10000 Loss (MSE):  train=0.5133759379386902\n",
      "Epoch: 4240/10000 Loss (MSE):  train=0.5133579969406128\n",
      "Epoch: 4250/10000 Loss (MSE):  train=0.5133413076400757\n",
      "Epoch: 4260/10000 Loss (MSE):  train=0.5133247971534729\n",
      "Epoch: 4270/10000 Loss (MSE):  train=0.5133084058761597\n",
      "Epoch: 4280/10000 Loss (MSE):  train=0.5132932066917419\n",
      "Epoch: 4290/10000 Loss (MSE):  train=0.5132778286933899\n",
      "Epoch: 4300/10000 Loss (MSE):  train=0.5132629871368408\n",
      "gammaaaaa:  [[1.0021764]\n",
      " [1.0021764]\n",
      " [1.0021764]\n",
      " [2.0014818]\n",
      " [2.0014818]\n",
      " [2.0014818]\n",
      " [2.0014818]\n",
      " [2.0014818]\n",
      " [2.0014815]\n",
      " [2.0014815]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 4310/10000 Loss (MSE):  train=0.5132483839988708\n",
      "Epoch: 4320/10000 Loss (MSE):  train=0.5132342576980591\n",
      "Epoch: 4330/10000 Loss (MSE):  train=0.5132201313972473\n",
      "Epoch: 4340/10000 Loss (MSE):  train=0.513206422328949\n",
      "Epoch: 4350/10000 Loss (MSE):  train=0.5131932497024536\n",
      "Epoch: 4360/10000 Loss (MSE):  train=0.5131804943084717\n",
      "Epoch: 4370/10000 Loss (MSE):  train=0.5131672620773315\n",
      "Epoch: 4380/10000 Loss (MSE):  train=0.5131552815437317\n",
      "Epoch: 4390/10000 Loss (MSE):  train=0.5131439566612244\n",
      "Epoch: 4400/10000 Loss (MSE):  train=0.5131312608718872\n",
      "gammaaaaa:  [[1.0021743]\n",
      " [1.0021743]\n",
      " [1.0021743]\n",
      " [2.0021605]\n",
      " [2.0021605]\n",
      " [2.0021605]\n",
      " [2.0021605]\n",
      " [2.0021605]\n",
      " [2.0021605]\n",
      " [2.0021605]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 4410/10000 Loss (MSE):  train=0.5131195187568665\n",
      "Epoch: 4420/10000 Loss (MSE):  train=0.5131081342697144\n",
      "Epoch: 4430/10000 Loss (MSE):  train=0.5130975246429443\n",
      "Epoch: 4440/10000 Loss (MSE):  train=0.5130870342254639\n",
      "Epoch: 4450/10000 Loss (MSE):  train=0.5130759477615356\n",
      "Epoch: 4460/10000 Loss (MSE):  train=0.5130659937858582\n",
      "Epoch: 4470/10000 Loss (MSE):  train=0.5130558013916016\n",
      "Epoch: 4480/10000 Loss (MSE):  train=0.5130460262298584\n",
      "Epoch: 4490/10000 Loss (MSE):  train=0.5130361318588257\n",
      "Epoch: 4500/10000 Loss (MSE):  train=0.5130263566970825\n",
      "gammaaaaa:  [[1.0021701]\n",
      " [1.0021701]\n",
      " [1.0021701]\n",
      " [2.0027225]\n",
      " [2.0027225]\n",
      " [2.0027225]\n",
      " [2.0027225]\n",
      " [2.0027225]\n",
      " [2.0027225]\n",
      " [2.0027225]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 4510/10000 Loss (MSE):  train=0.5130165219306946\n",
      "Epoch: 4520/10000 Loss (MSE):  train=0.5130071640014648\n",
      "Epoch: 4530/10000 Loss (MSE):  train=0.5129982233047485\n",
      "Epoch: 4540/10000 Loss (MSE):  train=0.5129891633987427\n",
      "Epoch: 4550/10000 Loss (MSE):  train=0.5129802227020264\n",
      "Epoch: 4560/10000 Loss (MSE):  train=0.5129712820053101\n",
      "Epoch: 4570/10000 Loss (MSE):  train=0.5129626989364624\n",
      "Epoch: 4580/10000 Loss (MSE):  train=0.5129543542861938\n",
      "Epoch: 4590/10000 Loss (MSE):  train=0.5129461884498596\n",
      "Epoch: 4600/10000 Loss (MSE):  train=0.5129375457763672\n",
      "gammaaaaa:  [[1.0021665]\n",
      " [1.0021665]\n",
      " [1.0021665]\n",
      " [2.003168 ]\n",
      " [2.003168 ]\n",
      " [2.003168 ]\n",
      " [2.003168 ]\n",
      " [2.003168 ]\n",
      " [2.003168 ]\n",
      " [2.003168 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 4610/10000 Loss (MSE):  train=0.5129302144050598\n",
      "Epoch: 4620/10000 Loss (MSE):  train=0.5129218697547913\n",
      "Epoch: 4630/10000 Loss (MSE):  train=0.5129142999649048\n",
      "Epoch: 4640/10000 Loss (MSE):  train=0.5129059553146362\n",
      "Epoch: 4650/10000 Loss (MSE):  train=0.5128987431526184\n",
      "Epoch: 4660/10000 Loss (MSE):  train=0.5128911733627319\n",
      "Epoch: 4670/10000 Loss (MSE):  train=0.5128838419914246\n",
      "Epoch: 4680/10000 Loss (MSE):  train=0.5128766298294067\n",
      "Epoch: 4690/10000 Loss (MSE):  train=0.5128690004348755\n",
      "Epoch: 4700/10000 Loss (MSE):  train=0.5128620862960815\n",
      "gammaaaaa:  [[1.0021641]\n",
      " [1.0021641]\n",
      " [1.0021641]\n",
      " [2.003511 ]\n",
      " [2.003511 ]\n",
      " [2.003511 ]\n",
      " [2.003511 ]\n",
      " [2.003511 ]\n",
      " [2.003511 ]\n",
      " [2.003511 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 4710/10000 Loss (MSE):  train=0.5128549933433533\n",
      "Epoch: 4720/10000 Loss (MSE):  train=0.5128479599952698\n",
      "Epoch: 4730/10000 Loss (MSE):  train=0.5128410458564758\n",
      "Epoch: 4740/10000 Loss (MSE):  train=0.5128340721130371\n",
      "Epoch: 4750/10000 Loss (MSE):  train=0.5128275752067566\n",
      "Epoch: 4760/10000 Loss (MSE):  train=0.5128205418586731\n",
      "Epoch: 4770/10000 Loss (MSE):  train=0.5128133893013\n",
      "Epoch: 4780/10000 Loss (MSE):  train=0.5128070116043091\n",
      "Epoch: 4790/10000 Loss (MSE):  train=0.5128008127212524\n",
      "Epoch: 4800/10000 Loss (MSE):  train=0.5127943754196167\n",
      "gammaaaaa:  [[1.0021646]\n",
      " [1.0021646]\n",
      " [1.0021646]\n",
      " [2.0037694]\n",
      " [2.0037694]\n",
      " [2.0037694]\n",
      " [2.0037694]\n",
      " [2.0037694]\n",
      " [2.0037694]\n",
      " [2.0037694]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 4810/10000 Loss (MSE):  train=0.5127873420715332\n",
      "Epoch: 4820/10000 Loss (MSE):  train=0.5127814412117004\n",
      "Epoch: 4830/10000 Loss (MSE):  train=0.512775182723999\n",
      "Epoch: 4840/10000 Loss (MSE):  train=0.5127686858177185\n",
      "Epoch: 4850/10000 Loss (MSE):  train=0.5127620100975037\n",
      "Epoch: 4860/10000 Loss (MSE):  train=0.5127558708190918\n",
      "Epoch: 4870/10000 Loss (MSE):  train=0.5127498507499695\n",
      "Epoch: 4880/10000 Loss (MSE):  train=0.5127436518669128\n",
      "Epoch: 4890/10000 Loss (MSE):  train=0.5127378702163696\n",
      "Epoch: 4900/10000 Loss (MSE):  train=0.5127315521240234\n",
      "gammaaaaa:  [[1.0021679]\n",
      " [1.0021679]\n",
      " [1.0021679]\n",
      " [2.0039637]\n",
      " [2.0039637]\n",
      " [2.0039637]\n",
      " [2.0039637]\n",
      " [2.0039637]\n",
      " [2.0039637]\n",
      " [2.0039637]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 4910/10000 Loss (MSE):  train=0.5127261281013489\n",
      "Epoch: 4920/10000 Loss (MSE):  train=0.5127204656600952\n",
      "Epoch: 4930/10000 Loss (MSE):  train=0.5127143859863281\n",
      "Epoch: 4940/10000 Loss (MSE):  train=0.512708842754364\n",
      "Epoch: 4950/10000 Loss (MSE):  train=0.5127030611038208\n",
      "Epoch: 4960/10000 Loss (MSE):  train=0.5126974582672119\n",
      "Epoch: 4970/10000 Loss (MSE):  train=0.5126916766166687\n",
      "Epoch: 4980/10000 Loss (MSE):  train=0.5126857757568359\n",
      "Epoch: 4990/10000 Loss (MSE):  train=0.5126801133155823\n",
      "Epoch: 5000/10000 Loss (MSE):  train=0.5126745104789734\n",
      "gammaaaaa:  [[1.0021752]\n",
      " [1.0021752]\n",
      " [1.0021752]\n",
      " [2.0041106]\n",
      " [2.0041106]\n",
      " [2.0041106]\n",
      " [2.0041106]\n",
      " [2.0041106]\n",
      " [2.0041103]\n",
      " [2.0041103]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 5010/10000 Loss (MSE):  train=0.5126691460609436\n",
      "Epoch: 5020/10000 Loss (MSE):  train=0.5126635432243347\n",
      "Epoch: 5030/10000 Loss (MSE):  train=0.5126581788063049\n",
      "Epoch: 5040/10000 Loss (MSE):  train=0.512652575969696\n",
      "Epoch: 5050/10000 Loss (MSE):  train=0.5126474499702454\n",
      "Epoch: 5060/10000 Loss (MSE):  train=0.5126420259475708\n",
      "Epoch: 5070/10000 Loss (MSE):  train=0.5126368999481201\n",
      "Epoch: 5080/10000 Loss (MSE):  train=0.5126320123672485\n",
      "Epoch: 5090/10000 Loss (MSE):  train=0.5126264691352844\n",
      "Epoch: 5100/10000 Loss (MSE):  train=0.5126210451126099\n",
      "gammaaaaa:  [[1.0021838]\n",
      " [1.0021838]\n",
      " [1.0021838]\n",
      " [2.0042238]\n",
      " [2.0042238]\n",
      " [2.0042238]\n",
      " [2.0042238]\n",
      " [2.0042238]\n",
      " [2.0042238]\n",
      " [2.0042238]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 5110/10000 Loss (MSE):  train=0.5126160383224487\n",
      "Epoch: 5120/10000 Loss (MSE):  train=0.5126108527183533\n",
      "Epoch: 5130/10000 Loss (MSE):  train=0.5126058459281921\n",
      "Epoch: 5140/10000 Loss (MSE):  train=0.5126007199287415\n",
      "Epoch: 5150/10000 Loss (MSE):  train=0.5125955939292908\n",
      "Epoch: 5160/10000 Loss (MSE):  train=0.5125902891159058\n",
      "Epoch: 5170/10000 Loss (MSE):  train=0.5125853419303894\n",
      "Epoch: 5180/10000 Loss (MSE):  train=0.5125802755355835\n",
      "Epoch: 5190/10000 Loss (MSE):  train=0.5125758051872253\n",
      "Epoch: 5200/10000 Loss (MSE):  train=0.5125710964202881\n",
      "gammaaaaa:  [[1.0021964]\n",
      " [1.0021964]\n",
      " [1.0021964]\n",
      " [2.004312 ]\n",
      " [2.004312 ]\n",
      " [2.004312 ]\n",
      " [2.004312 ]\n",
      " [2.004312 ]\n",
      " [2.004312 ]\n",
      " [2.004312 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 5210/10000 Loss (MSE):  train=0.512566328048706\n",
      "Epoch: 5220/10000 Loss (MSE):  train=0.512561023235321\n",
      "Epoch: 5230/10000 Loss (MSE):  train=0.5125563740730286\n",
      "Epoch: 5240/10000 Loss (MSE):  train=0.5125521421432495\n",
      "Epoch: 5250/10000 Loss (MSE):  train=0.5125468373298645\n",
      "Epoch: 5260/10000 Loss (MSE):  train=0.512542188167572\n",
      "Epoch: 5270/10000 Loss (MSE):  train=0.5125374794006348\n",
      "Epoch: 5280/10000 Loss (MSE):  train=0.5125327110290527\n",
      "Epoch: 5290/10000 Loss (MSE):  train=0.5125283002853394\n",
      "Epoch: 5300/10000 Loss (MSE):  train=0.5125236511230469\n",
      "gammaaaaa:  [[1.0022117]\n",
      " [1.0022117]\n",
      " [1.0022117]\n",
      " [2.0043845]\n",
      " [2.0043845]\n",
      " [2.0043845]\n",
      " [2.0043845]\n",
      " [2.0043845]\n",
      " [2.0043845]\n",
      " [2.0043845]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 5310/10000 Loss (MSE):  train=0.5125194787979126\n",
      "Epoch: 5320/10000 Loss (MSE):  train=0.5125145316123962\n",
      "Epoch: 5330/10000 Loss (MSE):  train=0.5125098824501038\n",
      "Epoch: 5340/10000 Loss (MSE):  train=0.5125054121017456\n",
      "Epoch: 5350/10000 Loss (MSE):  train=0.5125008821487427\n",
      "Epoch: 5360/10000 Loss (MSE):  train=0.5124964118003845\n",
      "Epoch: 5370/10000 Loss (MSE):  train=0.5124922394752502\n",
      "Epoch: 5380/10000 Loss (MSE):  train=0.5124872922897339\n",
      "Epoch: 5390/10000 Loss (MSE):  train=0.5124830603599548\n",
      "Epoch: 5400/10000 Loss (MSE):  train=0.5124785304069519\n",
      "gammaaaaa:  [[1.0022297]\n",
      " [1.0022297]\n",
      " [1.0022297]\n",
      " [2.0044434]\n",
      " [2.0044434]\n",
      " [2.0044434]\n",
      " [2.0044434]\n",
      " [2.0044434]\n",
      " [2.0044434]\n",
      " [2.0044434]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 5410/10000 Loss (MSE):  train=0.5124742984771729\n",
      "Epoch: 5420/10000 Loss (MSE):  train=0.5124695301055908\n",
      "Epoch: 5430/10000 Loss (MSE):  train=0.5124656558036804\n",
      "Epoch: 5440/10000 Loss (MSE):  train=0.5124614834785461\n",
      "Epoch: 5450/10000 Loss (MSE):  train=0.5124566555023193\n",
      "Epoch: 5460/10000 Loss (MSE):  train=0.5124527215957642\n",
      "Epoch: 5470/10000 Loss (MSE):  train=0.512448787689209\n",
      "Epoch: 5480/10000 Loss (MSE):  train=0.5124443769454956\n",
      "Epoch: 5490/10000 Loss (MSE):  train=0.5124400854110718\n",
      "Epoch: 5500/10000 Loss (MSE):  train=0.5124359130859375\n",
      "gammaaaaa:  [[1.0022496]\n",
      " [1.0022496]\n",
      " [1.0022496]\n",
      " [2.0044966]\n",
      " [2.0044966]\n",
      " [2.0044966]\n",
      " [2.0044966]\n",
      " [2.0044966]\n",
      " [2.0044966]\n",
      " [2.0044966]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 5510/10000 Loss (MSE):  train=0.5124316215515137\n",
      "Epoch: 5520/10000 Loss (MSE):  train=0.5124276876449585\n",
      "Epoch: 5530/10000 Loss (MSE):  train=0.5124233961105347\n",
      "Epoch: 5540/10000 Loss (MSE):  train=0.5124197602272034\n",
      "Epoch: 5550/10000 Loss (MSE):  train=0.5124155282974243\n",
      "Epoch: 5560/10000 Loss (MSE):  train=0.5124112963676453\n",
      "Epoch: 5570/10000 Loss (MSE):  train=0.5124070644378662\n",
      "Epoch: 5580/10000 Loss (MSE):  train=0.512403130531311\n",
      "Epoch: 5590/10000 Loss (MSE):  train=0.5123986005783081\n",
      "Epoch: 5600/10000 Loss (MSE):  train=0.5123948454856873\n",
      "gammaaaaa:  [[1.002271 ]\n",
      " [1.002271 ]\n",
      " [1.002271 ]\n",
      " [2.0045426]\n",
      " [2.0045426]\n",
      " [2.0045426]\n",
      " [2.0045426]\n",
      " [2.0045426]\n",
      " [2.0045428]\n",
      " [2.0045428]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 5610/10000 Loss (MSE):  train=0.512391209602356\n",
      "Epoch: 5620/10000 Loss (MSE):  train=0.5123871564865112\n",
      "Epoch: 5630/10000 Loss (MSE):  train=0.512382984161377\n",
      "Epoch: 5640/10000 Loss (MSE):  train=0.5123792886734009\n",
      "Epoch: 5650/10000 Loss (MSE):  train=0.5123751759529114\n",
      "Epoch: 5660/10000 Loss (MSE):  train=0.5123715400695801\n",
      "Epoch: 5670/10000 Loss (MSE):  train=0.5123674869537354\n",
      "Epoch: 5680/10000 Loss (MSE):  train=0.512363851070404\n",
      "Epoch: 5690/10000 Loss (MSE):  train=0.5123600959777832\n",
      "Epoch: 5700/10000 Loss (MSE):  train=0.512356162071228\n",
      "gammaaaaa:  [[1.0022941]\n",
      " [1.0022941]\n",
      " [1.0022941]\n",
      " [2.0045843]\n",
      " [2.0045843]\n",
      " [2.0045843]\n",
      " [2.0045843]\n",
      " [2.0045843]\n",
      " [2.0045843]\n",
      " [2.0045843]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 5710/10000 Loss (MSE):  train=0.5123516321182251\n",
      "Epoch: 5720/10000 Loss (MSE):  train=0.5123480558395386\n",
      "Epoch: 5730/10000 Loss (MSE):  train=0.5123443007469177\n",
      "Epoch: 5740/10000 Loss (MSE):  train=0.5123403072357178\n",
      "Epoch: 5750/10000 Loss (MSE):  train=0.5123370885848999\n",
      "Epoch: 5760/10000 Loss (MSE):  train=0.5123329162597656\n",
      "Epoch: 5770/10000 Loss (MSE):  train=0.5123295187950134\n",
      "Epoch: 5780/10000 Loss (MSE):  train=0.5123259425163269\n",
      "Epoch: 5790/10000 Loss (MSE):  train=0.5123218894004822\n",
      "Epoch: 5800/10000 Loss (MSE):  train=0.5123181343078613\n",
      "gammaaaaa:  [[1.0023179]\n",
      " [1.0023179]\n",
      " [1.0023179]\n",
      " [2.0046244]\n",
      " [2.0046244]\n",
      " [2.0046244]\n",
      " [2.0046244]\n",
      " [2.0046244]\n",
      " [2.0046244]\n",
      " [2.0046244]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 5810/10000 Loss (MSE):  train=0.51231449842453\n",
      "Epoch: 5820/10000 Loss (MSE):  train=0.5123110413551331\n",
      "Epoch: 5830/10000 Loss (MSE):  train=0.5123068690299988\n",
      "Epoch: 5840/10000 Loss (MSE):  train=0.5123030543327332\n",
      "Epoch: 5850/10000 Loss (MSE):  train=0.5122995972633362\n",
      "Epoch: 5860/10000 Loss (MSE):  train=0.5122964382171631\n",
      "Epoch: 5870/10000 Loss (MSE):  train=0.5122925043106079\n",
      "Epoch: 5880/10000 Loss (MSE):  train=0.5122891068458557\n",
      "Epoch: 5890/10000 Loss (MSE):  train=0.5122855305671692\n",
      "Epoch: 5900/10000 Loss (MSE):  train=0.5122817158699036\n",
      "gammaaaaa:  [[1.0023419]\n",
      " [1.0023419]\n",
      " [1.0023419]\n",
      " [2.0046644]\n",
      " [2.0046644]\n",
      " [2.0046644]\n",
      " [2.0046644]\n",
      " [2.0046644]\n",
      " [2.0046647]\n",
      " [2.0046647]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 5910/10000 Loss (MSE):  train=0.5122785568237305\n",
      "Epoch: 5920/10000 Loss (MSE):  train=0.5122746229171753\n",
      "Epoch: 5930/10000 Loss (MSE):  train=0.5122714638710022\n",
      "Epoch: 5940/10000 Loss (MSE):  train=0.5122679471969604\n",
      "Epoch: 5950/10000 Loss (MSE):  train=0.5122643709182739\n",
      "Epoch: 5960/10000 Loss (MSE):  train=0.5122608542442322\n",
      "Epoch: 5970/10000 Loss (MSE):  train=0.5122572183609009\n",
      "Epoch: 5980/10000 Loss (MSE):  train=0.5122538208961487\n",
      "Epoch: 5990/10000 Loss (MSE):  train=0.5122504234313965\n",
      "Epoch: 6000/10000 Loss (MSE):  train=0.5122474431991577\n",
      "gammaaaaa:  [[1.0023654]\n",
      " [1.0023654]\n",
      " [1.0023654]\n",
      " [2.0047026]\n",
      " [2.0047026]\n",
      " [2.0047026]\n",
      " [2.0047026]\n",
      " [2.0047026]\n",
      " [2.0047026]\n",
      " [2.0047026]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 6010/10000 Loss (MSE):  train=0.512243390083313\n",
      "Epoch: 6020/10000 Loss (MSE):  train=0.512240469455719\n",
      "Epoch: 6030/10000 Loss (MSE):  train=0.5122368335723877\n",
      "Epoch: 6040/10000 Loss (MSE):  train=0.512233316898346\n",
      "Epoch: 6050/10000 Loss (MSE):  train=0.5122299790382385\n",
      "Epoch: 6060/10000 Loss (MSE):  train=0.5122268199920654\n",
      "Epoch: 6070/10000 Loss (MSE):  train=0.5122233629226685\n",
      "Epoch: 6080/10000 Loss (MSE):  train=0.5122205018997192\n",
      "Epoch: 6090/10000 Loss (MSE):  train=0.5122169256210327\n",
      "Epoch: 6100/10000 Loss (MSE):  train=0.5122133493423462\n",
      "gammaaaaa:  [[1.0023892]\n",
      " [1.0023892]\n",
      " [1.0023892]\n",
      " [2.0047407]\n",
      " [2.0047407]\n",
      " [2.0047407]\n",
      " [2.0047407]\n",
      " [2.0047407]\n",
      " [2.0047407]\n",
      " [2.0047407]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 6110/10000 Loss (MSE):  train=0.5122098922729492\n",
      "Epoch: 6120/10000 Loss (MSE):  train=0.5122069120407104\n",
      "Epoch: 6130/10000 Loss (MSE):  train=0.5122035145759583\n",
      "Epoch: 6140/10000 Loss (MSE):  train=0.5121999382972717\n",
      "Epoch: 6150/10000 Loss (MSE):  train=0.5121966600418091\n",
      "Epoch: 6160/10000 Loss (MSE):  train=0.5121933817863464\n",
      "Epoch: 6170/10000 Loss (MSE):  train=0.512190043926239\n",
      "Epoch: 6180/10000 Loss (MSE):  train=0.5121868252754211\n",
      "Epoch: 6190/10000 Loss (MSE):  train=0.5121839046478271\n",
      "Epoch: 6200/10000 Loss (MSE):  train=0.5121804475784302\n",
      "gammaaaaa:  [[1.0024124]\n",
      " [1.0024124]\n",
      " [1.0024124]\n",
      " [2.0047789]\n",
      " [2.0047789]\n",
      " [2.0047789]\n",
      " [2.0047789]\n",
      " [2.0047789]\n",
      " [2.0047789]\n",
      " [2.0047789]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 6210/10000 Loss (MSE):  train=0.5121773481369019\n",
      "Epoch: 6220/10000 Loss (MSE):  train=0.512174129486084\n",
      "Epoch: 6230/10000 Loss (MSE):  train=0.5121710300445557\n",
      "Epoch: 6240/10000 Loss (MSE):  train=0.5121680498123169\n",
      "Epoch: 6250/10000 Loss (MSE):  train=0.5121644139289856\n",
      "Epoch: 6260/10000 Loss (MSE):  train=0.5121612548828125\n",
      "Epoch: 6270/10000 Loss (MSE):  train=0.5121580362319946\n",
      "Epoch: 6280/10000 Loss (MSE):  train=0.5121546983718872\n",
      "Epoch: 6290/10000 Loss (MSE):  train=0.5121514797210693\n",
      "Epoch: 6300/10000 Loss (MSE):  train=0.5121484994888306\n",
      "gammaaaaa:  [[1.0024358]\n",
      " [1.0024358]\n",
      " [1.0024358]\n",
      " [2.004817 ]\n",
      " [2.004817 ]\n",
      " [2.004817 ]\n",
      " [2.004817 ]\n",
      " [2.004817 ]\n",
      " [2.004817 ]\n",
      " [2.004817 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 6310/10000 Loss (MSE):  train=0.5121451616287231\n",
      "Epoch: 6320/10000 Loss (MSE):  train=0.5121429562568665\n",
      "Epoch: 6330/10000 Loss (MSE):  train=0.512139618396759\n",
      "Epoch: 6340/10000 Loss (MSE):  train=0.512136697769165\n",
      "Epoch: 6350/10000 Loss (MSE):  train=0.5121337175369263\n",
      "Epoch: 6360/10000 Loss (MSE):  train=0.512130618095398\n",
      "Epoch: 6370/10000 Loss (MSE):  train=0.5121272206306458\n",
      "Epoch: 6380/10000 Loss (MSE):  train=0.5121240019798279\n",
      "Epoch: 6390/10000 Loss (MSE):  train=0.5121207237243652\n",
      "Epoch: 6400/10000 Loss (MSE):  train=0.5121176242828369\n",
      "gammaaaaa:  [[1.0024586]\n",
      " [1.0024586]\n",
      " [1.0024586]\n",
      " [2.004855 ]\n",
      " [2.004855 ]\n",
      " [2.004855 ]\n",
      " [2.004855 ]\n",
      " [2.004855 ]\n",
      " [2.004855 ]\n",
      " [2.004855 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 6410/10000 Loss (MSE):  train=0.5121148824691772\n",
      "Epoch: 6420/10000 Loss (MSE):  train=0.5121114253997803\n",
      "Epoch: 6430/10000 Loss (MSE):  train=0.5121084451675415\n",
      "Epoch: 6440/10000 Loss (MSE):  train=0.5121053457260132\n",
      "Epoch: 6450/10000 Loss (MSE):  train=0.5121025443077087\n",
      "Epoch: 6460/10000 Loss (MSE):  train=0.5120993852615356\n",
      "Epoch: 6470/10000 Loss (MSE):  train=0.5120964646339417\n",
      "Epoch: 6480/10000 Loss (MSE):  train=0.5120933055877686\n",
      "Epoch: 6490/10000 Loss (MSE):  train=0.5120906233787537\n",
      "Epoch: 6500/10000 Loss (MSE):  train=0.5120875835418701\n",
      "gammaaaaa:  [[1.0024812]\n",
      " [1.0024812]\n",
      " [1.0024812]\n",
      " [2.0048933]\n",
      " [2.0048933]\n",
      " [2.0048933]\n",
      " [2.0048933]\n",
      " [2.0048933]\n",
      " [2.0048933]\n",
      " [2.0048933]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 6510/10000 Loss (MSE):  train=0.5120843648910522\n",
      "Epoch: 6520/10000 Loss (MSE):  train=0.5120816230773926\n",
      "Epoch: 6530/10000 Loss (MSE):  train=0.5120786428451538\n",
      "Epoch: 6540/10000 Loss (MSE):  train=0.5120755434036255\n",
      "Epoch: 6550/10000 Loss (MSE):  train=0.5120725035667419\n",
      "Epoch: 6560/10000 Loss (MSE):  train=0.512069582939148\n",
      "Epoch: 6570/10000 Loss (MSE):  train=0.512066662311554\n",
      "Epoch: 6580/10000 Loss (MSE):  train=0.5120636820793152\n",
      "Epoch: 6590/10000 Loss (MSE):  train=0.5120607614517212\n",
      "Epoch: 6600/10000 Loss (MSE):  train=0.5120578408241272\n",
      "gammaaaaa:  [[1.0025033]\n",
      " [1.0025033]\n",
      " [1.0025033]\n",
      " [2.0049312]\n",
      " [2.0049312]\n",
      " [2.0049312]\n",
      " [2.0049312]\n",
      " [2.0049312]\n",
      " [2.0049312]\n",
      " [2.0049312]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 6610/10000 Loss (MSE):  train=0.5120547413825989\n",
      "Epoch: 6620/10000 Loss (MSE):  train=0.5120521187782288\n",
      "Epoch: 6630/10000 Loss (MSE):  train=0.5120494365692139\n",
      "Epoch: 6640/10000 Loss (MSE):  train=0.5120462775230408\n",
      "Epoch: 6650/10000 Loss (MSE):  train=0.5120432376861572\n",
      "Epoch: 6660/10000 Loss (MSE):  train=0.5120404362678528\n",
      "Epoch: 6670/10000 Loss (MSE):  train=0.5120375752449036\n",
      "Epoch: 6680/10000 Loss (MSE):  train=0.5120347738265991\n",
      "Epoch: 6690/10000 Loss (MSE):  train=0.5120319724082947\n",
      "Epoch: 6700/10000 Loss (MSE):  train=0.5120291709899902\n",
      "gammaaaaa:  [[1.0025246]\n",
      " [1.0025246]\n",
      " [1.0025246]\n",
      " [2.0049715]\n",
      " [2.0049715]\n",
      " [2.0049715]\n",
      " [2.0049715]\n",
      " [2.0049715]\n",
      " [2.0049715]\n",
      " [2.0049715]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 6710/10000 Loss (MSE):  train=0.5120258331298828\n",
      "Epoch: 6720/10000 Loss (MSE):  train=0.5120230317115784\n",
      "Epoch: 6730/10000 Loss (MSE):  train=0.5120202898979187\n",
      "Epoch: 6740/10000 Loss (MSE):  train=0.5120173692703247\n",
      "Epoch: 6750/10000 Loss (MSE):  train=0.5120145082473755\n",
      "Epoch: 6760/10000 Loss (MSE):  train=0.5120112895965576\n",
      "Epoch: 6770/10000 Loss (MSE):  train=0.512008547782898\n",
      "Epoch: 6780/10000 Loss (MSE):  train=0.5120055675506592\n",
      "Epoch: 6790/10000 Loss (MSE):  train=0.5120030045509338\n",
      "Epoch: 6800/10000 Loss (MSE):  train=0.5120002031326294\n",
      "gammaaaaa:  [[1.002546 ]\n",
      " [1.002546 ]\n",
      " [1.002546 ]\n",
      " [2.0050101]\n",
      " [2.0050101]\n",
      " [2.0050101]\n",
      " [2.0050101]\n",
      " [2.0050101]\n",
      " [2.0050101]\n",
      " [2.0050101]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 6810/10000 Loss (MSE):  train=0.5119975209236145\n",
      "Epoch: 6820/10000 Loss (MSE):  train=0.5119947791099548\n",
      "Epoch: 6830/10000 Loss (MSE):  train=0.5119917988777161\n",
      "Epoch: 6840/10000 Loss (MSE):  train=0.511989176273346\n",
      "Epoch: 6850/10000 Loss (MSE):  train=0.5119858980178833\n",
      "Epoch: 6860/10000 Loss (MSE):  train=0.5119832754135132\n",
      "Epoch: 6870/10000 Loss (MSE):  train=0.5119805335998535\n",
      "Epoch: 6880/10000 Loss (MSE):  train=0.5119779109954834\n",
      "Epoch: 6890/10000 Loss (MSE):  train=0.5119752883911133\n",
      "Epoch: 6900/10000 Loss (MSE):  train=0.5119726061820984\n",
      "gammaaaaa:  [[1.0025665]\n",
      " [1.0025665]\n",
      " [1.0025665]\n",
      " [2.00505  ]\n",
      " [2.00505  ]\n",
      " [2.00505  ]\n",
      " [2.00505  ]\n",
      " [2.00505  ]\n",
      " [2.00505  ]\n",
      " [2.00505  ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 6910/10000 Loss (MSE):  train=0.5119692087173462\n",
      "Epoch: 6920/10000 Loss (MSE):  train=0.5119664669036865\n",
      "Epoch: 6930/10000 Loss (MSE):  train=0.511963963508606\n",
      "Epoch: 6940/10000 Loss (MSE):  train=0.5119612216949463\n",
      "Epoch: 6950/10000 Loss (MSE):  train=0.5119585394859314\n",
      "Epoch: 6960/10000 Loss (MSE):  train=0.5119556784629822\n",
      "Epoch: 6970/10000 Loss (MSE):  train=0.5119529366493225\n",
      "Epoch: 6980/10000 Loss (MSE):  train=0.5119504928588867\n",
      "Epoch: 6990/10000 Loss (MSE):  train=0.5119479298591614\n",
      "Epoch: 7000/10000 Loss (MSE):  train=0.5119451284408569\n",
      "gammaaaaa:  [[1.0025873]\n",
      " [1.0025873]\n",
      " [1.0025873]\n",
      " [2.0050905]\n",
      " [2.0050905]\n",
      " [2.0050905]\n",
      " [2.0050905]\n",
      " [2.0050905]\n",
      " [2.0050902]\n",
      " [2.0050902]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 7010/10000 Loss (MSE):  train=0.5119425058364868\n",
      "Epoch: 7020/10000 Loss (MSE):  train=0.5119394659996033\n",
      "Epoch: 7030/10000 Loss (MSE):  train=0.511936366558075\n",
      "Epoch: 7040/10000 Loss (MSE):  train=0.5119339227676392\n",
      "Epoch: 7050/10000 Loss (MSE):  train=0.5119313597679138\n",
      "Epoch: 7060/10000 Loss (MSE):  train=0.5119284987449646\n",
      "Epoch: 7070/10000 Loss (MSE):  train=0.5119256973266602\n",
      "Epoch: 7080/10000 Loss (MSE):  train=0.5119228959083557\n",
      "Epoch: 7090/10000 Loss (MSE):  train=0.5119204521179199\n",
      "Epoch: 7100/10000 Loss (MSE):  train=0.5119180679321289\n",
      "gammaaaaa:  [[1.0026078]\n",
      " [1.0026078]\n",
      " [1.0026078]\n",
      " [2.0051305]\n",
      " [2.0051305]\n",
      " [2.0051305]\n",
      " [2.0051305]\n",
      " [2.0051305]\n",
      " [2.0051305]\n",
      " [2.0051305]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 7110/10000 Loss (MSE):  train=0.5119151473045349\n",
      "Epoch: 7120/10000 Loss (MSE):  train=0.5119123458862305\n",
      "Epoch: 7130/10000 Loss (MSE):  train=0.5119096636772156\n",
      "Epoch: 7140/10000 Loss (MSE):  train=0.511906623840332\n",
      "Epoch: 7150/10000 Loss (MSE):  train=0.5119041204452515\n",
      "Epoch: 7160/10000 Loss (MSE):  train=0.5119012594223022\n",
      "Epoch: 7170/10000 Loss (MSE):  train=0.5118988752365112\n",
      "Epoch: 7180/10000 Loss (MSE):  train=0.5118963122367859\n",
      "Epoch: 7190/10000 Loss (MSE):  train=0.5118937492370605\n",
      "Epoch: 7200/10000 Loss (MSE):  train=0.5118908286094666\n",
      "gammaaaaa:  [[1.0026287]\n",
      " [1.0026287]\n",
      " [1.0026287]\n",
      " [2.0051703]\n",
      " [2.0051703]\n",
      " [2.0051703]\n",
      " [2.0051703]\n",
      " [2.0051703]\n",
      " [2.0051703]\n",
      " [2.0051703]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 7210/10000 Loss (MSE):  train=0.5118886232376099\n",
      "Epoch: 7220/10000 Loss (MSE):  train=0.5118860006332397\n",
      "Epoch: 7230/10000 Loss (MSE):  train=0.5118831992149353\n",
      "Epoch: 7240/10000 Loss (MSE):  train=0.5118802785873413\n",
      "Epoch: 7250/10000 Loss (MSE):  train=0.5118780136108398\n",
      "Epoch: 7260/10000 Loss (MSE):  train=0.5118751525878906\n",
      "Epoch: 7270/10000 Loss (MSE):  train=0.5118727087974548\n",
      "Epoch: 7280/10000 Loss (MSE):  train=0.5118700861930847\n",
      "Epoch: 7290/10000 Loss (MSE):  train=0.5118675827980042\n",
      "Epoch: 7300/10000 Loss (MSE):  train=0.5118647813796997\n",
      "gammaaaaa:  [[1.0026484]\n",
      " [1.0026484]\n",
      " [1.0026484]\n",
      " [2.0052123]\n",
      " [2.0052123]\n",
      " [2.0052123]\n",
      " [2.0052123]\n",
      " [2.0052123]\n",
      " [2.0052123]\n",
      " [2.0052123]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 7310/10000 Loss (MSE):  train=0.5118622779846191\n",
      "Epoch: 7320/10000 Loss (MSE):  train=0.5118595957756042\n",
      "Epoch: 7330/10000 Loss (MSE):  train=0.5118568539619446\n",
      "Epoch: 7340/10000 Loss (MSE):  train=0.5118546485900879\n",
      "Epoch: 7350/10000 Loss (MSE):  train=0.5118520259857178\n",
      "Epoch: 7360/10000 Loss (MSE):  train=0.5118492841720581\n",
      "Epoch: 7370/10000 Loss (MSE):  train=0.5118470191955566\n",
      "Epoch: 7380/10000 Loss (MSE):  train=0.5118442177772522\n",
      "Epoch: 7390/10000 Loss (MSE):  train=0.5118416547775269\n",
      "Epoch: 7400/10000 Loss (MSE):  train=0.5118389129638672\n",
      "gammaaaaa:  [[1.0026687]\n",
      " [1.0026687]\n",
      " [1.0026687]\n",
      " [2.005253 ]\n",
      " [2.005253 ]\n",
      " [2.005253 ]\n",
      " [2.005253 ]\n",
      " [2.005253 ]\n",
      " [2.005253 ]\n",
      " [2.005253 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 7410/10000 Loss (MSE):  train=0.5118362903594971\n",
      "Epoch: 7420/10000 Loss (MSE):  train=0.5118339657783508\n",
      "Epoch: 7430/10000 Loss (MSE):  train=0.5118316411972046\n",
      "Epoch: 7440/10000 Loss (MSE):  train=0.511829137802124\n",
      "Epoch: 7450/10000 Loss (MSE):  train=0.5118262767791748\n",
      "Epoch: 7460/10000 Loss (MSE):  train=0.5118238925933838\n",
      "Epoch: 7470/10000 Loss (MSE):  train=0.5118215084075928\n",
      "Epoch: 7480/10000 Loss (MSE):  train=0.5118191242218018\n",
      "Epoch: 7490/10000 Loss (MSE):  train=0.5118162035942078\n",
      "Epoch: 7500/10000 Loss (MSE):  train=0.5118136405944824\n",
      "gammaaaaa:  [[1.0026885]\n",
      " [1.0026885]\n",
      " [1.0026885]\n",
      " [2.005295 ]\n",
      " [2.005295 ]\n",
      " [2.005295 ]\n",
      " [2.005295 ]\n",
      " [2.005295 ]\n",
      " [2.0052953]\n",
      " [2.0052953]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 7510/10000 Loss (MSE):  train=0.5118110775947571\n",
      "Epoch: 7520/10000 Loss (MSE):  train=0.511808454990387\n",
      "Epoch: 7530/10000 Loss (MSE):  train=0.5118058919906616\n",
      "Epoch: 7540/10000 Loss (MSE):  train=0.5118036270141602\n",
      "Epoch: 7550/10000 Loss (MSE):  train=0.5118005871772766\n",
      "Epoch: 7560/10000 Loss (MSE):  train=0.5117982625961304\n",
      "Epoch: 7570/10000 Loss (MSE):  train=0.5117955803871155\n",
      "Epoch: 7580/10000 Loss (MSE):  train=0.511793315410614\n",
      "Epoch: 7590/10000 Loss (MSE):  train=0.5117908120155334\n",
      "Epoch: 7600/10000 Loss (MSE):  train=0.5117883086204529\n",
      "gammaaaaa:  [[1.0027081]\n",
      " [1.0027081]\n",
      " [1.0027081]\n",
      " [2.0053365]\n",
      " [2.0053365]\n",
      " [2.0053365]\n",
      " [2.0053365]\n",
      " [2.0053365]\n",
      " [2.0053365]\n",
      " [2.0053365]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 7610/10000 Loss (MSE):  train=0.5117858648300171\n",
      "Epoch: 7620/10000 Loss (MSE):  train=0.511783242225647\n",
      "Epoch: 7630/10000 Loss (MSE):  train=0.5117805004119873\n",
      "Epoch: 7640/10000 Loss (MSE):  train=0.5117779970169067\n",
      "Epoch: 7650/10000 Loss (MSE):  train=0.5117757320404053\n",
      "Epoch: 7660/10000 Loss (MSE):  train=0.5117733478546143\n",
      "Epoch: 7670/10000 Loss (MSE):  train=0.5117707252502441\n",
      "Epoch: 7680/10000 Loss (MSE):  train=0.511768639087677\n",
      "Epoch: 7690/10000 Loss (MSE):  train=0.5117659568786621\n",
      "Epoch: 7700/10000 Loss (MSE):  train=0.5117636919021606\n",
      "gammaaaaa:  [[1.0027286]\n",
      " [1.0027286]\n",
      " [1.0027286]\n",
      " [2.0053778]\n",
      " [2.0053778]\n",
      " [2.0053778]\n",
      " [2.0053778]\n",
      " [2.0053778]\n",
      " [2.0053778]\n",
      " [2.0053778]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 7710/10000 Loss (MSE):  train=0.5117611289024353\n",
      "Epoch: 7720/10000 Loss (MSE):  train=0.5117586255073547\n",
      "Epoch: 7730/10000 Loss (MSE):  train=0.5117560625076294\n",
      "Epoch: 7740/10000 Loss (MSE):  train=0.5117534399032593\n",
      "Epoch: 7750/10000 Loss (MSE):  train=0.5117512941360474\n",
      "Epoch: 7760/10000 Loss (MSE):  train=0.5117489695549011\n",
      "Epoch: 7770/10000 Loss (MSE):  train=0.5117461681365967\n",
      "Epoch: 7780/10000 Loss (MSE):  train=0.5117436647415161\n",
      "Epoch: 7790/10000 Loss (MSE):  train=0.5117412805557251\n",
      "Epoch: 7800/10000 Loss (MSE):  train=0.5117388963699341\n",
      "gammaaaaa:  [[1.0027477]\n",
      " [1.0027477]\n",
      " [1.0027477]\n",
      " [2.0054207]\n",
      " [2.0054207]\n",
      " [2.0054207]\n",
      " [2.0054207]\n",
      " [2.0054207]\n",
      " [2.0054207]\n",
      " [2.0054207]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 7810/10000 Loss (MSE):  train=0.5117369294166565\n",
      "Epoch: 7820/10000 Loss (MSE):  train=0.5117342472076416\n",
      "Epoch: 7830/10000 Loss (MSE):  train=0.5117316246032715\n",
      "Epoch: 7840/10000 Loss (MSE):  train=0.5117294192314148\n",
      "Epoch: 7850/10000 Loss (MSE):  train=0.511726975440979\n",
      "Epoch: 7860/10000 Loss (MSE):  train=0.5117245316505432\n",
      "Epoch: 7870/10000 Loss (MSE):  train=0.5117223262786865\n",
      "Epoch: 7880/10000 Loss (MSE):  train=0.5117200613021851\n",
      "Epoch: 7890/10000 Loss (MSE):  train=0.5117174983024597\n",
      "Epoch: 7900/10000 Loss (MSE):  train=0.5117149353027344\n",
      "gammaaaaa:  [[1.0027666]\n",
      " [1.0027666]\n",
      " [1.0027666]\n",
      " [2.0054638]\n",
      " [2.0054638]\n",
      " [2.0054638]\n",
      " [2.0054638]\n",
      " [2.0054638]\n",
      " [2.0054638]\n",
      " [2.0054638]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 7910/10000 Loss (MSE):  train=0.5117124319076538\n",
      "Epoch: 7920/10000 Loss (MSE):  train=0.5117101073265076\n",
      "Epoch: 7930/10000 Loss (MSE):  train=0.5117076635360718\n",
      "Epoch: 7940/10000 Loss (MSE):  train=0.5117049217224121\n",
      "Epoch: 7950/10000 Loss (MSE):  train=0.5117026567459106\n",
      "Epoch: 7960/10000 Loss (MSE):  train=0.511700451374054\n",
      "Epoch: 7970/10000 Loss (MSE):  train=0.5116975903511047\n",
      "Epoch: 7980/10000 Loss (MSE):  train=0.5116956233978271\n",
      "Epoch: 7990/10000 Loss (MSE):  train=0.5116937160491943\n",
      "Epoch: 8000/10000 Loss (MSE):  train=0.5116910338401794\n",
      "gammaaaaa:  [[1.0027854]\n",
      " [1.0027854]\n",
      " [1.0027854]\n",
      " [2.005507 ]\n",
      " [2.005507 ]\n",
      " [2.005507 ]\n",
      " [2.005507 ]\n",
      " [2.005507 ]\n",
      " [2.005507 ]\n",
      " [2.005507 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 8010/10000 Loss (MSE):  train=0.5116890668869019\n",
      "Epoch: 8020/10000 Loss (MSE):  train=0.511686384677887\n",
      "Epoch: 8030/10000 Loss (MSE):  train=0.5116838216781616\n",
      "Epoch: 8040/10000 Loss (MSE):  train=0.511681854724884\n",
      "Epoch: 8050/10000 Loss (MSE):  train=0.5116791725158691\n",
      "Epoch: 8060/10000 Loss (MSE):  train=0.511676549911499\n",
      "Epoch: 8070/10000 Loss (MSE):  train=0.5116748809814453\n",
      "Epoch: 8080/10000 Loss (MSE):  train=0.5116724371910095\n",
      "Epoch: 8090/10000 Loss (MSE):  train=0.5116697549819946\n",
      "Epoch: 8100/10000 Loss (MSE):  train=0.5116676092147827\n",
      "gammaaaaa:  [[1.0028045]\n",
      " [1.0028045]\n",
      " [1.0028045]\n",
      " [2.00555  ]\n",
      " [2.00555  ]\n",
      " [2.00555  ]\n",
      " [2.00555  ]\n",
      " [2.00555  ]\n",
      " [2.00555  ]\n",
      " [2.00555  ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 8110/10000 Loss (MSE):  train=0.5116653442382812\n",
      "Epoch: 8120/10000 Loss (MSE):  train=0.511663019657135\n",
      "Epoch: 8130/10000 Loss (MSE):  train=0.5116607546806335\n",
      "Epoch: 8140/10000 Loss (MSE):  train=0.5116584300994873\n",
      "Epoch: 8150/10000 Loss (MSE):  train=0.5116559863090515\n",
      "Epoch: 8160/10000 Loss (MSE):  train=0.51165372133255\n",
      "Epoch: 8170/10000 Loss (MSE):  train=0.5116512775421143\n",
      "Epoch: 8180/10000 Loss (MSE):  train=0.5116490125656128\n",
      "Epoch: 8190/10000 Loss (MSE):  train=0.5116467475891113\n",
      "Epoch: 8200/10000 Loss (MSE):  train=0.5116446018218994\n",
      "gammaaaaa:  [[1.0028228]\n",
      " [1.0028228]\n",
      " [1.0028228]\n",
      " [2.0055938]\n",
      " [2.0055938]\n",
      " [2.0055938]\n",
      " [2.0055938]\n",
      " [2.0055938]\n",
      " [2.0055938]\n",
      " [2.0055938]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 8210/10000 Loss (MSE):  train=0.5116420388221741\n",
      "Epoch: 8220/10000 Loss (MSE):  train=0.5116396546363831\n",
      "Epoch: 8230/10000 Loss (MSE):  train=0.5116376280784607\n",
      "Epoch: 8240/10000 Loss (MSE):  train=0.5116349458694458\n",
      "Epoch: 8250/10000 Loss (MSE):  train=0.511633038520813\n",
      "Epoch: 8260/10000 Loss (MSE):  train=0.511630654335022\n",
      "Epoch: 8270/10000 Loss (MSE):  train=0.5116286873817444\n",
      "Epoch: 8280/10000 Loss (MSE):  train=0.5116259455680847\n",
      "Epoch: 8290/10000 Loss (MSE):  train=0.5116236805915833\n",
      "Epoch: 8300/10000 Loss (MSE):  train=0.5116210579872131\n",
      "gammaaaaa:  [[1.0028417]\n",
      " [1.0028417]\n",
      " [1.0028417]\n",
      " [2.0056362]\n",
      " [2.0056362]\n",
      " [2.0056362]\n",
      " [2.0056362]\n",
      " [2.0056362]\n",
      " [2.0056362]\n",
      " [2.0056362]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 8310/10000 Loss (MSE):  train=0.5116187334060669\n",
      "Epoch: 8320/10000 Loss (MSE):  train=0.5116166472434998\n",
      "Epoch: 8330/10000 Loss (MSE):  train=0.511614203453064\n",
      "Epoch: 8340/10000 Loss (MSE):  train=0.5116119980812073\n",
      "Epoch: 8350/10000 Loss (MSE):  train=0.5116097927093506\n",
      "Epoch: 8360/10000 Loss (MSE):  train=0.511607825756073\n",
      "Epoch: 8370/10000 Loss (MSE):  train=0.5116052627563477\n",
      "Epoch: 8380/10000 Loss (MSE):  train=0.5116032361984253\n",
      "Epoch: 8390/10000 Loss (MSE):  train=0.5116007924079895\n",
      "Epoch: 8400/10000 Loss (MSE):  train=0.5115982294082642\n",
      "gammaaaaa:  [[1.0028595]\n",
      " [1.0028595]\n",
      " [1.0028595]\n",
      " [2.0056803]\n",
      " [2.0056803]\n",
      " [2.0056803]\n",
      " [2.0056803]\n",
      " [2.0056803]\n",
      " [2.0056803]\n",
      " [2.0056803]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 8410/10000 Loss (MSE):  train=0.5115959644317627\n",
      "Epoch: 8420/10000 Loss (MSE):  train=0.5115938782691956\n",
      "Epoch: 8430/10000 Loss (MSE):  train=0.511591911315918\n",
      "Epoch: 8440/10000 Loss (MSE):  train=0.511589765548706\n",
      "Epoch: 8450/10000 Loss (MSE):  train=0.511587381362915\n",
      "Epoch: 8460/10000 Loss (MSE):  train=0.511584997177124\n",
      "Epoch: 8470/10000 Loss (MSE):  train=0.5115829706192017\n",
      "Epoch: 8480/10000 Loss (MSE):  train=0.5115806460380554\n",
      "Epoch: 8490/10000 Loss (MSE):  train=0.5115784406661987\n",
      "Epoch: 8500/10000 Loss (MSE):  train=0.5115761756896973\n",
      "gammaaaaa:  [[1.0028771]\n",
      " [1.0028771]\n",
      " [1.0028771]\n",
      " [2.0057242]\n",
      " [2.0057242]\n",
      " [2.0057242]\n",
      " [2.0057242]\n",
      " [2.0057242]\n",
      " [2.0057242]\n",
      " [2.0057242]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 8510/10000 Loss (MSE):  train=0.5115742087364197\n",
      "Epoch: 8520/10000 Loss (MSE):  train=0.5115721225738525\n",
      "Epoch: 8530/10000 Loss (MSE):  train=0.5115696787834167\n",
      "Epoch: 8540/10000 Loss (MSE):  train=0.5115675330162048\n",
      "Epoch: 8550/10000 Loss (MSE):  train=0.5115654468536377\n",
      "Epoch: 8560/10000 Loss (MSE):  train=0.5115629434585571\n",
      "Epoch: 8570/10000 Loss (MSE):  train=0.5115607976913452\n",
      "Epoch: 8580/10000 Loss (MSE):  train=0.511558473110199\n",
      "Epoch: 8590/10000 Loss (MSE):  train=0.5115565061569214\n",
      "Epoch: 8600/10000 Loss (MSE):  train=0.5115540027618408\n",
      "gammaaaaa:  [[1.0028944]\n",
      " [1.0028944]\n",
      " [1.0028944]\n",
      " [2.0057685]\n",
      " [2.0057685]\n",
      " [2.0057685]\n",
      " [2.0057685]\n",
      " [2.0057685]\n",
      " [2.0057685]\n",
      " [2.0057685]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 8610/10000 Loss (MSE):  train=0.5115523338317871\n",
      "Epoch: 8620/10000 Loss (MSE):  train=0.5115501880645752\n",
      "Epoch: 8630/10000 Loss (MSE):  train=0.5115479230880737\n",
      "Epoch: 8640/10000 Loss (MSE):  train=0.5115456581115723\n",
      "Epoch: 8650/10000 Loss (MSE):  train=0.5115435123443604\n",
      "Epoch: 8660/10000 Loss (MSE):  train=0.5115410089492798\n",
      "Epoch: 8670/10000 Loss (MSE):  train=0.511539101600647\n",
      "Epoch: 8680/10000 Loss (MSE):  train=0.5115370750427246\n",
      "Epoch: 8690/10000 Loss (MSE):  train=0.5115346312522888\n",
      "Epoch: 8700/10000 Loss (MSE):  train=0.5115323066711426\n",
      "gammaaaaa:  [[1.0029117]\n",
      " [1.0029117]\n",
      " [1.0029117]\n",
      " [2.0058124]\n",
      " [2.0058124]\n",
      " [2.0058124]\n",
      " [2.0058124]\n",
      " [2.0058124]\n",
      " [2.0058124]\n",
      " [2.0058124]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 8710/10000 Loss (MSE):  train=0.5115305781364441\n",
      "Epoch: 8720/10000 Loss (MSE):  train=0.5115282535552979\n",
      "Epoch: 8730/10000 Loss (MSE):  train=0.511526346206665\n",
      "Epoch: 8740/10000 Loss (MSE):  train=0.5115240812301636\n",
      "Epoch: 8750/10000 Loss (MSE):  train=0.5115220546722412\n",
      "Epoch: 8760/10000 Loss (MSE):  train=0.511519730091095\n",
      "Epoch: 8770/10000 Loss (MSE):  train=0.5115178823471069\n",
      "Epoch: 8780/10000 Loss (MSE):  train=0.5115152597427368\n",
      "Epoch: 8790/10000 Loss (MSE):  train=0.5115134119987488\n",
      "Epoch: 8800/10000 Loss (MSE):  train=0.5115110874176025\n",
      "gammaaaaa:  [[1.0029289]\n",
      " [1.0029289]\n",
      " [1.0029289]\n",
      " [2.0058565]\n",
      " [2.0058565]\n",
      " [2.0058565]\n",
      " [2.0058565]\n",
      " [2.0058565]\n",
      " [2.0058565]\n",
      " [2.0058565]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 8810/10000 Loss (MSE):  train=0.511508584022522\n",
      "Epoch: 8820/10000 Loss (MSE):  train=0.5115069150924683\n",
      "Epoch: 8830/10000 Loss (MSE):  train=0.5115047693252563\n",
      "Epoch: 8840/10000 Loss (MSE):  train=0.5115024447441101\n",
      "Epoch: 8850/10000 Loss (MSE):  train=0.5115005970001221\n",
      "Epoch: 8860/10000 Loss (MSE):  train=0.5114985704421997\n",
      "Epoch: 8870/10000 Loss (MSE):  train=0.5114962458610535\n",
      "Epoch: 8880/10000 Loss (MSE):  train=0.5114943385124207\n",
      "Epoch: 8890/10000 Loss (MSE):  train=0.5114923715591431\n",
      "Epoch: 8900/10000 Loss (MSE):  train=0.5114901065826416\n",
      "gammaaaaa:  [[1.0029455]\n",
      " [1.0029455]\n",
      " [1.0029455]\n",
      " [2.0059   ]\n",
      " [2.0059   ]\n",
      " [2.0059   ]\n",
      " [2.0059   ]\n",
      " [2.0059   ]\n",
      " [2.0058997]\n",
      " [2.0058997]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 8910/10000 Loss (MSE):  train=0.5114877820014954\n",
      "Epoch: 8920/10000 Loss (MSE):  train=0.5114859342575073\n",
      "Epoch: 8930/10000 Loss (MSE):  train=0.5114839673042297\n",
      "Epoch: 8940/10000 Loss (MSE):  train=0.5114814639091492\n",
      "Epoch: 8950/10000 Loss (MSE):  train=0.5114792585372925\n",
      "Epoch: 8960/10000 Loss (MSE):  train=0.5114772915840149\n",
      "Epoch: 8970/10000 Loss (MSE):  train=0.5114753246307373\n",
      "Epoch: 8980/10000 Loss (MSE):  train=0.5114730000495911\n",
      "Epoch: 8990/10000 Loss (MSE):  train=0.5114709138870239\n",
      "Epoch: 9000/10000 Loss (MSE):  train=0.5114690661430359\n",
      "gammaaaaa:  [[1.0029621]\n",
      " [1.0029621]\n",
      " [1.0029621]\n",
      " [2.0059435]\n",
      " [2.0059435]\n",
      " [2.0059435]\n",
      " [2.0059435]\n",
      " [2.0059435]\n",
      " [2.0059435]\n",
      " [2.0059435]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 9010/10000 Loss (MSE):  train=0.5114673376083374\n",
      "Epoch: 9020/10000 Loss (MSE):  train=0.5114651918411255\n",
      "Epoch: 9030/10000 Loss (MSE):  train=0.5114630460739136\n",
      "Epoch: 9040/10000 Loss (MSE):  train=0.5114610195159912\n",
      "Epoch: 9050/10000 Loss (MSE):  train=0.5114588141441345\n",
      "Epoch: 9060/10000 Loss (MSE):  train=0.5114566683769226\n",
      "Epoch: 9070/10000 Loss (MSE):  train=0.5114551782608032\n",
      "Epoch: 9080/10000 Loss (MSE):  train=0.5114529132843018\n",
      "Epoch: 9090/10000 Loss (MSE):  train=0.5114507079124451\n",
      "Epoch: 9100/10000 Loss (MSE):  train=0.5114485025405884\n",
      "gammaaaaa:  [[1.0029777]\n",
      " [1.0029777]\n",
      " [1.0029777]\n",
      " [2.0059876]\n",
      " [2.0059876]\n",
      " [2.0059876]\n",
      " [2.0059876]\n",
      " [2.0059876]\n",
      " [2.0059876]\n",
      " [2.0059876]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 9110/10000 Loss (MSE):  train=0.5114468336105347\n",
      "Epoch: 9120/10000 Loss (MSE):  train=0.5114445686340332\n",
      "Epoch: 9130/10000 Loss (MSE):  train=0.5114421844482422\n",
      "Epoch: 9140/10000 Loss (MSE):  train=0.511440098285675\n",
      "Epoch: 9150/10000 Loss (MSE):  train=0.5114383697509766\n",
      "Epoch: 9160/10000 Loss (MSE):  train=0.5114360451698303\n",
      "Epoch: 9170/10000 Loss (MSE):  train=0.5114338994026184\n",
      "Epoch: 9180/10000 Loss (MSE):  train=0.5114320516586304\n",
      "Epoch: 9190/10000 Loss (MSE):  train=0.5114299058914185\n",
      "Epoch: 9200/10000 Loss (MSE):  train=0.5114280581474304\n",
      "gammaaaaa:  [[1.0029941]\n",
      " [1.0029941]\n",
      " [1.0029941]\n",
      " [2.0060308]\n",
      " [2.0060308]\n",
      " [2.0060308]\n",
      " [2.0060308]\n",
      " [2.0060308]\n",
      " [2.006031 ]\n",
      " [2.006031 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 9210/10000 Loss (MSE):  train=0.511425793170929\n",
      "Epoch: 9220/10000 Loss (MSE):  train=0.5114244818687439\n",
      "Epoch: 9230/10000 Loss (MSE):  train=0.5114226341247559\n",
      "Epoch: 9240/10000 Loss (MSE):  train=0.5114203095436096\n",
      "Epoch: 9250/10000 Loss (MSE):  train=0.5114182233810425\n",
      "Epoch: 9260/10000 Loss (MSE):  train=0.511415958404541\n",
      "Epoch: 9270/10000 Loss (MSE):  train=0.5114140510559082\n",
      "Epoch: 9280/10000 Loss (MSE):  train=0.5114117860794067\n",
      "Epoch: 9290/10000 Loss (MSE):  train=0.5114100575447083\n",
      "Epoch: 9300/10000 Loss (MSE):  train=0.5114082098007202\n",
      "gammaaaaa:  [[1.0030098]\n",
      " [1.0030098]\n",
      " [1.0030098]\n",
      " [2.0060742]\n",
      " [2.0060742]\n",
      " [2.0060742]\n",
      " [2.0060742]\n",
      " [2.0060742]\n",
      " [2.0060742]\n",
      " [2.0060742]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 9310/10000 Loss (MSE):  train=0.5114060640335083\n",
      "Epoch: 9320/10000 Loss (MSE):  train=0.5114041566848755\n",
      "Epoch: 9330/10000 Loss (MSE):  train=0.5114023089408875\n",
      "Epoch: 9340/10000 Loss (MSE):  train=0.511400043964386\n",
      "Epoch: 9350/10000 Loss (MSE):  train=0.5113978385925293\n",
      "Epoch: 9360/10000 Loss (MSE):  train=0.5113958120346069\n",
      "Epoch: 9370/10000 Loss (MSE):  train=0.511394202709198\n",
      "Epoch: 9380/10000 Loss (MSE):  train=0.51139235496521\n",
      "Epoch: 9390/10000 Loss (MSE):  train=0.511390209197998\n",
      "Epoch: 9400/10000 Loss (MSE):  train=0.5113883018493652\n",
      "gammaaaaa:  [[1.003025 ]\n",
      " [1.003025 ]\n",
      " [1.003025 ]\n",
      " [2.0061178]\n",
      " [2.0061178]\n",
      " [2.0061178]\n",
      " [2.0061178]\n",
      " [2.0061178]\n",
      " [2.0061178]\n",
      " [2.0061178]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 9410/10000 Loss (MSE):  train=0.5113863348960876\n",
      "Epoch: 9420/10000 Loss (MSE):  train=0.5113845467567444\n",
      "Epoch: 9430/10000 Loss (MSE):  train=0.5113824009895325\n",
      "Epoch: 9440/10000 Loss (MSE):  train=0.5113807916641235\n",
      "Epoch: 9450/10000 Loss (MSE):  train=0.5113787651062012\n",
      "Epoch: 9460/10000 Loss (MSE):  train=0.5113767981529236\n",
      "Epoch: 9470/10000 Loss (MSE):  train=0.5113747119903564\n",
      "Epoch: 9480/10000 Loss (MSE):  train=0.5113728046417236\n",
      "Epoch: 9490/10000 Loss (MSE):  train=0.5113707780838013\n",
      "Epoch: 9500/10000 Loss (MSE):  train=0.5113686919212341\n",
      "gammaaaaa:  [[1.0030403]\n",
      " [1.0030403]\n",
      " [1.0030403]\n",
      " [2.0061603]\n",
      " [2.0061603]\n",
      " [2.0061603]\n",
      " [2.0061603]\n",
      " [2.0061603]\n",
      " [2.00616  ]\n",
      " [2.00616  ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 9510/10000 Loss (MSE):  train=0.51136714220047\n",
      "Epoch: 9520/10000 Loss (MSE):  train=0.5113651752471924\n",
      "Epoch: 9530/10000 Loss (MSE):  train=0.5113632082939148\n",
      "Epoch: 9540/10000 Loss (MSE):  train=0.5113611817359924\n",
      "Epoch: 9550/10000 Loss (MSE):  train=0.5113590955734253\n",
      "Epoch: 9560/10000 Loss (MSE):  train=0.5113572478294373\n",
      "Epoch: 9570/10000 Loss (MSE):  train=0.5113554000854492\n",
      "Epoch: 9580/10000 Loss (MSE):  train=0.5113534331321716\n",
      "Epoch: 9590/10000 Loss (MSE):  train=0.5113512277603149\n",
      "Epoch: 9600/10000 Loss (MSE):  train=0.5113492012023926\n",
      "gammaaaaa:  [[1.003055 ]\n",
      " [1.003055 ]\n",
      " [1.003055 ]\n",
      " [2.0062013]\n",
      " [2.0062013]\n",
      " [2.0062013]\n",
      " [2.0062013]\n",
      " [2.0062013]\n",
      " [2.0062013]\n",
      " [2.0062013]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 9610/10000 Loss (MSE):  train=0.5113473534584045\n",
      "Epoch: 9620/10000 Loss (MSE):  train=0.5113452672958374\n",
      "Epoch: 9630/10000 Loss (MSE):  train=0.5113435983657837\n",
      "Epoch: 9640/10000 Loss (MSE):  train=0.5113416314125061\n",
      "Epoch: 9650/10000 Loss (MSE):  train=0.5113398432731628\n",
      "Epoch: 9660/10000 Loss (MSE):  train=0.5113378763198853\n",
      "Epoch: 9670/10000 Loss (MSE):  train=0.5113359689712524\n",
      "Epoch: 9680/10000 Loss (MSE):  train=0.5113341212272644\n",
      "Epoch: 9690/10000 Loss (MSE):  train=0.5113323330879211\n",
      "Epoch: 9700/10000 Loss (MSE):  train=0.5113304853439331\n",
      "gammaaaaa:  [[1.0030699]\n",
      " [1.0030699]\n",
      " [1.0030699]\n",
      " [2.0062428]\n",
      " [2.0062428]\n",
      " [2.0062428]\n",
      " [2.0062428]\n",
      " [2.0062428]\n",
      " [2.0062428]\n",
      " [2.0062428]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 9710/10000 Loss (MSE):  train=0.5113284587860107\n",
      "Epoch: 9720/10000 Loss (MSE):  train=0.511326789855957\n",
      "Epoch: 9730/10000 Loss (MSE):  train=0.5113248825073242\n",
      "Epoch: 9740/10000 Loss (MSE):  train=0.511323094367981\n",
      "Epoch: 9750/10000 Loss (MSE):  train=0.5113213062286377\n",
      "Epoch: 9760/10000 Loss (MSE):  train=0.5113191604614258\n",
      "Epoch: 9770/10000 Loss (MSE):  train=0.5113176107406616\n",
      "Epoch: 9780/10000 Loss (MSE):  train=0.5113158226013184\n",
      "Epoch: 9790/10000 Loss (MSE):  train=0.5113142728805542\n",
      "Epoch: 9800/10000 Loss (MSE):  train=0.511311948299408\n",
      "gammaaaaa:  [[1.0030841]\n",
      " [1.0030841]\n",
      " [1.0030841]\n",
      " [2.006283 ]\n",
      " [2.006283 ]\n",
      " [2.006283 ]\n",
      " [2.006283 ]\n",
      " [2.006283 ]\n",
      " [2.006283 ]\n",
      " [2.006283 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 9810/10000 Loss (MSE):  train=0.5113099813461304\n",
      "Epoch: 9820/10000 Loss (MSE):  train=0.5113081932067871\n",
      "Epoch: 9830/10000 Loss (MSE):  train=0.5113067030906677\n",
      "Epoch: 9840/10000 Loss (MSE):  train=0.5113050937652588\n",
      "Epoch: 9850/10000 Loss (MSE):  train=0.5113030672073364\n",
      "Epoch: 9860/10000 Loss (MSE):  train=0.5113011598587036\n",
      "Epoch: 9870/10000 Loss (MSE):  train=0.5112992525100708\n",
      "Epoch: 9880/10000 Loss (MSE):  train=0.5112974643707275\n",
      "Epoch: 9890/10000 Loss (MSE):  train=0.5112951993942261\n",
      "Epoch: 9900/10000 Loss (MSE):  train=0.5112936496734619\n",
      "gammaaaaa:  [[1.003098 ]\n",
      " [1.003098 ]\n",
      " [1.003098 ]\n",
      " [2.0063233]\n",
      " [2.0063233]\n",
      " [2.0063233]\n",
      " [2.0063233]\n",
      " [2.0063233]\n",
      " [2.006323 ]\n",
      " [2.006323 ]]\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/loss_array.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "Epoch: 9910/10000 Loss (MSE):  train=0.5112919807434082\n",
      "Epoch: 9920/10000 Loss (MSE):  train=0.5112900733947754\n",
      "Epoch: 9930/10000 Loss (MSE):  train=0.5112881660461426\n",
      "Epoch: 9940/10000 Loss (MSE):  train=0.511286199092865\n",
      "Epoch: 9950/10000 Loss (MSE):  train=0.511284589767456\n",
      "Epoch: 9960/10000 Loss (MSE):  train=0.5112825632095337\n",
      "Epoch: 9970/10000 Loss (MSE):  train=0.5112807154655457\n",
      "Epoch: 9980/10000 Loss (MSE):  train=0.5112790465354919\n",
      "Epoch: 9990/10000 Loss (MSE):  train=0.51127690076828\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/training_loss.png ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model.dil ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def loss_fn(params, Rs, Rs_1_ac,A=1, B=500): # A=4, B=996 wf=0.996):\n",
    "    Rs_1_pred, gamma = v_v_next_step_pos_gamma_fn(Rs, params)\n",
    "    var =1/gamma\n",
    "    return GaussianNLL(var, Rs_1_pred, Rs_1_ac, A, B)\n",
    "\n",
    "def gloss(*args):\n",
    "    return value_and_grad(loss_fn)(*args)\n",
    "\n",
    "def update(i, opt_state, params, loss__, *data):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads_ = gloss(params, *data)\n",
    "    opt_state = opt_update(i, grads_, opt_state)\n",
    "    return opt_state, get_params(opt_state), value\n",
    "\n",
    "@jit\n",
    "def step(i, ps, *args):\n",
    "    return update(i, *ps, *args)\n",
    "\n",
    "opt_init, opt_update_, get_params = optimizers.adam(lr)\n",
    "\n",
    "@jit\n",
    "def opt_update(i, grads_, opt_state):\n",
    "    grads_ = jax.tree_map(jnp.nan_to_num, grads_)\n",
    "    grads_ = jax.tree_map(partial(jnp.clip, a_min=-1000.0, a_max=1000.0), grads_)\n",
    "    return opt_update_(i, grads_, opt_state)\n",
    "\n",
    "def batching(*args, size=None):\n",
    "    L = len(args[0])\n",
    "    if size != None:\n",
    "        nbatches1 = int((L - 0.5) // size) + 1\n",
    "        nbatches2 = max(1, nbatches1 - 1)\n",
    "        size1 = int(L/nbatches1)\n",
    "        size2 = int(L/nbatches2)\n",
    "        if size1*nbatches1 > size2*nbatches2:\n",
    "            size = size1\n",
    "            nbatches = nbatches1\n",
    "        else:\n",
    "            size = size2\n",
    "            nbatches = nbatches2\n",
    "    else:\n",
    "        nbatches = 1\n",
    "        size = L\n",
    "    \n",
    "    newargs = []\n",
    "    for arg in args:\n",
    "        newargs += [jnp.array([arg[i*size:(i+1)*size]\n",
    "                                for i in range(nbatches)])]\n",
    "    return newargs\n",
    "\n",
    "bRs_in, bRs_out = batching(Rs_in, Rs_out, size=min(len(Rs_in), batch_size))\n",
    "\n",
    "print(f\"training ...\")\n",
    "\n",
    "opt_state = opt_init(params)\n",
    "epoch = 0\n",
    "optimizer_step = -1\n",
    "larray = []\n",
    "ltarray = []\n",
    "last_loss = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    l = 0.0\n",
    "    count = 0\n",
    "    for data in zip(bRs_in, bRs_out):\n",
    "        optimizer_step += 1\n",
    "        opt_state, params, l_ = step(\n",
    "            optimizer_step, (opt_state, params, 0), *data)\n",
    "        l += l_\n",
    "        count+=1\n",
    "    # print(\"epoch,countttttt: \", epoch,count)\n",
    "    # opt_state, params, l_ = step(optimizer_step, (opt_state, params, 0), Rs, Vs, Fs)\n",
    "    l = l/count\n",
    "    larray += [l]\n",
    "    # ltarray += [loss_fn(params, bRs_in, bVs_in, bRs_out)]\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}/{epochs} Loss (MSE):  train={larray[-1]}\")#, test={ltarray[-1]}\")\n",
    "    if epoch % 100 == 0:\n",
    "        print('gammaaaaa: ', gamma_fn_model(params))\n",
    "        metadata = {\n",
    "            \"savedat\": epoch,\n",
    "            # \"mpass\": mpass,\n",
    "            }\n",
    "        savefile(f\"fgnode_trained_model.dil\",\n",
    "                    params, metadata=metadata)\n",
    "        # savefile(f\"loss_array.dil\", (larray, ltarray), metadata=metadata)\n",
    "        savefile(f\"loss_array.dil\", larray, metadata=metadata)\n",
    "        if last_loss > larray[-1]:\n",
    "            last_loss = larray[-1]\n",
    "            savefile(f\"fgnode_trained_model_low.dil\",\n",
    "                        params, metadata=metadata)\n",
    "        fig, axs = panel(1, 1)\n",
    "        # plt.semilogy(larray, label=\"Training\")\n",
    "        plt.plot(larray, label=\"Training\")\n",
    "        # plt.semilogy(ltarray, label=\"Test\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(_filename(f\"training_loss.png\"))\n",
    "\n",
    "fig, axs = panel(1, 1)\n",
    "# plt.semilogy(larray, label=\"Training\")\n",
    "plt.plot(larray, label=\"Training\")\n",
    "# plt.semilogy(ltarray, label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(_filename(f\"training_loss.png\"))\n",
    "\n",
    "params = get_params(opt_state)\n",
    "savefile(f\"fgnode_trained_model.dil\", params, metadata=metadata)\n",
    "# savefile(f\"loss_array.dil\", (larray, ltarray), metadata=metadata)\n",
    "\n",
    "if last_loss > larray[-1]:\n",
    "    last_loss = larray[-1]\n",
    "    savefile(f\"fgnode_trained_model_low.dil\", params, metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params, _ = loadfile(f\"fgnode_trained_model_low.dil\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rname=False\n",
    "\n",
    "# PSYS = f\"a-{N}-Spring-data-brownian_EM\"\n",
    "# TAG = f\"2BNN\"\n",
    "# out_dir = f\"../results\"\n",
    "\n",
    "def _filename(name, tag=TAG):\n",
    "    rstring = randfilename if (rname and (tag != \"data\")) else (\n",
    "        \"0\" if (tag == \"data\") or (withdata == None) else f\"0_{withdata}\")\n",
    "    filename_prefix = f\"{out_dir}/{PSYS}-{tag}/{rstring}/\"\n",
    "    file = f\"{filename_prefix}/{name}\"\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    filename = f\"{filename_prefix}/{name}\".replace(\"//\", \"/\")\n",
    "    print(\"===\", filename, \"===\")\n",
    "    return filename\n",
    "\n",
    "def OUT(f):\n",
    "    @wraps(f)\n",
    "    def func(file, *args, tag=TAG, **kwargs):\n",
    "        return f(_filename(file, tag=tag), *args, **kwargs)\n",
    "    return func\n",
    "\n",
    "loadmodel = OUT(src.models.loadmodel)\n",
    "savemodel = OUT(src.models.savemodel)\n",
    "\n",
    "loadfile = OUT(src.io.loadfile)\n",
    "savefile = OUT(src.io.savefile)\n",
    "save_ovito = OUT(src.io.save_ovito)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil ===\n",
      "Loading ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/fgnode_trained_model_low.dil\n"
     ]
    }
   ],
   "source": [
    "params, _ = loadfile(f\"fgnode_trained_model_low.dil\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.0031127],\n",
       "       [1.0031127],\n",
       "       [1.0031127],\n",
       "       [2.0063612],\n",
       "       [2.0063612],\n",
       "       [2.0063612],\n",
       "       [2.0063612],\n",
       "       [2.0063612],\n",
       "       [2.0063615],\n",
       "       [2.0063615]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_fn_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "spring_constant = 1.0\n",
    "length_constant = 1.0\n",
    "# gamma_orig = jnp.ones(jnp.unique(species).shape)\n",
    "gamma_orig = jnp.where(jnp.arange(N) <3, 1.0, 2.0).reshape(-1,1)\n",
    "stride = 1\n",
    "runs=100\n",
    "\n",
    "def SPRING(x, stiffness=1.0, length=1.0):\n",
    "    x_ = jnp.linalg.norm(x, keepdims=True)\n",
    "    return 0.5*stiffness*(x_ - length)**2\n",
    "\n",
    "def pot_energy_orig(x):\n",
    "    dr = x[senders, :] - x[receivers, :]\n",
    "    return vmap(partial(SPRING, stiffness=spring_constant, length=length_constant))(dr).sum()\n",
    "\n",
    "def force_fn_orig(R, params):\n",
    "    return -grad(pot_energy_orig)(R)\n",
    "\n",
    "\n",
    "def get_forward_sim(params = None, force_fn = None, gamma = None, runs=10):\n",
    "        @jit\n",
    "        def fn(R,key):\n",
    "            return predition_brow(R, params, force_fn, shift, dt, kT, masses, gamma = gamma, stride=stride, runs=runs, key=key)\n",
    "        return fn\n",
    "\n",
    "gamma_model = gamma_fn_model(params)\n",
    "\n",
    "sim_orig = get_forward_sim(params=None,force_fn=force_fn_orig, gamma=gamma_orig,runs=runs)\n",
    "sim_model = get_forward_sim(params=params,force_fn=force_fn_model, gamma=gamma_model,runs=runs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating trajectory 0/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/actual_0_0.xyz ===\n",
      "Saving ovito file: ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/actual_0_0.xyz\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/pred_0_0.xyz ===\n",
      "Saving ovito file: ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/pred_0_0.xyz\n",
      "Simulating trajectory 1/100 ...\n",
      "Simulating trajectory 2/100 ...\n",
      "Simulating trajectory 3/100 ...\n",
      "Simulating trajectory 4/100 ...\n",
      "Simulating trajectory 5/100 ...\n",
      "Simulating trajectory 6/100 ...\n",
      "Simulating trajectory 7/100 ...\n",
      "Simulating trajectory 8/100 ...\n",
      "Simulating trajectory 9/100 ...\n",
      "Simulating trajectory 10/100 ...\n",
      "Simulating trajectory 11/100 ...\n",
      "Simulating trajectory 12/100 ...\n",
      "Simulating trajectory 13/100 ...\n",
      "Simulating trajectory 14/100 ...\n",
      "Simulating trajectory 15/100 ...\n",
      "Simulating trajectory 16/100 ...\n",
      "Simulating trajectory 17/100 ...\n",
      "Simulating trajectory 18/100 ...\n",
      "Simulating trajectory 19/100 ...\n",
      "Simulating trajectory 20/100 ...\n",
      "Simulating trajectory 21/100 ...\n",
      "Simulating trajectory 22/100 ...\n",
      "Simulating trajectory 23/100 ...\n",
      "Simulating trajectory 24/100 ...\n",
      "Simulating trajectory 25/100 ...\n",
      "Simulating trajectory 26/100 ...\n",
      "Simulating trajectory 27/100 ...\n",
      "Simulating trajectory 28/100 ...\n",
      "Simulating trajectory 29/100 ...\n",
      "Simulating trajectory 30/100 ...\n",
      "Simulating trajectory 31/100 ...\n",
      "Simulating trajectory 32/100 ...\n",
      "Simulating trajectory 33/100 ...\n",
      "Simulating trajectory 34/100 ...\n",
      "Simulating trajectory 35/100 ...\n",
      "Simulating trajectory 36/100 ...\n",
      "Simulating trajectory 37/100 ...\n",
      "Simulating trajectory 38/100 ...\n",
      "Simulating trajectory 39/100 ...\n",
      "Simulating trajectory 40/100 ...\n",
      "Simulating trajectory 41/100 ...\n",
      "Simulating trajectory 42/100 ...\n",
      "Simulating trajectory 43/100 ...\n",
      "Simulating trajectory 44/100 ...\n",
      "Simulating trajectory 45/100 ...\n",
      "Simulating trajectory 46/100 ...\n",
      "Simulating trajectory 47/100 ...\n",
      "Simulating trajectory 48/100 ...\n",
      "Simulating trajectory 49/100 ...\n",
      "Simulating trajectory 50/100 ...\n",
      "Simulating trajectory 51/100 ...\n",
      "Simulating trajectory 52/100 ...\n",
      "Simulating trajectory 53/100 ...\n",
      "Simulating trajectory 54/100 ...\n",
      "Simulating trajectory 55/100 ...\n",
      "Simulating trajectory 56/100 ...\n",
      "Simulating trajectory 57/100 ...\n",
      "Simulating trajectory 58/100 ...\n",
      "Simulating trajectory 59/100 ...\n",
      "Simulating trajectory 60/100 ...\n",
      "Simulating trajectory 61/100 ...\n",
      "Simulating trajectory 62/100 ...\n",
      "Simulating trajectory 63/100 ...\n",
      "Simulating trajectory 64/100 ...\n",
      "Simulating trajectory 65/100 ...\n",
      "Simulating trajectory 66/100 ...\n",
      "Simulating trajectory 67/100 ...\n",
      "Simulating trajectory 68/100 ...\n",
      "Simulating trajectory 69/100 ...\n",
      "Simulating trajectory 70/100 ...\n",
      "Simulating trajectory 71/100 ...\n",
      "Simulating trajectory 72/100 ...\n",
      "Simulating trajectory 73/100 ...\n",
      "Simulating trajectory 74/100 ...\n",
      "Simulating trajectory 75/100 ...\n",
      "Simulating trajectory 76/100 ...\n",
      "Simulating trajectory 77/100 ...\n",
      "Simulating trajectory 78/100 ...\n",
      "Simulating trajectory 79/100 ...\n",
      "Simulating trajectory 80/100 ...\n",
      "Simulating trajectory 81/100 ...\n",
      "Simulating trajectory 82/100 ...\n",
      "Simulating trajectory 83/100 ...\n",
      "Simulating trajectory 84/100 ...\n",
      "Simulating trajectory 85/100 ...\n",
      "Simulating trajectory 86/100 ...\n",
      "Simulating trajectory 87/100 ...\n",
      "Simulating trajectory 88/100 ...\n",
      "Simulating trajectory 89/100 ...\n",
      "Simulating trajectory 90/100 ...\n",
      "Simulating trajectory 91/100 ...\n",
      "Simulating trajectory 92/100 ...\n",
      "Simulating trajectory 93/100 ...\n",
      "Simulating trajectory 94/100 ...\n",
      "Simulating trajectory 95/100 ...\n",
      "Simulating trajectory 96/100 ...\n",
      "Simulating trajectory 97/100 ...\n",
      "Simulating trajectory 98/100 ...\n",
      "Simulating trajectory 99/100 ...\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/error_paramete_plot_a_b_c.pkl ===\n",
      "=== ../results/a-10-AB-Spring-data-brownian_EM-2BNN/05-24-2023_22-18-21/error_parameter.pkl ===\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "plotthings = True\n",
    "rng_key = random.PRNGKey(0)\n",
    "maxtraj = 100\n",
    "\n",
    "_gamma = gamma_fn_model(params)\n",
    "nexp = {\n",
    "        \"dz_actual\": [],\n",
    "        \"dz_pred\": [],\n",
    "        \"z_actual\": [],\n",
    "        \"z_pred\": [],\n",
    "        \"_gamma\": [_gamma],\n",
    "        \"simulation_time\":[],\n",
    "        }\n",
    "\n",
    "trajectories = []\n",
    "for ind in range(maxtraj):\n",
    "    print(f\"Simulating trajectory {ind}/{maxtraj} ...\")\n",
    "    R, _ = chain(N)[:2]\n",
    "    for rand in range(10):\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        actual_traj = sim_orig(R,(ind+13)*subkey)\n",
    "        rng_key, subkey = random.split(rng_key)\n",
    "        \n",
    "        start = time.time()\n",
    "        pred_traj = sim_model(R, (ind+13)*subkey)\n",
    "        end = time.time()\n",
    "        nexp[\"simulation_time\"] += [end-start]\n",
    "        \n",
    "        \n",
    "        \n",
    "        nexp[\"dz_actual\"] += [actual_traj.position-R]\n",
    "        nexp[\"dz_pred\"] += [pred_traj.position-R]\n",
    "        \n",
    "        nexp[\"z_actual\"] += [actual_traj.position]\n",
    "        nexp[\"z_pred\"] += [pred_traj.position]\n",
    "        \n",
    "        if save_ovito:\n",
    "            if ind<1 and rand<1:\n",
    "                save_ovito(f\"actual_{ind}_{rand}.xyz\", [state for state in BrownianStates(actual_traj)], lattice=\"\")\n",
    "                save_ovito(f\"pred_{ind}_{rand}.xyz\", [state for state in BrownianStates(pred_traj)], lattice=\"\")\n",
    "        \n",
    "        # trajectories += [(actual_traj, pred_traj)]\n",
    "        # if ind%10==0:\n",
    "            # savefile(\"trajectories.pkl\", trajectories)\n",
    "\n",
    "def KL_divergence(sigma0,mu0,sigma1,mu1, eps=1e-8):\n",
    "    return jnp.log(sigma1/sigma0) + (jnp.square(sigma0)+jnp.square(mu0-mu1))/(2*jnp.square(sigma1)) - 0.5\n",
    "\n",
    "def get_kld(d_actual, d_pred):\n",
    "    mu0 = jnp.mean(d_actual, axis=(0,2,3))\n",
    "    std0 = jnp.std(d_actual, axis=(0,2,3))\n",
    "    mu1 = jnp.mean(d_pred, axis=(0,2,3))\n",
    "    std1 = jnp.std(d_pred, axis=(0,2,3))\n",
    "    kld = []\n",
    "    for i in range(len(std0)):\n",
    "        kld.append(KL_divergence(std0[i],mu0[i],std1[i],mu1[i]))\n",
    "    return jnp.array(kld)\n",
    "\n",
    "def get_std_rmse(d_actual, d_pred):\n",
    "    std0 = jnp.std(d_actual, axis=(0,2,3))\n",
    "    std1 = jnp.std(d_pred, axis=(0,2,3))\n",
    "    return jnp.sqrt(jnp.square(std0 - std1))\n",
    "\n",
    "def get_dist_by_var(actual, pred, zeta):\n",
    "    disp = displacement(actual, pred)\n",
    "    dist_matrix = jnp.sqrt(jnp.square(disp).sum(-1))\n",
    "    dist_mean = jnp.mean(dist_matrix, axis=(0,2))\n",
    "    dist_by_zeta = dist_mean/zeta\n",
    "    return dist_by_zeta\n",
    "\n",
    "nexp2 = {\n",
    "        \"kld\": [],\n",
    "        \"std_rmse\": [],\n",
    "        \"dist_by_var\": [],\n",
    "        }\n",
    "\n",
    "nexp2[\"kld\"] = jnp.array(get_kld(jnp.array(nexp[\"dz_actual\"]),jnp.array(nexp[\"dz_pred\"])))\n",
    "\n",
    "nexp2[\"std_rmse\"] = jnp.array(get_std_rmse(jnp.array(nexp[\"dz_actual\"]),jnp.array(nexp[\"dz_pred\"])))\n",
    "\n",
    "nexp2[\"dist_by_var\"] = jnp.array(get_dist_by_var(jnp.array(nexp['z_actual']), jnp.array(nexp['z_pred']),1/(jnp.array(nexp['_gamma'])[0][0])))\n",
    "\n",
    "savefile(f\"error_paramete_plot_a_b_c.pkl\", nexp2)\n",
    "\n",
    "savefile(f\"error_parameter.pkl\", nexp)\n",
    "# savefile(\"trajectories.pkl\", trajectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../results/a-5-Spring-data-brownian_EM-2BNN/0/mu_sigma.png ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-2BNN/0/kld1.png ===\n",
      "=== ../results/a-5-Spring-data-brownian_EM-2BNN/0/kld_x_y.png ===\n"
     ]
    }
   ],
   "source": [
    "def KL_divergence(sigma0,mu0,sigma1,mu1, eps=1e-8):\n",
    "    # q = np.where(q == 0.0, eps, q)\n",
    "    # p = np.where(p == 0, eps, p)\n",
    "    return jnp.log(sigma1/sigma0) + (jnp.square(sigma0)+jnp.square(mu0-mu1))/(2*jnp.square(sigma1)) - 0.5\n",
    "\n",
    "actual = jnp.array(nexp[\"dz_actual\"])\n",
    "pred = jnp.array(nexp[\"dz_pred\"])\n",
    "\n",
    "\n",
    "mu0 = jnp.mean(actual, axis=(0,2,3))\n",
    "std0 = jnp.std(actual, axis=(0,2,3))\n",
    "\n",
    "mu1 = jnp.mean(pred, axis=(0,2,3))\n",
    "std1 = jnp.std(pred, axis=(0,2,3))\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(mu0,label='mu0')\n",
    "plt.plot(mu1,label='mu1')\n",
    "plt.plot(std0,label='std0')\n",
    "plt.plot(std1,label='std1')\n",
    "plt.legend()\n",
    "plt.savefig(_filename('mu_sigma.png'))\n",
    "plt.clf()\n",
    "\n",
    "kld = []\n",
    "for i in range(100):\n",
    "    kld.append(KL_divergence(std0[i],mu0[i],std1[i],mu1[i]))\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(kld)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('$D_{KL}$($\\hat{X}$||X)')\n",
    "plt.savefig(_filename('kld1.png'))\n",
    "plt.clf()\n",
    "\n",
    "mu0 = jnp.mean(actual, axis=(0,2))\n",
    "std0 = jnp.std(actual, axis=(0,2))\n",
    "\n",
    "mu1 = jnp.mean(pred, axis=(0,2))\n",
    "std1 = jnp.std(pred, axis=(0,2))\n",
    "\n",
    "kld_x = []\n",
    "for i in range(100):\n",
    "    kld_x.append(KL_divergence(std0[i,0],mu0[i,0],std1[i,0],mu1[i,0]))\n",
    "\n",
    "kld_y = []\n",
    "for i in range(100):\n",
    "    kld_y.append(KL_divergence(std0[i,1],mu0[i,1],std1[i,1],mu1[i,1]))\n",
    "\n",
    "\n",
    "plt.plot(kld_x, label ='x')\n",
    "plt.plot(kld_y, label ='y')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('$D_{KL}$($\\hat{X}$||X)')\n",
    "plt.legend()\n",
    "plt.savefig(_filename('kld_x_y.png'))\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_jaxbrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
